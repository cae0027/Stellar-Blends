{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from MuyGPyS import config\n",
    "# config.update(\"muygpys_jax_enabled\", False)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from MuyGPyS.examples.classify import do_classify\n",
    "from MuyGPyS.gp.deformation import F2, Isotropy\n",
    "from MuyGPyS.gp.hyperparameter import Parameter, Parameter as ScalarParam\n",
    "from MuyGPyS.gp.kernels import RBF, Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "from MuyGPyS.optimize import Bayes_optimize\n",
    "from MuyGPyS.optimize.loss import LossFn, cross_entropy_fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_image_data.csv']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# data_path = ['norm_11.csv','norm_1.csv', 'norm_21.csv', 'raw_image_data.csv']\n",
    "data_path = [ 'raw_image_data.csv']\n",
    "# get rid of \"../data/data-norm/\"\n",
    "norm_data_names = data_path\n",
    "norm_data_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_onehot_value(values):\n",
    "    onehot = []\n",
    "    for val in values:\n",
    "        if val == 0:\n",
    "            onehot.append([1., -1.])\n",
    "        elif val == 1:\n",
    "            onehot.append([-1., 1.])\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_kwargs_exact = {\"nn_method\": \"exact\", \"algorithm\": \"ball_tree\"}\n",
    "\n",
    "nn_kwargs_hnsw = {\"nn_method\": \"hnsw\"}\n",
    "\n",
    "k_kwargs_rbf ={\n",
    "            \"kernel\": RBF(\n",
    "                 deformation=Isotropy(\n",
    "                     metric=F2,\n",
    "                 length_scale=Parameter(1.0, (1e-2, 1e2)),\n",
    "                 ),\n",
    "            ),\n",
    "            \"noise\": HomoscedasticNoise(1e-5),\n",
    "            }\n",
    "k_kwargs_mattern= { \"kernel\": Matern(\n",
    "             smoothness=ScalarParam(0.5),\n",
    "             deformation=Isotropy(\n",
    "                 metric=F2,\n",
    "                 length_scale=Parameter(1.0, (1e-2, 1e2)),\n",
    "             ),\n",
    "         ),\n",
    "         \"noise\": HomoscedasticNoise(1e-5),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============  raw_image_datacsv  ===============\n",
      "Training data: 12022 single stars and 9779 blended stars\n",
      "Testing data: 3087 single stars and 2364 blended stars\n",
      "Running Classifier on raw_image_datacsv\n",
      "\u001b[91mData point [100.] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 5 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 6 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 7 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 8 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 9 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 10 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 11 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 12 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 13 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 14 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 15 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 16 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 17 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 18 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for raw_image_datacsv : 78.536 %\n"
     ]
    }
   ],
   "source": [
    "for path in norm_data_names:\n",
    "    path1 = '../data/data-norm/max-only/' + path\n",
    "    data = pd.read_csv(path1,na_values='-')\n",
    "    data.fillna(0,inplace=True)\n",
    "    data_label = ''.join(path.split('.')[:2])\n",
    "    truth_labels = data.iloc[:, 0].values\n",
    "    image_data = data.iloc[:, 1:].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(image_data, truth_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"=============== \", data_label, \" ===============\")\n",
    "    print('Training data:', len(y_train[y_train==0]), 'single stars and', len(y_train[y_train==1]), 'blended stars')\n",
    "    print('Testing data:', len(y_test[y_test==0]), 'single stars and', len(y_test[y_test==1]), 'blended stars')\n",
    "\n",
    "    onehot_train, onehot_test = generate_onehot_value(y_train), generate_onehot_value(y_test)\n",
    "\n",
    "    train = {'input': X_train, 'output': onehot_train, 'lookup': y_train}\n",
    "    test = {'input': X_test, 'output': onehot_test, 'lookup': y_test}\n",
    "\n",
    "    print(\"Running Classifier on\", data_label)\n",
    "    #Switch verbose to True for more output\n",
    "\n",
    "\n",
    "    muygps, nbrs_lookup, surrogate_predictions = do_classify(\n",
    "                                test_features=np.array(test['input']), \n",
    "                                train_features=np.array(train['input']), \n",
    "                                train_labels=np.array(train['output']), \n",
    "                                nn_count=30,\n",
    "                                batch_count=200,\n",
    "                                loss_fn=cross_entropy_fn,\n",
    "                                opt_fn=Bayes_optimize,\n",
    "                                k_kwargs=k_kwargs_mattern,\n",
    "                                nn_kwargs=nn_kwargs_hnsw,\n",
    "                                verbose=False)\n",
    "    predicted_labels = np.argmax(surrogate_predictions, axis=1)\n",
    "    print(\"Total accuracy for\", data_label, \":\", np.around((np.sum(predicted_labels == np.argmax(test[\"output\"], axis=1))/len(predicted_labels))*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muygps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
