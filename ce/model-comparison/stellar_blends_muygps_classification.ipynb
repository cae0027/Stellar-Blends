{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stellar Blends Classification\n",
    "\n",
    "### In this notebook we run the un-normalized and normalized datasets through the MuyGPyS classifier (a python classifying function that uses the MuyGPS  Gaussian process hyperparameter estimation method), and compare the resulting accuracies.\n",
    "\n",
    "**Note:** Must have run `data_normalization.ipynb` to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuyGPyS.optimize.loss import mse_fn, lool_fn, pseudo_huber_fn, looph_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eleh/miniconda3/envs/muygps/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# from MuyGPyS import config\n",
    "# config.update(\"muygpys_jax_enabled\", False)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from MuyGPyS.examples.classify import do_classify\n",
    "from MuyGPyS.gp.deformation import F2, Isotropy\n",
    "from MuyGPyS.gp.hyperparameter import Parameter, Parameter as ScalarParam\n",
    "from MuyGPyS.gp.kernels import RBF, Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "from MuyGPyS.optimize import Bayes_optimize\n",
    "from MuyGPyS.optimize.loss import LossFn, cross_entropy_fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in all flattened data (normalized and un-normalized):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# read normalized data csv file names from the data directory\n",
    "norm_data_names = glob('../data/data-norm/max-only/*.csv')\n",
    "# get rid of \"../data/data-norm/\"\n",
    "norm_data_names = [name.split('/')[-1] for name in norm_data_names]\n",
    "# norm_data_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nthroot_0.03448.csv',\n",
       " 'nthroot_0.06897.csv',\n",
       " 'nthroot_0.1034.csv',\n",
       " 'nthroot_0.1379.csv',\n",
       " 'nthroot_0.1724.csv',\n",
       " 'nthroot_0.2069.csv',\n",
       " 'nthroot_0.2414.csv',\n",
       " 'nthroot_0.2759.csv',\n",
       " 'nthroot_0.3103.csv',\n",
       " 'nthroot_0.3448.csv',\n",
       " 'nthroot_0.3793.csv',\n",
       " 'nthroot_0.4138.csv',\n",
       " 'nthroot_0.4483.csv',\n",
       " 'nthroot_0.4828.csv',\n",
       " 'nthroot_0.5172.csv',\n",
       " 'nthroot_0.5517.csv',\n",
       " 'nthroot_0.5862.csv',\n",
       " 'nthroot_0.6207.csv',\n",
       " 'nthroot_0.6552.csv',\n",
       " 'nthroot_0.6897.csv',\n",
       " 'nthroot_0.7241.csv',\n",
       " 'nthroot_0.7586.csv',\n",
       " 'nthroot_0.7931.csv',\n",
       " 'nthroot_0.8276.csv',\n",
       " 'nthroot_0.8621.csv',\n",
       " 'nthroot_0.8966.csv',\n",
       " 'nthroot_0.931.csv',\n",
       " 'nthroot_0.9655.csv',\n",
       " 'nthroot_1.0.csv',\n",
       " 'norm_1.csv',\n",
       " 'norm_11.csv',\n",
       " 'norm_2.csv',\n",
       " 'norm_21.csv',\n",
       " 'norm_3.csv',\n",
       " 'norm_31.csv',\n",
       " 'norm_4.csv',\n",
       " 'norm_41.csv',\n",
       " 'norm_5.csv',\n",
       " 'norm_51.csv',\n",
       " 'raw_image_data.csv',\n",
       " 'nthroot_log.csv',\n",
       " 'nthroot_mm0.03448.csv',\n",
       " 'nthroot_mm0.06897.csv',\n",
       " 'nthroot_mm0.1034.csv',\n",
       " 'nthroot_mm0.1379.csv',\n",
       " 'nthroot_mm0.1724.csv',\n",
       " 'nthroot_mm0.2069.csv',\n",
       " 'nthroot_mm0.2414.csv',\n",
       " 'nthroot_mm0.2759.csv',\n",
       " 'nthroot_mm0.3103.csv',\n",
       " 'nthroot_mm0.3448.csv',\n",
       " 'nthroot_mm0.3793.csv',\n",
       " 'nthroot_mm0.4138.csv',\n",
       " 'nthroot_mm0.4483.csv',\n",
       " 'nthroot_mm0.4828.csv',\n",
       " 'nthroot_mm0.5172.csv',\n",
       " 'nthroot_mm0.5517.csv',\n",
       " 'nthroot_mm0.5862.csv',\n",
       " 'nthroot_mm0.6207.csv',\n",
       " 'nthroot_mm0.6552.csv',\n",
       " 'nthroot_mm0.6897.csv',\n",
       " 'nthroot_mm0.7241.csv',\n",
       " 'nthroot_mm0.7586.csv',\n",
       " 'nthroot_mm0.7931.csv',\n",
       " 'nthroot_mm0.8276.csv',\n",
       " 'nthroot_mm0.8621.csv',\n",
       " 'nthroot_mm0.8966.csv',\n",
       " 'nthroot_mm0.931.csv',\n",
       " 'nthroot_mm0.9655.csv',\n",
       " 'nthroot_mm1.0.csv',\n",
       " 'std_scaler.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the names by their numbers\n",
    "norm_data_names.sort(key=lambda x: x.split('_')[1])\n",
    "norm_data_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that generates \"one-hot\" values.\n",
    "\n",
    "This essentially just takes our truth labels of 0 and 1, and does the following conversions for use in the classifier:\n",
    "- 0 to [1., -1.]\n",
    "- 1 to [-1., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_onehot_value(values):\n",
    "    onehot = []\n",
    "    for val in values:\n",
    "        if val == 0:\n",
    "            onehot.append([1., -1.])\n",
    "        elif val == 1:\n",
    "            onehot.append([-1., 1.])\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the classifier on each dataset\n",
    "\n",
    "For each dataset (un-normalized and normalized) in `data_files`, this for loop does the following:\n",
    "- Separate labels from data\n",
    "- Split up data between training and testing\n",
    "    - `test_size` is the fraction of the data you want to use for testing, where 0.5 means half of the data is used for testing and half for training.\n",
    "    - `random_state` makes each dataset get trained and tested on the same number of stars and galaxies.\n",
    "- Gets the one-hot values for the testing and training labels\n",
    "- Gets `train` and `test` into the proper format for the classifier, a dictionary with the keys: \n",
    "    - 'input': \n",
    "    - 'output':\n",
    "    - 'lookup':\n",
    "- Does the classification (`do_classify`)\n",
    "- Computes the accuracy of the classifier for the given dataset, by compairing predicted labels to truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_kwargs_exact = {\"nn_method\": \"exact\", \"algorithm\": \"ball_tree\"}\n",
    "\n",
    "nn_kwargs_hnsw = {\"nn_method\": \"hnsw\"}\n",
    "\n",
    "k_kwargs_rbf ={\n",
    "            \"kernel\": RBF(\n",
    "                 deformation=Isotropy(\n",
    "                     metric=F2,\n",
    "                 length_scale=Parameter(1.0, (1e-2, 1e2)),\n",
    "                 ),\n",
    "            ),\n",
    "            \"noise\": HomoscedasticNoise(1e-5),\n",
    "            }\n",
    "k_kwargs_mattern= { \"kernel\": Matern(\n",
    "             smoothness=ScalarParam(0.5),\n",
    "             deformation=Isotropy(\n",
    "                 metric=F2,\n",
    "                 length_scale=Parameter(1.0, (1e-2, 1e2)),\n",
    "             ),\n",
    "         ),\n",
    "         \"noise\": HomoscedasticNoise(1e-5),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============  nthroot_003448  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_003448\n",
      "Total accuracy for nthroot_003448 : 77.16 %\n",
      "===============  nthroot_006897  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_006897\n",
      "Total accuracy for nthroot_006897 : 78.243 %\n",
      "===============  nthroot_01034  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_01034\n",
      "Total accuracy for nthroot_01034 : 77.032 %\n",
      "===============  nthroot_01379  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_01379\n",
      "Total accuracy for nthroot_01379 : 77.637 %\n",
      "===============  nthroot_01724  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_01724\n",
      "Total accuracy for nthroot_01724 : 76.995 %\n",
      "===============  nthroot_02069  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_02069\n",
      "Total accuracy for nthroot_02069 : 76.848 %\n",
      "===============  nthroot_02414  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_02414\n",
      "Total accuracy for nthroot_02414 : 77.582 %\n",
      "===============  nthroot_02759  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_02759\n",
      "Total accuracy for nthroot_02759 : 77.894 %\n",
      "===============  nthroot_03103  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_03103\n",
      "Total accuracy for nthroot_03103 : 77.967 %\n",
      "===============  nthroot_03448  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_03448\n",
      "Total accuracy for nthroot_03448 : 77.344 %\n",
      "===============  nthroot_03793  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_03793\n",
      "Total accuracy for nthroot_03793 : 77.289 %\n",
      "===============  nthroot_04138  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_04138\n",
      "Total accuracy for nthroot_04138 : 75.564 %\n",
      "===============  nthroot_04483  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_04483\n",
      "Total accuracy for nthroot_04483 : 76.096 %\n",
      "===============  nthroot_04828  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_04828\n",
      "Total accuracy for nthroot_04828 : 77.197 %\n",
      "===============  nthroot_05172  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_05172\n",
      "Total accuracy for nthroot_05172 : 77.49 %\n",
      "===============  nthroot_05517  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_05517\n",
      "Total accuracy for nthroot_05517 : 75.564 %\n",
      "===============  nthroot_05862  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_05862\n",
      "Total accuracy for nthroot_05862 : 74.665 %\n",
      "===============  nthroot_06207  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_06207\n",
      "\u001b[91mData point [100.] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 5 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 6 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 7 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 8 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 9 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 10 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 11 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 12 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 13 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 14 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 15 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 16 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 17 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 18 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for nthroot_06207 : 74.096 %\n",
      "===============  nthroot_06552  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_06552\n",
      "Total accuracy for nthroot_06552 : 77.325 %\n",
      "===============  nthroot_06897  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_06897\n",
      "Total accuracy for nthroot_06897 : 74.445 %\n",
      "===============  nthroot_07241  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_07241\n",
      "Total accuracy for nthroot_07241 : 76.023 %\n",
      "===============  nthroot_07586  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_07586\n",
      "Total accuracy for nthroot_07586 : 76.298 %\n",
      "===============  nthroot_07931  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_07931\n",
      "Total accuracy for nthroot_07931 : 76.28 %\n",
      "===============  nthroot_08276  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_08276\n",
      "Total accuracy for nthroot_08276 : 75.821 %\n",
      "===============  nthroot_08621  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_08621\n",
      "Total accuracy for nthroot_08621 : 75.252 %\n",
      "===============  nthroot_08966  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_08966\n",
      "Total accuracy for nthroot_08966 : 74.408 %\n",
      "===============  nthroot_0931  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_0931\n",
      "Total accuracy for nthroot_0931 : 76.114 %\n",
      "===============  nthroot_09655  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_09655\n",
      "\u001b[91mData point [100.] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for nthroot_09655 : 74.83 %\n",
      "===============  nthroot_10  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_10\n",
      "\u001b[91mData point [100.] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 5 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for nthroot_10 : 74.629 %\n",
      "===============  norm_1csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_1csv\n",
      "Total accuracy for norm_1csv : 78.72 %\n",
      "===============  norm_11csv  ===============\n",
      "Training data: 12102 single stars and 9699 blended stars\n",
      "Testing data: 3007 single stars and 2444 blended stars\n",
      "Running Classifier on norm_11csv\n",
      "Total accuracy for norm_11csv : 78.921 %\n",
      "===============  norm_2csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_2csv\n",
      "Total accuracy for norm_2csv : 76.628 %\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for norm_21csv : 79.967 %\n",
      "===============  norm_3csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_3csv\n",
      "Total accuracy for norm_3csv : 79.343 %\n",
      "===============  norm_31csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_31csv\n",
      "Total accuracy for norm_31csv : 70.666 %\n",
      "===============  norm_4csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_4csv\n",
      "\u001b[91mData point [100.] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for norm_4csv : 69.584 %\n",
      "===============  norm_41csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_41csv\n",
      "Total accuracy for norm_41csv : 70.684 %\n",
      "===============  norm_5csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_5csv\n",
      "Total accuracy for norm_5csv : 80.022 %\n",
      "===============  norm_51csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_51csv\n",
      "Total accuracy for norm_51csv : 70.024 %\n",
      "===============  raw_image_datacsv  ===============\n",
      "Training data: 12022 single stars and 9779 blended stars\n",
      "Testing data: 3087 single stars and 2364 blended stars\n",
      "Running Classifier on raw_image_datacsv\n",
      "\u001b[91mData point [100.] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 5 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 6 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 7 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 8 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 9 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 10 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 11 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 12 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 13 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 14 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 15 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 16 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 17 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 18 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 19 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for raw_image_datacsv : 78.463 %\n",
      "===============  nthroot_logcsv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on nthroot_logcsv\n",
      "Total accuracy for nthroot_logcsv : 77.27 %\n",
      "===============  nthroot_mm003448  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm003448\n",
      "\u001b[91mData point [0.01] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [0.01] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for nthroot_mm003448 : 82.187 %\n",
      "===============  nthroot_mm006897  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm006897\n",
      "Total accuracy for nthroot_mm006897 : 79.508 %\n",
      "===============  nthroot_mm01034  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm01034\n",
      "Total accuracy for nthroot_mm01034 : 81.912 %\n",
      "===============  nthroot_mm01379  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm01379\n",
      "Total accuracy for nthroot_mm01379 : 79.728 %\n",
      "===============  nthroot_mm01724  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm01724\n",
      "Total accuracy for nthroot_mm01724 : 77.27 %\n",
      "===============  nthroot_mm02069  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm02069\n",
      "Total accuracy for nthroot_mm02069 : 77.619 %\n",
      "===============  nthroot_mm02414  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm02414\n",
      "Total accuracy for nthroot_mm02414 : 79.93 %\n",
      "===============  nthroot_mm02759  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm02759\n",
      "Total accuracy for nthroot_mm02759 : 81.38 %\n",
      "===============  nthroot_mm03103  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm03103\n",
      "Total accuracy for nthroot_mm03103 : 81.728 %\n",
      "===============  nthroot_mm03448  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm03448\n",
      "Total accuracy for nthroot_mm03448 : 80.04 %\n",
      "===============  nthroot_mm03793  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm03793\n",
      "Total accuracy for nthroot_mm03793 : 79.82 %\n",
      "===============  nthroot_mm04138  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm04138\n",
      "Total accuracy for nthroot_mm04138 : 79.233 %\n",
      "===============  nthroot_mm04483  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm04483\n",
      "Total accuracy for nthroot_mm04483 : 79.196 %\n",
      "===============  nthroot_mm04828  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm04828\n",
      "Total accuracy for nthroot_mm04828 : 79.086 %\n",
      "===============  nthroot_mm05172  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm05172\n",
      "Total accuracy for nthroot_mm05172 : 81.655 %\n",
      "===============  nthroot_mm05517  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm05517\n",
      "Total accuracy for nthroot_mm05517 : 79.343 %\n",
      "===============  nthroot_mm05862  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm05862\n",
      "Total accuracy for nthroot_mm05862 : 81.636 %\n",
      "===============  nthroot_mm06207  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm06207\n",
      "Total accuracy for nthroot_mm06207 : 79.692 %\n",
      "===============  nthroot_mm06552  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm06552\n",
      "Total accuracy for nthroot_mm06552 : 80.059 %\n",
      "===============  nthroot_mm06897  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm06897\n",
      "Total accuracy for nthroot_mm06897 : 78.701 %\n",
      "===============  nthroot_mm07241  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm07241\n",
      "\u001b[91mData point [100.] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 5 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 6 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 7 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 8 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 9 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 10 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 11 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 12 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 13 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 14 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 15 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 16 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for nthroot_mm07241 : 75.968 %\n",
      "===============  nthroot_mm07586  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm07586\n",
      "Total accuracy for nthroot_mm07586 : 78.775 %\n",
      "===============  nthroot_mm07931  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm07931\n",
      "Total accuracy for nthroot_mm07931 : 78.903 %\n",
      "===============  nthroot_mm08276  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm08276\n",
      "Total accuracy for nthroot_mm08276 : 79.417 %\n",
      "===============  nthroot_mm08621  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm08621\n",
      "Total accuracy for nthroot_mm08621 : 79.178 %\n",
      "===============  nthroot_mm08966  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm08966\n",
      "\u001b[91mData point [0.01] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [0.01] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [0.01] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [0.01] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for nthroot_mm08966 : 77.289 %\n",
      "===============  nthroot_mm0931  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm0931\n",
      "Total accuracy for nthroot_mm0931 : 79.38 %\n",
      "===============  nthroot_mm09655  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm09655\n",
      "\u001b[91mData point [100.] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 2 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 3 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 4 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 5 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 6 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 7 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 8 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 9 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 10 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 11 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 12 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 13 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 14 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 15 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 16 duplicates registered. Continuing ...\u001b[0m\n",
      "\u001b[91mData point [100.] is not unique. 17 duplicates registered. Continuing ...\u001b[0m\n",
      "Total accuracy for nthroot_mm09655 : 75.986 %\n",
      "===============  nthroot_mm10  ===============\n",
      "Training data: 12118 single stars and 9683 blended stars\n",
      "Testing data: 2991 single stars and 2460 blended stars\n",
      "Running Classifier on nthroot_mm10\n",
      "Total accuracy for nthroot_mm10 : 79.05 %\n",
      "===============  std_scalercsv  ===============\n",
      "Training data: 12079 single stars and 9722 blended stars\n",
      "Testing data: 3030 single stars and 2421 blended stars\n",
      "Running Classifier on std_scalercsv\n",
      "Total accuracy for std_scalercsv : 73.766 %\n"
     ]
    }
   ],
   "source": [
    "norm_name = []\n",
    "my_accuracy = []\n",
    "for path in tqdm(norm_data_names):\n",
    "    path1 = '../data/data-norm/max-only/' + path\n",
    "    data = pd.read_csv(path1,na_values='-')\n",
    "    data.fillna(0,inplace=True)\n",
    "    data_label = ''.join(path.split('.')[:2])\n",
    "    truth_labels = data.iloc[:, 0].values\n",
    "    image_data = data.iloc[:, 1:].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(image_data, truth_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"=============== \", data_label, \" ===============\")\n",
    "    print('Training data:', len(y_train[y_train==0]), 'single stars and', len(y_train[y_train==1]), 'blended stars')\n",
    "    print('Testing data:', len(y_test[y_test==0]), 'single stars and', len(y_test[y_test==1]), 'blended stars')\n",
    "\n",
    "    onehot_train, onehot_test = generate_onehot_value(y_train), generate_onehot_value(y_test)\n",
    "\n",
    "    train = {'input': X_train, 'output': onehot_train, 'lookup': y_train}\n",
    "    test = {'input': X_test, 'output': onehot_test, 'lookup': y_test}\n",
    "\n",
    "    print(\"Running Classifier on\", data_label)\n",
    "    #Switch verbose to True for more output\n",
    "\n",
    "\n",
    "    muygps, nbrs_lookup, surrogate_predictions = do_classify(\n",
    "                                test_features=np.array(test['input']), \n",
    "                                train_features=np.array(train['input']), \n",
    "                                train_labels=np.array(train['output']), \n",
    "                                nn_count=30,\n",
    "                                batch_count=200,\n",
    "                                loss_fn=cross_entropy_fn,\n",
    "                                opt_fn=Bayes_optimize,\n",
    "                                k_kwargs=k_kwargs_mattern,\n",
    "                                nn_kwargs=nn_kwargs_hnsw,\n",
    "                                verbose=False)\n",
    "    predicted_labels = np.argmax(surrogate_predictions, axis=1)\n",
    "    accur = np.around((np.sum(predicted_labels == np.argmax(test[\"output\"], axis=1))/len(predicted_labels))*100, 3)\n",
    "    norm_name.append(data_label.split('_')[-1])\n",
    "    my_accuracy.append(accur)\n",
    "    print(\"Total accuracy for\", data_label, \":\", accur, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69.584, 82.187)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(my_accuracy), max(my_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>35</th>\n",
       "      <th>38</th>\n",
       "      <th>34</th>\n",
       "      <th>36</th>\n",
       "      <th>70</th>\n",
       "      <th>17</th>\n",
       "      <th>25</th>\n",
       "      <th>19</th>\n",
       "      <th>28</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>37</th>\n",
       "      <th>50</th>\n",
       "      <th>59</th>\n",
       "      <th>48</th>\n",
       "      <th>57</th>\n",
       "      <th>55</th>\n",
       "      <th>49</th>\n",
       "      <th>43</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>norm_name</th>\n",
       "      <td>4csv</td>\n",
       "      <td>51csv</td>\n",
       "      <td>31csv</td>\n",
       "      <td>41csv</td>\n",
       "      <td>scalercsv</td>\n",
       "      <td>06207</td>\n",
       "      <td>08966</td>\n",
       "      <td>06897</td>\n",
       "      <td>10</td>\n",
       "      <td>05862</td>\n",
       "      <td>...</td>\n",
       "      <td>21csv</td>\n",
       "      <td>5csv</td>\n",
       "      <td>mm03448</td>\n",
       "      <td>mm06552</td>\n",
       "      <td>mm02759</td>\n",
       "      <td>mm05862</td>\n",
       "      <td>mm05172</td>\n",
       "      <td>mm03103</td>\n",
       "      <td>mm01034</td>\n",
       "      <td>mm003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>69.584</td>\n",
       "      <td>70.024</td>\n",
       "      <td>70.666</td>\n",
       "      <td>70.684</td>\n",
       "      <td>73.766</td>\n",
       "      <td>74.096</td>\n",
       "      <td>74.408</td>\n",
       "      <td>74.445</td>\n",
       "      <td>74.629</td>\n",
       "      <td>74.665</td>\n",
       "      <td>...</td>\n",
       "      <td>79.967</td>\n",
       "      <td>80.022</td>\n",
       "      <td>80.04</td>\n",
       "      <td>80.059</td>\n",
       "      <td>81.38</td>\n",
       "      <td>81.636</td>\n",
       "      <td>81.655</td>\n",
       "      <td>81.728</td>\n",
       "      <td>81.912</td>\n",
       "      <td>82.187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               35      38      34      36         70      17      25      19  \\\n",
       "norm_name    4csv   51csv   31csv   41csv  scalercsv   06207   08966   06897   \n",
       "accuracy   69.584  70.024  70.666  70.684     73.766  74.096  74.408  74.445   \n",
       "\n",
       "               28      16  ...      32      37       50       59       48  \\\n",
       "norm_name      10   05862  ...   21csv    5csv  mm03448  mm06552  mm02759   \n",
       "accuracy   74.629  74.665  ...  79.967  80.022    80.04   80.059    81.38   \n",
       "\n",
       "                57       55       49       43        41  \n",
       "norm_name  mm05862  mm05172  mm03103  mm01034  mm003448  \n",
       "accuracy    81.636   81.655   81.728   81.912    82.187  \n",
       "\n",
       "[2 rows x 71 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accura = pd.DataFrame({'norm_name': norm_name, 'accuracy': my_accuracy})\n",
    "accura.to_csv('../data/muygps-max-only-accuracy.csv', index=False)\n",
    "\n",
    "accura = pd.read_csv('../data/muygps-max-only-accuracy.csv')   \n",
    "accura.sort_values(by=['accuracy'], inplace=True)\n",
    "accura.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_name</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mm003448</td>\n",
       "      <td>82.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>mm01034</td>\n",
       "      <td>81.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mm03103</td>\n",
       "      <td>81.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>mm05172</td>\n",
       "      <td>81.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>mm05862</td>\n",
       "      <td>81.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mm02759</td>\n",
       "      <td>81.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>mm06552</td>\n",
       "      <td>80.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mm03448</td>\n",
       "      <td>80.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5csv</td>\n",
       "      <td>80.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>21csv</td>\n",
       "      <td>79.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mm02414</td>\n",
       "      <td>79.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mm03793</td>\n",
       "      <td>79.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>mm01379</td>\n",
       "      <td>79.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mm06207</td>\n",
       "      <td>79.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mm006897</td>\n",
       "      <td>79.508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   norm_name  accuracy\n",
       "41  mm003448    82.187\n",
       "43   mm01034    81.912\n",
       "49   mm03103    81.728\n",
       "55   mm05172    81.655\n",
       "57   mm05862    81.636\n",
       "48   mm02759    81.380\n",
       "59   mm06552    80.059\n",
       "50   mm03448    80.040\n",
       "37      5csv    80.022\n",
       "32     21csv    79.967\n",
       "47   mm02414    79.930\n",
       "51   mm03793    79.820\n",
       "44   mm01379    79.728\n",
       "58   mm06207    79.692\n",
       "42  mm006897    79.508"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accura.nlargest(15, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>***Note:*** Each time you run the classifier will result in different accuracies.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, all 5 normalization techniques do much better than the un-normalized data, with some performing better than others.\n",
    "\n",
    "### Things you can try, to see how they affect the classifier accuracy:\n",
    "- Play around with different values of `test_size`. What does testing on more or less data do?\n",
    "- Play around with different parameters that are passed to `do_classify`. Start with `nn_count` and `embed_dim`(For what those arguments are, and a full list of all of the arguments you can pass to do_classify, look at the function `do_classify` in `/MuyGPyS/examples/classify.py`).\n",
    "- Try generating more cutouts using `generating_ZTF_cutouts_from_ra_dec.ipynb`. How does having more testing and training data affects the classifier?\n",
    "- Play around with the parameters used to make the cutouts. What happens if you remove blend cuts? Can the classifier classify blends? What is you increase the seeing limit? Can the classifier classify images with bad atmoshperic quality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>**Optional Step:**</u>\n",
    "### Running each dataset through the classifier multiple times, testing and training on varying amounts of data, different random states, and plotting the accuracy outcomes\n",
    "\n",
    "- Each time you run the following steps, you change:\n",
    "    - `test_size`: This is used in `train_test_split`, and changes the size of the testing and training datasets, which effects the accuracy of the classifier.\n",
    "    - `random_state`: This is used in `train_test_split`, and changes the ratio of how many stars-to-galaxies get tested on.\n",
    "- You can set how many times to run the classifier with varying test sizes and random states by setting `num_runs`, and you can manually change the test_size values by editing `test_size_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_values = [.2, .25, .33, .4, .5, .75]\n",
    "num_runs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_classifier(image_data, truth_labels, test_size, state):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(image_data, truth_labels, test_size=test_size, random_state=state)\n",
    "#     onehot_train, onehot_test = generate_onehot_value(y_train), generate_onehot_value(y_test)\n",
    "#     train = {'input': X_train, 'output': onehot_train, 'lookup': y_train}\n",
    "#     test = {'input': X_test, 'output': onehot_test, 'lookup': y_test}\n",
    "#     #Switch verbose to True for more output\n",
    "#     muygps, nbrs_lookup, surrogate_predictions= do_classify(\n",
    "#                         test_features=np.array(test['input']),\n",
    "#                         train_features=np.array(train['input']), \n",
    "#                         train_labels=np.array(train['output']), \n",
    "#                         nn_count=20,\n",
    "#                         batch_count=200,\n",
    "#                         loss_fn=cross_entropy_fn,\n",
    "#                         opt_fn=Bayes_optimize,\n",
    "#                         k_kwargs=k_kwargs_mattern,\n",
    "#                         nn_kwargs=nn_kwargs_hnsw, \n",
    "#                         verbose=False) \n",
    "#     predicted_labels = np.argmax(surrogate_predictions, axis=1)\n",
    "#     accuracy = (np.sum(predicted_labels == np.argmax(test[\"output\"], axis=1))/len(predicted_labels))*100\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# accuracies = pd.DataFrame({'test_size': test_size_values})\n",
    "\n",
    "# # Setting progress bar for each time the classifier will be run during this step\n",
    "# pbar = tqdm(total=len(norm_data_names)*num_runs*len(test_size_values), desc='Running classifier', leave=True)\n",
    "\n",
    "# for path in norm_data_names:\n",
    "#     path1 = '../data/data-norm/max-only/' + path\n",
    "#     data = pd.read_csv(path1,na_values='-')\n",
    "#     data.fillna(0,inplace=True)\n",
    "#     data_label = ''.join(path.split('.')[:2])\n",
    "#     truth_labels = data.iloc[:, 0].values\n",
    "#     image_data = data.iloc[:, 1:].values\n",
    "#     all_acc_dataset = []\n",
    "#     for test_size in test_size_values:\n",
    "#         acc = []\n",
    "#         idx = 1\n",
    "#         while idx <= num_runs:\n",
    "#             accuracy = run_classifier(image_data, truth_labels, test_size, state=random.randint(0, 10000))\n",
    "#             acc.append(accuracy)\n",
    "#             pbar.update(1)\n",
    "#             idx += 1\n",
    "#         avg_acc = np.average(acc)\n",
    "#         all_acc_dataset.append(avg_acc)\n",
    "#     temp_df = pd.DataFrame({str(data_label): all_acc_dataset})\n",
    "#     accuracies = pd.concat([accuracies, temp_df], axis=1)\n",
    "# display(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,4))\n",
    "\n",
    "# for path in norm_data_names:\n",
    "#     path1 = '../data/data-norm/max-only/' + path\n",
    "#     data = pd.read_csv(path1,na_values='-')\n",
    "#     data.fillna(0,inplace=True)\n",
    "#     data_label = ''.join(path.split('.')[:2])\n",
    "#     # data_label = 'Normalized {} {}'.format(*path.split('_')[:2])\n",
    "#     plt.plot(accuracies['test_size'].values, accuracies[data_label].values, label=data_label)\n",
    "\n",
    "# plt.title(\"MuyGPs Stellar Blending 2-class\")    \n",
    "# plt.legend(fontsize=10)   \n",
    "# plt.tick_params(labelsize=10)\n",
    "# plt.xlabel(\"Test size (as a ratio to full data size)\", fontsize=10)\n",
    "# plt.ylabel(\"Accuracy [%]\", fontsize=10)\n",
    "# plt.savefig(\"muygps_.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies.to_csv(\"max-only-accuracy.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "611680c3a571b4cc3609a25adc9d467ee0ee0a175b157eb6c71343c892809ab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
