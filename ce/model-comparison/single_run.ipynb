{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eleh/miniconda3/envs/muygps/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# from MuyGPyS import config\n",
    "# config.update(\"muygpys_jax_enabled\", False)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from MuyGPyS.examples.classify import do_classify\n",
    "from MuyGPyS.gp.deformation import F2, Isotropy, l2\n",
    "from MuyGPyS.gp.hyperparameter import Parameter, Parameter as ScalarParam\n",
    "from MuyGPyS.gp.kernels import RBF, Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "from MuyGPyS.optimize import Bayes_optimize, L_BFGS_B_optimize\n",
    "from MuyGPyS.optimize.loss import LossFn, cross_entropy_fn, looph_fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_path = ['norm_11.csv','norm_1.csv', 'norm_21.csv', 'raw_image_data.csv']\n",
    "data_path = [ 'raw_image_data.csv']\n",
    "# get rid of \"../data/data-norm/\"\n",
    "norm_data_names = data_path\n",
    "norm_data_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_onehot_value(values):\n",
    "    onehot = []\n",
    "    for val in values:\n",
    "        if val == 0:\n",
    "            onehot.append([1., -1.])\n",
    "        elif val == 1:\n",
    "            onehot.append([-1., 1.])\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_kwargs_exact = {\"nn_method\": \"exact\", \"algorithm\": \"ball_tree\"}\n",
    "\n",
    "nn_kwargs_hnsw = {\"nn_method\": \"hnsw\"}\n",
    "\n",
    "k_kwargs_rbf ={\n",
    "            \"kernel\": RBF(\n",
    "                 deformation=Isotropy(\n",
    "                     metric=F2,\n",
    "                 length_scale=Parameter(1.0, (1e-2, 1e2)),\n",
    "                 ),\n",
    "            ),\n",
    "            \"noise\": HomoscedasticNoise(1e-5),\n",
    "            }\n",
    "k_kwargs_mattern= { \"kernel\": Matern(\n",
    "             smoothness=ScalarParam(0.5),\n",
    "             deformation=Isotropy(\n",
    "                 metric=F2,\n",
    "                 length_scale=Parameter(1.0, (1e-2, 1e2)),\n",
    "             ),\n",
    "         ),\n",
    "         \"noise\": HomoscedasticNoise(1e-5),\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary Test Sizes\n",
    "Using the top performing normalization, we vary test sizes to see the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_kwargs_hnsw = {\"nn_method\": \"hnsw\"}\n",
    "\n",
    "# k_kwargs_mattern= { \"kernel\": Matern(\n",
    "#              smoothness=ScalarParam(0.858571),\n",
    "#              deformation=Isotropy(\n",
    "#                  metric=F2,\n",
    "#                  length_scale=Parameter(.756327, (1e-2, 1e2)),\n",
    "#              ),\n",
    "#          ),\n",
    "#          \"noise\": HomoscedasticNoise(0.244898),\n",
    "#          }\n",
    "\n",
    "k_kwargs_mattern= { \"kernel\": Matern(\n",
    "             smoothness=ScalarParam(0.5),\n",
    "             deformation=Isotropy(\n",
    "                 metric=l2,\n",
    "                 length_scale=Parameter(10.0, (1e-2, 1e2)),\n",
    "             ),\n",
    "         ),\n",
    "         \"noise\": HomoscedasticNoise(1e-6),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============  norm_21csv  ===============\n",
      "Training data: 12073 single stars and 9728 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 1.0 : 83.728\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 9660 single stars and 7780 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 0.8 : 81.104\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 8452 single stars and 6808 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 0.7 : 79.71\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 7246 single stars and 5834 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 0.6 : 78.444\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 6048 single stars and 4852 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 0.5 : 77.197\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 4802 single stars and 3918 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 0.4 : 75.637\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 3594 single stars and 2946 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 0.3 : 74.72\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 2379 single stars and 1981 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 0.2 : 67.547\n",
      "===============  norm_21csv  ===============\n",
      "Training data: 1212 single stars and 968 blended stars\n",
      "Testing data: 3036 single stars and 2415 blended stars\n",
      "Running Classifier on norm_21csv\n",
      "Total accuracy for 0.1 : 71.51\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "train_sizes = [1.0, 0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]\n",
    "# read in data\n",
    "path = 'norm_21.csv'\n",
    "path1 = '../data/data-norm/max-only/' + path\n",
    "data = pd.read_csv(path1,na_values='-')\n",
    "data.fillna(0,inplace=True)\n",
    "data_label = ''.join(path.split('.')[:2])\n",
    "truth_labels = data.iloc[:, 0].values\n",
    "image_data = data.iloc[:, 1:].values\n",
    "\n",
    "# reserve test data\n",
    "X, X_test, y, y_test = train_test_split(image_data, truth_labels, train_size=0.8, random_state=42)\n",
    "\n",
    "accuracy = {i:[] for i in train_sizes}\n",
    "# i = 0   # run one at a time since MUYGPS won't left me run multiple at once\n",
    "for size in train_sizes:\n",
    "    if size == 1.0:\n",
    "        X_train, y_train = X, y\n",
    "    else:\n",
    "        X_train, _, y_train, _ = train_test_split(X, y, train_size=size, random_state=32)\n",
    "\n",
    "\n",
    "    print(\"=============== \", data_label, \" ===============\")\n",
    "    print('Training data:', len(y_train[y_train==0]), 'single stars and', len(y_train[y_train==1]), 'blended stars')\n",
    "    print('Testing data:', len(y_test[y_test==0]), 'single stars and', len(y_test[y_test==1]), 'blended stars')\n",
    "\n",
    "    onehot_train, onehot_test = generate_onehot_value(y_train), generate_onehot_value(y_test)\n",
    "\n",
    "    train = {'input': X_train, 'output': onehot_train, 'lookup': y_train}\n",
    "    test = {'input': X_test, 'output': onehot_test, 'lookup': y_test}\n",
    "\n",
    "    print(\"Running Classifier on\", data_label)\n",
    "    #Switch verbose to True for more output\n",
    "\n",
    "\n",
    "    muygps, nbrs_lookup, surrogate_predictions = do_classify(\n",
    "                                test_features=np.array(test['input']), \n",
    "                                train_features=np.array(train['input']), \n",
    "                                train_labels=np.array(train['output']), \n",
    "                                nn_count=40,\n",
    "                                batch_count=200,\n",
    "                                loss_fn=looph_fn,\n",
    "                                opt_fn=L_BFGS_B_optimize,\n",
    "                                k_kwargs=k_kwargs_mattern,\n",
    "                                nn_kwargs=nn_kwargs_hnsw,\n",
    "                                verbose=False)\n",
    "    predicted_labels = np.argmax(surrogate_predictions, axis=1)\n",
    "    accur = np.around((np.sum(predicted_labels == np.argmax(test[\"output\"], axis=1))/len(predicted_labels))*100, 3)\n",
    "    accuracy[size].append(accur)\n",
    "    print(\"Total accuracy for\", size, \":\", accur)\n",
    "\n",
    "    # check if accuracy file exists, if not save it as a new file and if it does exist, append to it\n",
    "    try:\n",
    "        with open('./vary-test-size/muygps-accuracy.pkl', 'rb') as f:\n",
    "            acc = pickle.load(f)\n",
    "            acc.update(accuracy)\n",
    "        with open('./vary-test-size/muygps-accuracy.pkl', 'wb') as f:\n",
    "            pickle.dump(acc, f)\n",
    "    except:\n",
    "        with open('./vary-test-size/muygps-accuracy.pkl', 'wb') as f:\n",
    "            pickle.dump(accuracy, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle save accuracy\n",
    "import pickle\n",
    "with open('./vary-test-size/muygps-accuracy.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracy, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muygps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
