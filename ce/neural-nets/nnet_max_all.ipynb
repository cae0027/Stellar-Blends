{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model for Comparison (Max-all)\n",
    "In comparison to state of the art models, we train a neural network on the normalized data including the raw data. \n",
    "Since our dataset comparises image data, a natural thing to do is compare with a CNN model. However, we do not compare with a CNN model because the resolution of the data is small. The data are 10x10 images. We trained CNN models, though but did not get any better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "\n",
    "class DynamicBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(DynamicBinaryClassifier, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "        self.hidden_layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(prev_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class BinaryClassifierTrainer:\n",
    "    def __init__(self, model, criterion, optimizer, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def _to_tensor(self, data):\n",
    "        if not torch.is_tensor(data):\n",
    "            data = torch.tensor(data, dtype=torch.float32)\n",
    "        return data.to(self.device)\n",
    "\n",
    "    def train(self, input_data, labels, num_epochs=100, batch_size=32):\n",
    "        input_data, labels = self._to_tensor(input_data), self._to_tensor(labels)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0.0\n",
    "\n",
    "            # Forward pass and calculate loss\n",
    "            for i in range(0, len(input_data), batch_size):\n",
    "                batch_input = input_data[i:i + batch_size]\n",
    "                batch_labels = labels[i:i + batch_size]\n",
    "\n",
    "                outputs = self.model(batch_input)\n",
    "                loss = self.criterion(outputs, batch_labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            average_loss = total_loss / (len(input_data) / batch_size)\n",
    "\n",
    "            # Print the average loss every 100 epochs\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {average_loss:.8f}')\n",
    "\n",
    "    def evaluate(self, input_data, labels):\n",
    "        input_data, labels = self._to_tensor(input_data), self._to_tensor(labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_data)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "\n",
    "        accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        return accuracy\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_1_data.csv\n",
      "Epoch [100/200], Average Loss: 0.50620754\n",
      "Epoch [200/200], Average Loss: 0.47587905\n",
      "Test Accuracy: 0.7399\n",
      "norm_1_data.csv\n",
      "Epoch [100/200], Average Loss: 0.45274650\n",
      "Epoch [200/200], Average Loss: 0.43312552\n",
      "Test Accuracy: 0.7472\n",
      "norm_1_data.csv\n",
      "Epoch [100/200], Average Loss: 0.41499026\n",
      "Epoch [200/200], Average Loss: 0.39766189\n",
      "Test Accuracy: 0.7496\n",
      "nthroot_0.4828.csv\n",
      "Epoch [100/200], Average Loss: 0.53570529\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from glob import glob\n",
    "\n",
    "# Example usage:\n",
    "input_size = 100\n",
    "hidden_sizes = [70,64, 32]\n",
    "output_size = 1\n",
    "\n",
    "model = DynamicBinaryClassifier(input_size, hidden_sizes, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "trainer = BinaryClassifierTrainer(model, criterion, optimizer)\n",
    "\n",
    "start = perf_counter()\n",
    "# read data\n",
    "batch_size = 128\n",
    "files = glob('../../data/data-norm/max-pixel-all/*.csv')\n",
    "file_names = [f.split('/')[-1] for f in files]\n",
    "results = {name:[] for name in file_names}\n",
    "for name in results:\n",
    "    for _ in range(3):\n",
    "        print(name)\n",
    "        dat = pd.read_csv(f'../../data/data-norm/max-pixel-all/{name}')\n",
    "        data = dat.iloc[:, 1:].values\n",
    "        labels = dat.iloc[:, 0].values.reshape(-1, 1)\n",
    "        # Split the data into training and test sets\n",
    "        input_train, input_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "        # Training\n",
    "        trainer.train(input_train, labels_train, num_epochs=200, batch_size=batch_size)\n",
    "        # Evaluation\n",
    "        test_accuracy = trainer.evaluate(input_test, labels_test)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "        results[name].append(test_accuracy)\n",
    "data_accuracies = pd.DataFrame(results)\n",
    "data_accuracies.to_csv('../../data/data-norm/accuracies-nnet-max-all.csv', index=False)\n",
    "\n",
    "end = perf_counter()\n",
    "print(f'Total time taken: {(end-start)/60:.6f} minutes')\n",
    "# dat = pd.read_csv('../../data/data-norm/max-only/raw_image_data.csv')\n",
    "# data = dat.iloc[:, 1:].values\n",
    "# labels = dat.iloc[:, 0].values.reshape(-1, 1)\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# input_train, input_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Training\n",
    "# trainer.train(input_train, labels_train, num_epochs=1000, batch_size=32)\n",
    "\n",
    "# # Evaluation\n",
    "# test_accuracy = trainer.evaluate(input_test, labels_test)\n",
    "# print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_accuracies = pd.read_csv('../../data/data-norm/accuracies-nnet-max-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nthroot_0.4483_data.csv\n",
       "1         nthroot_0.5862.csv\n",
       "2    nthroot_0.4483_data.csv\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return column with max value\n",
    "data_accuracies.idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.774537\n",
       "1    0.777105\n",
       "2    0.774904\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(data_accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idcs = np.argmax(data_accuracies.values, axis=1)\n",
    "idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nthroot_0.4483_data.csv</th>\n",
       "      <th>nthroot_0.5862.csv</th>\n",
       "      <th>nthroot_0.4483_data.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774537</td>\n",
       "      <td>0.774170</td>\n",
       "      <td>0.774537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775087</td>\n",
       "      <td>0.777105</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774904</td>\n",
       "      <td>0.770501</td>\n",
       "      <td>0.774904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nthroot_0.4483_data.csv  nthroot_0.5862.csv  nthroot_0.4483_data.csv\n",
       "0                 0.774537            0.774170                 0.774537\n",
       "1                 0.775087            0.777105                 0.775087\n",
       "2                 0.774904            0.770501                 0.774904"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_accuracies.iloc[:, idcs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all normalizations as well as the raw data, the $r^{th}$ with max-all over each image performs the best at an average of $77\\%$ accuracy on $20\\%$ test data for neural nets models. So judging from these runs, we conlcude that for neural net models, dividing each pixel with the absolute max over the entire dataset is more benefitial than dividing by max over each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nthroot_0.4483_data.csv    0.774843\n",
       "nthroot_0.5862.csv         0.773925\n",
       "nthroot_0.5862_data.csv    0.766587\n",
       "nthroot_0.7931.csv         0.763346\n",
       "nthroot_0.5172.csv         0.752278\n",
       "nthroot_1.0.csv            0.750199\n",
       "norm_1_data.csv            0.747875\n",
       "nthroot_0.4828.csv         0.737541\n",
       "norm_41_data.csv           0.631383\n",
       "norm_31_data.csv           0.618908\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_accuracies.mean(axis=0).nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary Test Size\n",
    "We check DNN performance when the test size changes. Use the top performing normalization `nthroot_0.5862.csv` file as well the optimized DNN hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/5000], Average Loss: 0.63515377\n",
      "Epoch [200/5000], Average Loss: 0.59384577\n",
      "Epoch [300/5000], Average Loss: 0.57089741\n",
      "Epoch [400/5000], Average Loss: 0.56067075\n",
      "Epoch [500/5000], Average Loss: 0.55313288\n",
      "Epoch [600/5000], Average Loss: 0.54798395\n",
      "Epoch [700/5000], Average Loss: 0.54378209\n",
      "Epoch [800/5000], Average Loss: 0.53918287\n",
      "Epoch [900/5000], Average Loss: 0.53571763\n",
      "Epoch [1000/5000], Average Loss: 0.53302630\n",
      "Epoch [1100/5000], Average Loss: 0.52950280\n",
      "Epoch [1200/5000], Average Loss: 0.52622631\n",
      "Epoch [1300/5000], Average Loss: 0.52359590\n",
      "Epoch [1400/5000], Average Loss: 0.52003026\n",
      "Epoch [1500/5000], Average Loss: 0.51746077\n",
      "Epoch [1600/5000], Average Loss: 0.51384635\n",
      "Epoch [1700/5000], Average Loss: 0.51004781\n",
      "Epoch [1800/5000], Average Loss: 0.50680383\n",
      "Epoch [1900/5000], Average Loss: 0.50335095\n",
      "Epoch [2000/5000], Average Loss: 0.49937122\n",
      "Epoch [2100/5000], Average Loss: 0.49601718\n",
      "Epoch [2200/5000], Average Loss: 0.49230493\n",
      "Epoch [2300/5000], Average Loss: 0.48921100\n",
      "Epoch [2400/5000], Average Loss: 0.48584471\n",
      "Epoch [2500/5000], Average Loss: 0.48251584\n",
      "Epoch [2600/5000], Average Loss: 0.48051841\n",
      "Epoch [2700/5000], Average Loss: 0.47742881\n",
      "Epoch [2800/5000], Average Loss: 0.47533178\n",
      "Epoch [2900/5000], Average Loss: 0.47212983\n",
      "Epoch [3000/5000], Average Loss: 0.46931011\n",
      "Epoch [3100/5000], Average Loss: 0.46770923\n",
      "Epoch [3200/5000], Average Loss: 0.46403698\n",
      "Epoch [3300/5000], Average Loss: 0.46131814\n",
      "Epoch [3400/5000], Average Loss: 0.45921109\n",
      "Epoch [3500/5000], Average Loss: 0.45631214\n",
      "Epoch [3600/5000], Average Loss: 0.45498170\n",
      "Epoch [3700/5000], Average Loss: 0.45315135\n",
      "Epoch [3800/5000], Average Loss: 0.44985053\n",
      "Epoch [3900/5000], Average Loss: 0.44783927\n",
      "Epoch [4000/5000], Average Loss: 0.44426600\n",
      "Epoch [4100/5000], Average Loss: 0.44187475\n",
      "Epoch [4200/5000], Average Loss: 0.44059318\n",
      "Epoch [4300/5000], Average Loss: 0.43771632\n",
      "Epoch [4400/5000], Average Loss: 0.43447585\n",
      "Epoch [4500/5000], Average Loss: 0.43409868\n",
      "Epoch [4600/5000], Average Loss: 0.43305142\n",
      "Epoch [4700/5000], Average Loss: 0.43049100\n",
      "Epoch [4800/5000], Average Loss: 0.42731714\n",
      "Epoch [4900/5000], Average Loss: 0.42580943\n",
      "Epoch [5000/5000], Average Loss: 0.42342167\n",
      "Test Accuracy: 0.7217\n",
      "Epoch [100/5000], Average Loss: 0.62409782\n",
      "Epoch [200/5000], Average Loss: 0.57848073\n",
      "Epoch [300/5000], Average Loss: 0.55989499\n",
      "Epoch [400/5000], Average Loss: 0.54990124\n",
      "Epoch [500/5000], Average Loss: 0.54365274\n",
      "Epoch [600/5000], Average Loss: 0.53735506\n",
      "Epoch [700/5000], Average Loss: 0.53256837\n",
      "Epoch [800/5000], Average Loss: 0.52764555\n",
      "Epoch [900/5000], Average Loss: 0.52298399\n",
      "Epoch [1000/5000], Average Loss: 0.51835301\n",
      "Epoch [1100/5000], Average Loss: 0.51383985\n",
      "Epoch [1200/5000], Average Loss: 0.50896864\n",
      "Epoch [1300/5000], Average Loss: 0.50509813\n",
      "Epoch [1400/5000], Average Loss: 0.50018869\n",
      "Epoch [1500/5000], Average Loss: 0.49568832\n",
      "Epoch [1600/5000], Average Loss: 0.49083009\n",
      "Epoch [1700/5000], Average Loss: 0.48581714\n",
      "Epoch [1800/5000], Average Loss: 0.48185747\n",
      "Epoch [1900/5000], Average Loss: 0.47754902\n",
      "Epoch [2000/5000], Average Loss: 0.47352688\n",
      "Epoch [2100/5000], Average Loss: 0.46945192\n",
      "Epoch [2200/5000], Average Loss: 0.46516260\n",
      "Epoch [2300/5000], Average Loss: 0.46193563\n",
      "Epoch [2400/5000], Average Loss: 0.45813530\n",
      "Epoch [2500/5000], Average Loss: 0.45556046\n",
      "Epoch [2600/5000], Average Loss: 0.45165878\n",
      "Epoch [2700/5000], Average Loss: 0.44813311\n",
      "Epoch [2800/5000], Average Loss: 0.44543649\n",
      "Epoch [2900/5000], Average Loss: 0.44333826\n",
      "Epoch [3000/5000], Average Loss: 0.43991198\n",
      "Epoch [3100/5000], Average Loss: 0.43707890\n",
      "Epoch [3200/5000], Average Loss: 0.43363962\n",
      "Epoch [3300/5000], Average Loss: 0.43201590\n",
      "Epoch [3400/5000], Average Loss: 0.43269601\n",
      "Epoch [3500/5000], Average Loss: 0.42663610\n",
      "Epoch [3600/5000], Average Loss: 0.42464265\n",
      "Epoch [3700/5000], Average Loss: 0.42174021\n",
      "Epoch [3800/5000], Average Loss: 0.41981355\n",
      "Epoch [3900/5000], Average Loss: 0.41784976\n",
      "Epoch [4000/5000], Average Loss: 0.41428687\n",
      "Epoch [4100/5000], Average Loss: 0.41184677\n",
      "Epoch [4200/5000], Average Loss: 0.40903022\n",
      "Epoch [4300/5000], Average Loss: 0.40882452\n",
      "Epoch [4400/5000], Average Loss: 0.40504683\n",
      "Epoch [4500/5000], Average Loss: 0.40375469\n",
      "Epoch [4600/5000], Average Loss: 0.40308278\n",
      "Epoch [4700/5000], Average Loss: 0.40176997\n",
      "Epoch [4800/5000], Average Loss: 0.39778255\n",
      "Epoch [4900/5000], Average Loss: 0.39941154\n",
      "Epoch [5000/5000], Average Loss: 0.39209815\n",
      "Test Accuracy: 0.7130\n",
      "Epoch [100/5000], Average Loss: 0.63282336\n",
      "Epoch [200/5000], Average Loss: 0.58851017\n",
      "Epoch [300/5000], Average Loss: 0.56556782\n",
      "Epoch [400/5000], Average Loss: 0.55370885\n",
      "Epoch [500/5000], Average Loss: 0.54646780\n",
      "Epoch [600/5000], Average Loss: 0.54065186\n",
      "Epoch [700/5000], Average Loss: 0.53572532\n",
      "Epoch [800/5000], Average Loss: 0.53127623\n",
      "Epoch [900/5000], Average Loss: 0.52691277\n",
      "Epoch [1000/5000], Average Loss: 0.52286086\n",
      "Epoch [1100/5000], Average Loss: 0.51957184\n",
      "Epoch [1200/5000], Average Loss: 0.51684157\n",
      "Epoch [1300/5000], Average Loss: 0.51363461\n",
      "Epoch [1400/5000], Average Loss: 0.51026647\n",
      "Epoch [1500/5000], Average Loss: 0.50728012\n",
      "Epoch [1600/5000], Average Loss: 0.50488191\n",
      "Epoch [1700/5000], Average Loss: 0.50233126\n",
      "Epoch [1800/5000], Average Loss: 0.49969002\n",
      "Epoch [1900/5000], Average Loss: 0.49662695\n",
      "Epoch [2000/5000], Average Loss: 0.49399294\n",
      "Epoch [2100/5000], Average Loss: 0.49119001\n",
      "Epoch [2200/5000], Average Loss: 0.48877990\n",
      "Epoch [2300/5000], Average Loss: 0.48628701\n",
      "Epoch [2400/5000], Average Loss: 0.48404682\n",
      "Epoch [2500/5000], Average Loss: 0.48200763\n",
      "Epoch [2600/5000], Average Loss: 0.47970694\n",
      "Epoch [2700/5000], Average Loss: 0.47817871\n",
      "Epoch [2800/5000], Average Loss: 0.47596889\n",
      "Epoch [2900/5000], Average Loss: 0.47425194\n",
      "Epoch [3000/5000], Average Loss: 0.47176763\n",
      "Epoch [3100/5000], Average Loss: 0.47050779\n",
      "Epoch [3200/5000], Average Loss: 0.46887554\n",
      "Epoch [3300/5000], Average Loss: 0.46594837\n",
      "Epoch [3400/5000], Average Loss: 0.46435162\n",
      "Epoch [3500/5000], Average Loss: 0.46276119\n",
      "Epoch [3600/5000], Average Loss: 0.46099992\n",
      "Epoch [3700/5000], Average Loss: 0.45888659\n",
      "Epoch [3800/5000], Average Loss: 0.45776689\n",
      "Epoch [3900/5000], Average Loss: 0.45497120\n",
      "Epoch [4000/5000], Average Loss: 0.45254908\n",
      "Epoch [4100/5000], Average Loss: 0.45163595\n",
      "Epoch [4200/5000], Average Loss: 0.44961497\n",
      "Epoch [4300/5000], Average Loss: 0.44612156\n",
      "Epoch [4400/5000], Average Loss: 0.44387685\n",
      "Epoch [4500/5000], Average Loss: 0.44050978\n",
      "Epoch [4600/5000], Average Loss: 0.43703603\n",
      "Epoch [4700/5000], Average Loss: 0.43340536\n",
      "Epoch [4800/5000], Average Loss: 0.43046532\n",
      "Epoch [4900/5000], Average Loss: 0.42808508\n",
      "Epoch [5000/5000], Average Loss: 0.42490532\n",
      "Test Accuracy: 0.7177\n",
      "Epoch [100/5000], Average Loss: 0.63134553\n",
      "Epoch [200/5000], Average Loss: 0.58667389\n",
      "Epoch [300/5000], Average Loss: 0.56599345\n",
      "Epoch [400/5000], Average Loss: 0.55439616\n",
      "Epoch [500/5000], Average Loss: 0.54678118\n",
      "Epoch [600/5000], Average Loss: 0.54033346\n",
      "Epoch [700/5000], Average Loss: 0.53382625\n",
      "Epoch [800/5000], Average Loss: 0.52871532\n",
      "Epoch [900/5000], Average Loss: 0.52395527\n",
      "Epoch [1000/5000], Average Loss: 0.51943689\n",
      "Epoch [1100/5000], Average Loss: 0.51495917\n",
      "Epoch [1200/5000], Average Loss: 0.51100440\n",
      "Epoch [1300/5000], Average Loss: 0.50746301\n",
      "Epoch [1400/5000], Average Loss: 0.50292999\n",
      "Epoch [1500/5000], Average Loss: 0.50049297\n",
      "Epoch [1600/5000], Average Loss: 0.49702411\n",
      "Epoch [1700/5000], Average Loss: 0.49428743\n",
      "Epoch [1800/5000], Average Loss: 0.49196186\n",
      "Epoch [1900/5000], Average Loss: 0.48982758\n",
      "Epoch [2000/5000], Average Loss: 0.48759058\n",
      "Epoch [2100/5000], Average Loss: 0.48519963\n",
      "Epoch [2200/5000], Average Loss: 0.48299170\n",
      "Epoch [2300/5000], Average Loss: 0.48068690\n",
      "Epoch [2400/5000], Average Loss: 0.47915675\n",
      "Epoch [2500/5000], Average Loss: 0.47683221\n",
      "Epoch [2600/5000], Average Loss: 0.47459557\n",
      "Epoch [2700/5000], Average Loss: 0.47274912\n",
      "Epoch [2800/5000], Average Loss: 0.47061463\n",
      "Epoch [2900/5000], Average Loss: 0.46867902\n",
      "Epoch [3000/5000], Average Loss: 0.46691269\n",
      "Epoch [3100/5000], Average Loss: 0.46426154\n",
      "Epoch [3200/5000], Average Loss: 0.46258988\n",
      "Epoch [3300/5000], Average Loss: 0.45994931\n",
      "Epoch [3400/5000], Average Loss: 0.45696902\n",
      "Epoch [3500/5000], Average Loss: 0.45558023\n",
      "Epoch [3600/5000], Average Loss: 0.45330951\n",
      "Epoch [3700/5000], Average Loss: 0.45098684\n",
      "Epoch [3800/5000], Average Loss: 0.44793579\n",
      "Epoch [3900/5000], Average Loss: 0.44619022\n",
      "Epoch [4000/5000], Average Loss: 0.44360465\n",
      "Epoch [4100/5000], Average Loss: 0.44121968\n",
      "Epoch [4200/5000], Average Loss: 0.43925708\n",
      "Epoch [4300/5000], Average Loss: 0.43671777\n",
      "Epoch [4400/5000], Average Loss: 0.43610711\n",
      "Epoch [4500/5000], Average Loss: 0.43703330\n",
      "Epoch [4600/5000], Average Loss: 0.43380243\n",
      "Epoch [4700/5000], Average Loss: 0.43229954\n",
      "Epoch [4800/5000], Average Loss: 0.43076003\n",
      "Epoch [4900/5000], Average Loss: 0.42844469\n",
      "Epoch [5000/5000], Average Loss: 0.42715365\n",
      "Test Accuracy: 0.7252\n",
      "Epoch [100/5000], Average Loss: 0.64049555\n",
      "Epoch [200/5000], Average Loss: 0.60078228\n",
      "Epoch [300/5000], Average Loss: 0.57017796\n",
      "Epoch [400/5000], Average Loss: 0.55673489\n",
      "Epoch [500/5000], Average Loss: 0.54831836\n",
      "Epoch [600/5000], Average Loss: 0.54178039\n",
      "Epoch [700/5000], Average Loss: 0.53707579\n",
      "Epoch [800/5000], Average Loss: 0.53291422\n",
      "Epoch [900/5000], Average Loss: 0.52864282\n",
      "Epoch [1000/5000], Average Loss: 0.52452140\n",
      "Epoch [1100/5000], Average Loss: 0.52035442\n",
      "Epoch [1200/5000], Average Loss: 0.51611317\n",
      "Epoch [1300/5000], Average Loss: 0.51183020\n",
      "Epoch [1400/5000], Average Loss: 0.50757384\n",
      "Epoch [1500/5000], Average Loss: 0.50475840\n",
      "Epoch [1600/5000], Average Loss: 0.50130082\n",
      "Epoch [1700/5000], Average Loss: 0.49653054\n",
      "Epoch [1800/5000], Average Loss: 0.49363557\n",
      "Epoch [1900/5000], Average Loss: 0.48965582\n",
      "Epoch [2000/5000], Average Loss: 0.48724187\n",
      "Epoch [2100/5000], Average Loss: 0.48417281\n",
      "Epoch [2200/5000], Average Loss: 0.48177609\n",
      "Epoch [2300/5000], Average Loss: 0.47811485\n",
      "Epoch [2400/5000], Average Loss: 0.47553938\n",
      "Epoch [2500/5000], Average Loss: 0.47388110\n",
      "Epoch [2600/5000], Average Loss: 0.47026361\n",
      "Epoch [2700/5000], Average Loss: 0.46869278\n",
      "Epoch [2800/5000], Average Loss: 0.46582744\n",
      "Epoch [2900/5000], Average Loss: 0.46312880\n",
      "Epoch [3000/5000], Average Loss: 0.45962739\n",
      "Epoch [3100/5000], Average Loss: 0.45826221\n",
      "Epoch [3200/5000], Average Loss: 0.45616784\n",
      "Epoch [3300/5000], Average Loss: 0.45272029\n",
      "Epoch [3400/5000], Average Loss: 0.45186429\n",
      "Epoch [3500/5000], Average Loss: 0.45046687\n",
      "Epoch [3600/5000], Average Loss: 0.44635677\n",
      "Epoch [3700/5000], Average Loss: 0.44456799\n",
      "Epoch [3800/5000], Average Loss: 0.44040389\n",
      "Epoch [3900/5000], Average Loss: 0.43737925\n",
      "Epoch [4000/5000], Average Loss: 0.43659967\n",
      "Epoch [4100/5000], Average Loss: 0.43239150\n",
      "Epoch [4200/5000], Average Loss: 0.43044469\n",
      "Epoch [4300/5000], Average Loss: 0.43058562\n",
      "Epoch [4400/5000], Average Loss: 0.42617688\n",
      "Epoch [4500/5000], Average Loss: 0.42383883\n",
      "Epoch [4600/5000], Average Loss: 0.42099571\n",
      "Epoch [4700/5000], Average Loss: 0.41935259\n",
      "Epoch [4800/5000], Average Loss: 0.41673338\n",
      "Epoch [4900/5000], Average Loss: 0.41672345\n",
      "Epoch [5000/5000], Average Loss: 0.41260721\n",
      "Test Accuracy: 0.7197\n",
      "Epoch [100/5000], Average Loss: 0.63803666\n",
      "Epoch [200/5000], Average Loss: 0.59681575\n",
      "Epoch [300/5000], Average Loss: 0.57365842\n",
      "Epoch [400/5000], Average Loss: 0.56303511\n",
      "Epoch [500/5000], Average Loss: 0.55601394\n",
      "Epoch [600/5000], Average Loss: 0.55050851\n",
      "Epoch [700/5000], Average Loss: 0.54586862\n",
      "Epoch [800/5000], Average Loss: 0.54181163\n",
      "Epoch [900/5000], Average Loss: 0.53805149\n",
      "Epoch [1000/5000], Average Loss: 0.53391409\n",
      "Epoch [1100/5000], Average Loss: 0.53107864\n",
      "Epoch [1200/5000], Average Loss: 0.52778078\n",
      "Epoch [1300/5000], Average Loss: 0.52519649\n",
      "Epoch [1400/5000], Average Loss: 0.52179804\n",
      "Epoch [1500/5000], Average Loss: 0.51831336\n",
      "Epoch [1600/5000], Average Loss: 0.51555793\n",
      "Epoch [1700/5000], Average Loss: 0.51232071\n",
      "Epoch [1800/5000], Average Loss: 0.50995568\n",
      "Epoch [1900/5000], Average Loss: 0.50766089\n",
      "Epoch [2000/5000], Average Loss: 0.50437623\n",
      "Epoch [2100/5000], Average Loss: 0.50196685\n",
      "Epoch [2200/5000], Average Loss: 0.49942782\n",
      "Epoch [2300/5000], Average Loss: 0.49780776\n",
      "Epoch [2400/5000], Average Loss: 0.49522176\n",
      "Epoch [2500/5000], Average Loss: 0.49190493\n",
      "Epoch [2600/5000], Average Loss: 0.48958364\n",
      "Epoch [2700/5000], Average Loss: 0.48861776\n",
      "Epoch [2800/5000], Average Loss: 0.48488987\n",
      "Epoch [2900/5000], Average Loss: 0.48286860\n",
      "Epoch [3000/5000], Average Loss: 0.48083660\n",
      "Epoch [3100/5000], Average Loss: 0.47964362\n",
      "Epoch [3200/5000], Average Loss: 0.47726815\n",
      "Epoch [3300/5000], Average Loss: 0.47447399\n",
      "Epoch [3400/5000], Average Loss: 0.47152243\n",
      "Epoch [3500/5000], Average Loss: 0.46958733\n",
      "Epoch [3600/5000], Average Loss: 0.46685160\n",
      "Epoch [3700/5000], Average Loss: 0.46356195\n",
      "Epoch [3800/5000], Average Loss: 0.46029279\n",
      "Epoch [3900/5000], Average Loss: 0.45681816\n",
      "Epoch [4000/5000], Average Loss: 0.45424647\n",
      "Epoch [4100/5000], Average Loss: 0.45196586\n",
      "Epoch [4200/5000], Average Loss: 0.44875414\n",
      "Epoch [4300/5000], Average Loss: 0.44570969\n",
      "Epoch [4400/5000], Average Loss: 0.44427350\n",
      "Epoch [4500/5000], Average Loss: 0.44196979\n",
      "Epoch [4600/5000], Average Loss: 0.43918501\n",
      "Epoch [4700/5000], Average Loss: 0.43794392\n",
      "Epoch [4800/5000], Average Loss: 0.43591814\n",
      "Epoch [4900/5000], Average Loss: 0.43368868\n",
      "Epoch [5000/5000], Average Loss: 0.43149883\n",
      "Test Accuracy: 0.7043\n",
      "Epoch [100/5000], Average Loss: 0.64340464\n",
      "Epoch [200/5000], Average Loss: 0.60589644\n",
      "Epoch [300/5000], Average Loss: 0.57895575\n",
      "Epoch [400/5000], Average Loss: 0.56424950\n",
      "Epoch [500/5000], Average Loss: 0.55394993\n",
      "Epoch [600/5000], Average Loss: 0.54586575\n",
      "Epoch [700/5000], Average Loss: 0.53897239\n",
      "Epoch [800/5000], Average Loss: 0.53335251\n",
      "Epoch [900/5000], Average Loss: 0.52845176\n",
      "Epoch [1000/5000], Average Loss: 0.52360136\n",
      "Epoch [1100/5000], Average Loss: 0.51954248\n",
      "Epoch [1200/5000], Average Loss: 0.51464890\n",
      "Epoch [1300/5000], Average Loss: 0.51058729\n",
      "Epoch [1400/5000], Average Loss: 0.50641075\n",
      "Epoch [1500/5000], Average Loss: 0.50243979\n",
      "Epoch [1600/5000], Average Loss: 0.49924868\n",
      "Epoch [1700/5000], Average Loss: 0.49632965\n",
      "Epoch [1800/5000], Average Loss: 0.49297966\n",
      "Epoch [1900/5000], Average Loss: 0.49006559\n",
      "Epoch [2000/5000], Average Loss: 0.48767584\n",
      "Epoch [2100/5000], Average Loss: 0.48431242\n",
      "Epoch [2200/5000], Average Loss: 0.48169308\n",
      "Epoch [2300/5000], Average Loss: 0.47840716\n",
      "Epoch [2400/5000], Average Loss: 0.47581212\n",
      "Epoch [2500/5000], Average Loss: 0.47293436\n",
      "Epoch [2600/5000], Average Loss: 0.47031934\n",
      "Epoch [2700/5000], Average Loss: 0.46744127\n",
      "Epoch [2800/5000], Average Loss: 0.46342415\n",
      "Epoch [2900/5000], Average Loss: 0.45948757\n",
      "Epoch [3000/5000], Average Loss: 0.45593064\n",
      "Epoch [3100/5000], Average Loss: 0.45343767\n",
      "Epoch [3200/5000], Average Loss: 0.44974666\n",
      "Epoch [3300/5000], Average Loss: 0.44725815\n",
      "Epoch [3400/5000], Average Loss: 0.44481566\n",
      "Epoch [3500/5000], Average Loss: 0.44136349\n",
      "Epoch [3600/5000], Average Loss: 0.43807733\n",
      "Epoch [3700/5000], Average Loss: 0.43563408\n",
      "Epoch [3800/5000], Average Loss: 0.43160021\n",
      "Epoch [3900/5000], Average Loss: 0.42941748\n",
      "Epoch [4000/5000], Average Loss: 0.42743857\n",
      "Epoch [4100/5000], Average Loss: 0.42489312\n",
      "Epoch [4200/5000], Average Loss: 0.42187288\n",
      "Epoch [4300/5000], Average Loss: 0.41933897\n",
      "Epoch [4400/5000], Average Loss: 0.41718631\n",
      "Epoch [4500/5000], Average Loss: 0.41439058\n",
      "Epoch [4600/5000], Average Loss: 0.41265333\n",
      "Epoch [4700/5000], Average Loss: 0.41058183\n",
      "Epoch [4800/5000], Average Loss: 0.40825185\n",
      "Epoch [4900/5000], Average Loss: 0.40593491\n",
      "Epoch [5000/5000], Average Loss: 0.40308944\n",
      "Test Accuracy: 0.7275\n",
      "Epoch [100/5000], Average Loss: 0.64255807\n",
      "Epoch [200/5000], Average Loss: 0.60616683\n",
      "Epoch [300/5000], Average Loss: 0.58277569\n",
      "Epoch [400/5000], Average Loss: 0.56857400\n",
      "Epoch [500/5000], Average Loss: 0.55794728\n",
      "Epoch [600/5000], Average Loss: 0.54953263\n",
      "Epoch [700/5000], Average Loss: 0.54290767\n",
      "Epoch [800/5000], Average Loss: 0.53734046\n",
      "Epoch [900/5000], Average Loss: 0.53226838\n",
      "Epoch [1000/5000], Average Loss: 0.52760679\n",
      "Epoch [1100/5000], Average Loss: 0.52352483\n",
      "Epoch [1200/5000], Average Loss: 0.51975185\n",
      "Epoch [1300/5000], Average Loss: 0.51596080\n",
      "Epoch [1400/5000], Average Loss: 0.51264027\n",
      "Epoch [1500/5000], Average Loss: 0.50905536\n",
      "Epoch [1600/5000], Average Loss: 0.50636529\n",
      "Epoch [1700/5000], Average Loss: 0.50345286\n",
      "Epoch [1800/5000], Average Loss: 0.50078462\n",
      "Epoch [1900/5000], Average Loss: 0.49831644\n",
      "Epoch [2000/5000], Average Loss: 0.49591832\n",
      "Epoch [2100/5000], Average Loss: 0.49341986\n",
      "Epoch [2200/5000], Average Loss: 0.49104216\n",
      "Epoch [2300/5000], Average Loss: 0.48849649\n",
      "Epoch [2400/5000], Average Loss: 0.48640128\n",
      "Epoch [2500/5000], Average Loss: 0.48418737\n",
      "Epoch [2600/5000], Average Loss: 0.48177924\n",
      "Epoch [2700/5000], Average Loss: 0.47897019\n",
      "Epoch [2800/5000], Average Loss: 0.47724381\n",
      "Epoch [2900/5000], Average Loss: 0.47501603\n",
      "Epoch [3000/5000], Average Loss: 0.47325002\n",
      "Epoch [3100/5000], Average Loss: 0.47098766\n",
      "Epoch [3200/5000], Average Loss: 0.46898147\n",
      "Epoch [3300/5000], Average Loss: 0.46752795\n",
      "Epoch [3400/5000], Average Loss: 0.46529114\n",
      "Epoch [3500/5000], Average Loss: 0.46308793\n",
      "Epoch [3600/5000], Average Loss: 0.46090108\n",
      "Epoch [3700/5000], Average Loss: 0.46002331\n",
      "Epoch [3800/5000], Average Loss: 0.45774071\n",
      "Epoch [3900/5000], Average Loss: 0.45600837\n",
      "Epoch [4000/5000], Average Loss: 0.45327121\n",
      "Epoch [4100/5000], Average Loss: 0.45106649\n",
      "Epoch [4200/5000], Average Loss: 0.45071933\n",
      "Epoch [4300/5000], Average Loss: 0.44814697\n",
      "Epoch [4400/5000], Average Loss: 0.44715885\n",
      "Epoch [4500/5000], Average Loss: 0.44606993\n",
      "Epoch [4600/5000], Average Loss: 0.44415511\n",
      "Epoch [4700/5000], Average Loss: 0.44316251\n",
      "Epoch [4800/5000], Average Loss: 0.44075263\n",
      "Epoch [4900/5000], Average Loss: 0.43951959\n",
      "Epoch [5000/5000], Average Loss: 0.43928141\n",
      "Test Accuracy: 0.7192\n",
      "Epoch [100/5000], Average Loss: 0.64255383\n",
      "Epoch [200/5000], Average Loss: 0.60690373\n",
      "Epoch [300/5000], Average Loss: 0.58682305\n",
      "Epoch [400/5000], Average Loss: 0.57301518\n",
      "Epoch [500/5000], Average Loss: 0.56384797\n",
      "Epoch [600/5000], Average Loss: 0.55669940\n",
      "Epoch [700/5000], Average Loss: 0.55092775\n",
      "Epoch [800/5000], Average Loss: 0.54634481\n",
      "Epoch [900/5000], Average Loss: 0.54159685\n",
      "Epoch [1000/5000], Average Loss: 0.53726144\n",
      "Epoch [1100/5000], Average Loss: 0.53321014\n",
      "Epoch [1200/5000], Average Loss: 0.52888744\n",
      "Epoch [1300/5000], Average Loss: 0.52530301\n",
      "Epoch [1400/5000], Average Loss: 0.52188460\n",
      "Epoch [1500/5000], Average Loss: 0.51917826\n",
      "Epoch [1600/5000], Average Loss: 0.51586101\n",
      "Epoch [1700/5000], Average Loss: 0.51296864\n",
      "Epoch [1800/5000], Average Loss: 0.51016902\n",
      "Epoch [1900/5000], Average Loss: 0.50703942\n",
      "Epoch [2000/5000], Average Loss: 0.50436304\n",
      "Epoch [2100/5000], Average Loss: 0.50175669\n",
      "Epoch [2200/5000], Average Loss: 0.49974181\n",
      "Epoch [2300/5000], Average Loss: 0.49731120\n",
      "Epoch [2400/5000], Average Loss: 0.49501947\n",
      "Epoch [2500/5000], Average Loss: 0.49321967\n",
      "Epoch [2600/5000], Average Loss: 0.49120722\n",
      "Epoch [2700/5000], Average Loss: 0.48910931\n",
      "Epoch [2800/5000], Average Loss: 0.48783350\n",
      "Epoch [2900/5000], Average Loss: 0.48603331\n",
      "Epoch [3000/5000], Average Loss: 0.48455677\n",
      "Epoch [3100/5000], Average Loss: 0.48247948\n",
      "Epoch [3200/5000], Average Loss: 0.48085226\n",
      "Epoch [3300/5000], Average Loss: 0.48019135\n",
      "Epoch [3400/5000], Average Loss: 0.47857732\n",
      "Epoch [3500/5000], Average Loss: 0.47701564\n",
      "Epoch [3600/5000], Average Loss: 0.47575617\n",
      "Epoch [3700/5000], Average Loss: 0.47366938\n",
      "Epoch [3800/5000], Average Loss: 0.47304637\n",
      "Epoch [3900/5000], Average Loss: 0.47166850\n",
      "Epoch [4000/5000], Average Loss: 0.47010570\n",
      "Epoch [4100/5000], Average Loss: 0.46883612\n",
      "Epoch [4200/5000], Average Loss: 0.46726584\n",
      "Epoch [4300/5000], Average Loss: 0.46644926\n",
      "Epoch [4400/5000], Average Loss: 0.46539859\n",
      "Epoch [4500/5000], Average Loss: 0.46376815\n",
      "Epoch [4600/5000], Average Loss: 0.46290106\n",
      "Epoch [4700/5000], Average Loss: 0.46175395\n",
      "Epoch [4800/5000], Average Loss: 0.46026715\n",
      "Epoch [4900/5000], Average Loss: 0.45934245\n",
      "Epoch [5000/5000], Average Loss: 0.45918083\n",
      "Test Accuracy: 0.7102\n",
      "Epoch [100/5000], Average Loss: 0.63527257\n",
      "Epoch [200/5000], Average Loss: 0.60173110\n",
      "Epoch [300/5000], Average Loss: 0.57285347\n",
      "Epoch [400/5000], Average Loss: 0.55659031\n",
      "Epoch [500/5000], Average Loss: 0.54648366\n",
      "Epoch [600/5000], Average Loss: 0.53947084\n",
      "Epoch [700/5000], Average Loss: 0.53421310\n",
      "Epoch [800/5000], Average Loss: 0.52975861\n",
      "Epoch [900/5000], Average Loss: 0.52520878\n",
      "Epoch [1000/5000], Average Loss: 0.51994280\n",
      "Epoch [1100/5000], Average Loss: 0.51490092\n",
      "Epoch [1200/5000], Average Loss: 0.50985272\n",
      "Epoch [1300/5000], Average Loss: 0.50429506\n",
      "Epoch [1400/5000], Average Loss: 0.49967636\n",
      "Epoch [1500/5000], Average Loss: 0.49548907\n",
      "Epoch [1600/5000], Average Loss: 0.49208750\n",
      "Epoch [1700/5000], Average Loss: 0.48672111\n",
      "Epoch [1800/5000], Average Loss: 0.48303301\n",
      "Epoch [1900/5000], Average Loss: 0.47862898\n",
      "Epoch [2000/5000], Average Loss: 0.47567932\n",
      "Epoch [2100/5000], Average Loss: 0.47142746\n",
      "Epoch [2200/5000], Average Loss: 0.46832628\n",
      "Epoch [2300/5000], Average Loss: 0.46469718\n",
      "Epoch [2400/5000], Average Loss: 0.46227629\n",
      "Epoch [2500/5000], Average Loss: 0.45894431\n",
      "Epoch [2600/5000], Average Loss: 0.45569886\n",
      "Epoch [2700/5000], Average Loss: 0.45404165\n",
      "Epoch [2800/5000], Average Loss: 0.45142595\n",
      "Epoch [2900/5000], Average Loss: 0.44925921\n",
      "Epoch [3000/5000], Average Loss: 0.44668293\n",
      "Epoch [3100/5000], Average Loss: 0.44328793\n",
      "Epoch [3200/5000], Average Loss: 0.44130775\n",
      "Epoch [3300/5000], Average Loss: 0.44032254\n",
      "Epoch [3400/5000], Average Loss: 0.43681342\n",
      "Epoch [3500/5000], Average Loss: 0.43442595\n",
      "Epoch [3600/5000], Average Loss: 0.43260635\n",
      "Epoch [3700/5000], Average Loss: 0.43055448\n",
      "Epoch [3800/5000], Average Loss: 0.43011038\n",
      "Epoch [3900/5000], Average Loss: 0.42763629\n",
      "Epoch [4000/5000], Average Loss: 0.42540369\n",
      "Epoch [4100/5000], Average Loss: 0.42244734\n",
      "Epoch [4200/5000], Average Loss: 0.42020838\n",
      "Epoch [4300/5000], Average Loss: 0.41806925\n",
      "Epoch [4400/5000], Average Loss: 0.41693955\n",
      "Epoch [4500/5000], Average Loss: 0.41304022\n",
      "Epoch [4600/5000], Average Loss: 0.40995378\n",
      "Epoch [4700/5000], Average Loss: 0.40811759\n",
      "Epoch [4800/5000], Average Loss: 0.40595766\n",
      "Epoch [4900/5000], Average Loss: 0.40338351\n",
      "Epoch [5000/5000], Average Loss: 0.39926386\n",
      "Test Accuracy: 0.7075\n",
      "Epoch [100/5000], Average Loss: 0.63065233\n",
      "Epoch [200/5000], Average Loss: 0.59444572\n",
      "Epoch [300/5000], Average Loss: 0.56828860\n",
      "Epoch [400/5000], Average Loss: 0.55585802\n",
      "Epoch [500/5000], Average Loss: 0.54627260\n",
      "Epoch [600/5000], Average Loss: 0.53784352\n",
      "Epoch [700/5000], Average Loss: 0.53075147\n",
      "Epoch [800/5000], Average Loss: 0.52380602\n",
      "Epoch [900/5000], Average Loss: 0.51765981\n",
      "Epoch [1000/5000], Average Loss: 0.51258960\n",
      "Epoch [1100/5000], Average Loss: 0.50825089\n",
      "Epoch [1200/5000], Average Loss: 0.50335415\n",
      "Epoch [1300/5000], Average Loss: 0.50002206\n",
      "Epoch [1400/5000], Average Loss: 0.49597555\n",
      "Epoch [1500/5000], Average Loss: 0.49328068\n",
      "Epoch [1600/5000], Average Loss: 0.48931344\n",
      "Epoch [1700/5000], Average Loss: 0.48512398\n",
      "Epoch [1800/5000], Average Loss: 0.48170432\n",
      "Epoch [1900/5000], Average Loss: 0.47802703\n",
      "Epoch [2000/5000], Average Loss: 0.47401225\n",
      "Epoch [2100/5000], Average Loss: 0.46970794\n",
      "Epoch [2200/5000], Average Loss: 0.46529049\n",
      "Epoch [2300/5000], Average Loss: 0.46300240\n",
      "Epoch [2400/5000], Average Loss: 0.45893216\n",
      "Epoch [2500/5000], Average Loss: 0.45644359\n",
      "Epoch [2600/5000], Average Loss: 0.45281400\n",
      "Epoch [2700/5000], Average Loss: 0.45019770\n",
      "Epoch [2800/5000], Average Loss: 0.44684106\n",
      "Epoch [2900/5000], Average Loss: 0.44475293\n",
      "Epoch [3000/5000], Average Loss: 0.44253829\n",
      "Epoch [3100/5000], Average Loss: 0.43790833\n",
      "Epoch [3200/5000], Average Loss: 0.43603517\n",
      "Epoch [3300/5000], Average Loss: 0.43311814\n",
      "Epoch [3400/5000], Average Loss: 0.42993415\n",
      "Epoch [3500/5000], Average Loss: 0.42753170\n",
      "Epoch [3600/5000], Average Loss: 0.42481058\n",
      "Epoch [3700/5000], Average Loss: 0.42334525\n",
      "Epoch [3800/5000], Average Loss: 0.42105307\n",
      "Epoch [3900/5000], Average Loss: 0.41976081\n",
      "Epoch [4000/5000], Average Loss: 0.41633700\n",
      "Epoch [4100/5000], Average Loss: 0.41438654\n",
      "Epoch [4200/5000], Average Loss: 0.41409545\n",
      "Epoch [4300/5000], Average Loss: 0.41185512\n",
      "Epoch [4400/5000], Average Loss: 0.40956798\n",
      "Epoch [4500/5000], Average Loss: 0.40797175\n",
      "Epoch [4600/5000], Average Loss: 0.40426139\n",
      "Epoch [4700/5000], Average Loss: 0.40354376\n",
      "Epoch [4800/5000], Average Loss: 0.40205434\n",
      "Epoch [4900/5000], Average Loss: 0.39844324\n",
      "Epoch [5000/5000], Average Loss: 0.39629585\n",
      "Test Accuracy: 0.7090\n",
      "Epoch [100/5000], Average Loss: 0.63308477\n",
      "Epoch [200/5000], Average Loss: 0.59732581\n",
      "Epoch [300/5000], Average Loss: 0.57084013\n",
      "Epoch [400/5000], Average Loss: 0.55918497\n",
      "Epoch [500/5000], Average Loss: 0.54993223\n",
      "Epoch [600/5000], Average Loss: 0.54148361\n",
      "Epoch [700/5000], Average Loss: 0.53387031\n",
      "Epoch [800/5000], Average Loss: 0.52655569\n",
      "Epoch [900/5000], Average Loss: 0.51946945\n",
      "Epoch [1000/5000], Average Loss: 0.51167901\n",
      "Epoch [1100/5000], Average Loss: 0.50589075\n",
      "Epoch [1200/5000], Average Loss: 0.50000232\n",
      "Epoch [1300/5000], Average Loss: 0.49540158\n",
      "Epoch [1400/5000], Average Loss: 0.49059584\n",
      "Epoch [1500/5000], Average Loss: 0.48621733\n",
      "Epoch [1600/5000], Average Loss: 0.48186518\n",
      "Epoch [1700/5000], Average Loss: 0.47852575\n",
      "Epoch [1800/5000], Average Loss: 0.47454966\n",
      "Epoch [1900/5000], Average Loss: 0.47176656\n",
      "Epoch [2000/5000], Average Loss: 0.46868788\n",
      "Epoch [2100/5000], Average Loss: 0.46579018\n",
      "Epoch [2200/5000], Average Loss: 0.46356173\n",
      "Epoch [2300/5000], Average Loss: 0.45925348\n",
      "Epoch [2400/5000], Average Loss: 0.45718616\n",
      "Epoch [2500/5000], Average Loss: 0.45483377\n",
      "Epoch [2600/5000], Average Loss: 0.45330568\n",
      "Epoch [2700/5000], Average Loss: 0.45171900\n",
      "Epoch [2800/5000], Average Loss: 0.44818060\n",
      "Epoch [2900/5000], Average Loss: 0.44546770\n",
      "Epoch [3000/5000], Average Loss: 0.44369428\n",
      "Epoch [3100/5000], Average Loss: 0.44048572\n",
      "Epoch [3200/5000], Average Loss: 0.43829630\n",
      "Epoch [3300/5000], Average Loss: 0.43607851\n",
      "Epoch [3400/5000], Average Loss: 0.43482117\n",
      "Epoch [3500/5000], Average Loss: 0.43260072\n",
      "Epoch [3600/5000], Average Loss: 0.43051671\n",
      "Epoch [3700/5000], Average Loss: 0.42917822\n",
      "Epoch [3800/5000], Average Loss: 0.42684135\n",
      "Epoch [3900/5000], Average Loss: 0.42370327\n",
      "Epoch [4000/5000], Average Loss: 0.42248386\n",
      "Epoch [4100/5000], Average Loss: 0.42205462\n",
      "Epoch [4200/5000], Average Loss: 0.41864196\n",
      "Epoch [4300/5000], Average Loss: 0.41676861\n",
      "Epoch [4400/5000], Average Loss: 0.41563340\n",
      "Epoch [4500/5000], Average Loss: 0.41446875\n",
      "Epoch [4600/5000], Average Loss: 0.41175619\n",
      "Epoch [4700/5000], Average Loss: 0.41065601\n",
      "Epoch [4800/5000], Average Loss: 0.40851957\n",
      "Epoch [4900/5000], Average Loss: 0.40758721\n",
      "Epoch [5000/5000], Average Loss: 0.40668944\n",
      "Test Accuracy: 0.6977\n",
      "Epoch [100/5000], Average Loss: 0.64368002\n",
      "Epoch [200/5000], Average Loss: 0.61532254\n",
      "Epoch [300/5000], Average Loss: 0.59189614\n",
      "Epoch [400/5000], Average Loss: 0.57611534\n",
      "Epoch [500/5000], Average Loss: 0.56420788\n",
      "Epoch [600/5000], Average Loss: 0.55505218\n",
      "Epoch [700/5000], Average Loss: 0.54800915\n",
      "Epoch [800/5000], Average Loss: 0.54141908\n",
      "Epoch [900/5000], Average Loss: 0.53612902\n",
      "Epoch [1000/5000], Average Loss: 0.53083515\n",
      "Epoch [1100/5000], Average Loss: 0.52526139\n",
      "Epoch [1200/5000], Average Loss: 0.52080733\n",
      "Epoch [1300/5000], Average Loss: 0.51795157\n",
      "Epoch [1400/5000], Average Loss: 0.51363160\n",
      "Epoch [1500/5000], Average Loss: 0.50919156\n",
      "Epoch [1600/5000], Average Loss: 0.50580635\n",
      "Epoch [1700/5000], Average Loss: 0.50189214\n",
      "Epoch [1800/5000], Average Loss: 0.49849897\n",
      "Epoch [1900/5000], Average Loss: 0.49516946\n",
      "Epoch [2000/5000], Average Loss: 0.49255448\n",
      "Epoch [2100/5000], Average Loss: 0.48814019\n",
      "Epoch [2200/5000], Average Loss: 0.48509360\n",
      "Epoch [2300/5000], Average Loss: 0.48175050\n",
      "Epoch [2400/5000], Average Loss: 0.47966628\n",
      "Epoch [2500/5000], Average Loss: 0.47872745\n",
      "Epoch [2600/5000], Average Loss: 0.47557813\n",
      "Epoch [2700/5000], Average Loss: 0.47289878\n",
      "Epoch [2800/5000], Average Loss: 0.47040984\n",
      "Epoch [2900/5000], Average Loss: 0.46729073\n",
      "Epoch [3000/5000], Average Loss: 0.46449119\n",
      "Epoch [3100/5000], Average Loss: 0.46153484\n",
      "Epoch [3200/5000], Average Loss: 0.45668360\n",
      "Epoch [3300/5000], Average Loss: 0.45361187\n",
      "Epoch [3400/5000], Average Loss: 0.45051456\n",
      "Epoch [3500/5000], Average Loss: 0.44771245\n",
      "Epoch [3600/5000], Average Loss: 0.44419011\n",
      "Epoch [3700/5000], Average Loss: 0.44014110\n",
      "Epoch [3800/5000], Average Loss: 0.43708866\n",
      "Epoch [3900/5000], Average Loss: 0.43541771\n",
      "Epoch [4000/5000], Average Loss: 0.43377501\n",
      "Epoch [4100/5000], Average Loss: 0.42817548\n",
      "Epoch [4200/5000], Average Loss: 0.42677655\n",
      "Epoch [4300/5000], Average Loss: 0.42286472\n",
      "Epoch [4400/5000], Average Loss: 0.42010465\n",
      "Epoch [4500/5000], Average Loss: 0.41950759\n",
      "Epoch [4600/5000], Average Loss: 0.41484967\n",
      "Epoch [4700/5000], Average Loss: 0.41315691\n",
      "Epoch [4800/5000], Average Loss: 0.41052557\n",
      "Epoch [4900/5000], Average Loss: 0.40762184\n",
      "Epoch [5000/5000], Average Loss: 0.40530314\n",
      "Test Accuracy: 0.7087\n",
      "Epoch [100/5000], Average Loss: 0.64410094\n",
      "Epoch [200/5000], Average Loss: 0.61465767\n",
      "Epoch [300/5000], Average Loss: 0.58721042\n",
      "Epoch [400/5000], Average Loss: 0.57173982\n",
      "Epoch [500/5000], Average Loss: 0.56140344\n",
      "Epoch [600/5000], Average Loss: 0.55427062\n",
      "Epoch [700/5000], Average Loss: 0.54796444\n",
      "Epoch [800/5000], Average Loss: 0.54251259\n",
      "Epoch [900/5000], Average Loss: 0.53745498\n",
      "Epoch [1000/5000], Average Loss: 0.53246185\n",
      "Epoch [1100/5000], Average Loss: 0.52728083\n",
      "Epoch [1200/5000], Average Loss: 0.52245591\n",
      "Epoch [1300/5000], Average Loss: 0.51754213\n",
      "Epoch [1400/5000], Average Loss: 0.51305573\n",
      "Epoch [1500/5000], Average Loss: 0.50914430\n",
      "Epoch [1600/5000], Average Loss: 0.50565330\n",
      "Epoch [1700/5000], Average Loss: 0.50235918\n",
      "Epoch [1800/5000], Average Loss: 0.49845668\n",
      "Epoch [1900/5000], Average Loss: 0.49543657\n",
      "Epoch [2000/5000], Average Loss: 0.49237641\n",
      "Epoch [2100/5000], Average Loss: 0.48983901\n",
      "Epoch [2200/5000], Average Loss: 0.48632512\n",
      "Epoch [2300/5000], Average Loss: 0.48442320\n",
      "Epoch [2400/5000], Average Loss: 0.48180292\n",
      "Epoch [2500/5000], Average Loss: 0.47927873\n",
      "Epoch [2600/5000], Average Loss: 0.47686335\n",
      "Epoch [2700/5000], Average Loss: 0.47563643\n",
      "Epoch [2800/5000], Average Loss: 0.47319090\n",
      "Epoch [2900/5000], Average Loss: 0.47164534\n",
      "Epoch [3000/5000], Average Loss: 0.46958230\n",
      "Epoch [3100/5000], Average Loss: 0.46687012\n",
      "Epoch [3200/5000], Average Loss: 0.46534457\n",
      "Epoch [3300/5000], Average Loss: 0.46353817\n",
      "Epoch [3400/5000], Average Loss: 0.46178044\n",
      "Epoch [3500/5000], Average Loss: 0.45999549\n",
      "Epoch [3600/5000], Average Loss: 0.45953178\n",
      "Epoch [3700/5000], Average Loss: 0.45709062\n",
      "Epoch [3800/5000], Average Loss: 0.45606341\n",
      "Epoch [3900/5000], Average Loss: 0.45401084\n",
      "Epoch [4000/5000], Average Loss: 0.45405044\n",
      "Epoch [4100/5000], Average Loss: 0.45169714\n",
      "Epoch [4200/5000], Average Loss: 0.44941806\n",
      "Epoch [4300/5000], Average Loss: 0.44949734\n",
      "Epoch [4400/5000], Average Loss: 0.44671554\n",
      "Epoch [4500/5000], Average Loss: 0.44719078\n",
      "Epoch [4600/5000], Average Loss: 0.44427489\n",
      "Epoch [4700/5000], Average Loss: 0.44263854\n",
      "Epoch [4800/5000], Average Loss: 0.44209015\n",
      "Epoch [4900/5000], Average Loss: 0.44078923\n",
      "Epoch [5000/5000], Average Loss: 0.43994515\n",
      "Test Accuracy: 0.6994\n",
      "Epoch [100/5000], Average Loss: 0.64696311\n",
      "Epoch [200/5000], Average Loss: 0.62255687\n",
      "Epoch [300/5000], Average Loss: 0.59964179\n",
      "Epoch [400/5000], Average Loss: 0.58286868\n",
      "Epoch [500/5000], Average Loss: 0.57068154\n",
      "Epoch [600/5000], Average Loss: 0.56147464\n",
      "Epoch [700/5000], Average Loss: 0.55419145\n",
      "Epoch [800/5000], Average Loss: 0.54811982\n",
      "Epoch [900/5000], Average Loss: 0.54270058\n",
      "Epoch [1000/5000], Average Loss: 0.53827021\n",
      "Epoch [1100/5000], Average Loss: 0.53303112\n",
      "Epoch [1200/5000], Average Loss: 0.52883218\n",
      "Epoch [1300/5000], Average Loss: 0.52432733\n",
      "Epoch [1400/5000], Average Loss: 0.51990272\n",
      "Epoch [1500/5000], Average Loss: 0.51566721\n",
      "Epoch [1600/5000], Average Loss: 0.51113017\n",
      "Epoch [1700/5000], Average Loss: 0.50669462\n",
      "Epoch [1800/5000], Average Loss: 0.50069500\n",
      "Epoch [1900/5000], Average Loss: 0.49585941\n",
      "Epoch [2000/5000], Average Loss: 0.49132028\n",
      "Epoch [2100/5000], Average Loss: 0.48714664\n",
      "Epoch [2200/5000], Average Loss: 0.48399345\n",
      "Epoch [2300/5000], Average Loss: 0.48033388\n",
      "Epoch [2400/5000], Average Loss: 0.47672927\n",
      "Epoch [2500/5000], Average Loss: 0.47442904\n",
      "Epoch [2600/5000], Average Loss: 0.47159719\n",
      "Epoch [2700/5000], Average Loss: 0.46907440\n",
      "Epoch [2800/5000], Average Loss: 0.46594365\n",
      "Epoch [2900/5000], Average Loss: 0.46406446\n",
      "Epoch [3000/5000], Average Loss: 0.46203690\n",
      "Epoch [3100/5000], Average Loss: 0.45845813\n",
      "Epoch [3200/5000], Average Loss: 0.45775523\n",
      "Epoch [3300/5000], Average Loss: 0.45510985\n",
      "Epoch [3400/5000], Average Loss: 0.45370682\n",
      "Epoch [3500/5000], Average Loss: 0.45331081\n",
      "Epoch [3600/5000], Average Loss: 0.44893193\n",
      "Epoch [3700/5000], Average Loss: 0.44752722\n",
      "Epoch [3800/5000], Average Loss: 0.44463250\n",
      "Epoch [3900/5000], Average Loss: 0.44292022\n",
      "Epoch [4000/5000], Average Loss: 0.44239062\n",
      "Epoch [4100/5000], Average Loss: 0.43996308\n",
      "Epoch [4200/5000], Average Loss: 0.43911395\n",
      "Epoch [4300/5000], Average Loss: 0.43654876\n",
      "Epoch [4400/5000], Average Loss: 0.43496921\n",
      "Epoch [4500/5000], Average Loss: 0.43354100\n",
      "Epoch [4600/5000], Average Loss: 0.43012441\n",
      "Epoch [4700/5000], Average Loss: 0.42881978\n",
      "Epoch [4800/5000], Average Loss: 0.42844308\n",
      "Epoch [4900/5000], Average Loss: 0.42415820\n",
      "Epoch [5000/5000], Average Loss: 0.42554955\n",
      "Test Accuracy: 0.7067\n",
      "Epoch [100/5000], Average Loss: 0.65823681\n",
      "Epoch [200/5000], Average Loss: 0.62849315\n",
      "Epoch [300/5000], Average Loss: 0.60334940\n",
      "Epoch [400/5000], Average Loss: 0.58899079\n",
      "Epoch [500/5000], Average Loss: 0.57917450\n",
      "Epoch [600/5000], Average Loss: 0.57106048\n",
      "Epoch [700/5000], Average Loss: 0.56379748\n",
      "Epoch [800/5000], Average Loss: 0.55716905\n",
      "Epoch [900/5000], Average Loss: 0.55143403\n",
      "Epoch [1000/5000], Average Loss: 0.54585472\n",
      "Epoch [1100/5000], Average Loss: 0.54048676\n",
      "Epoch [1200/5000], Average Loss: 0.53562324\n",
      "Epoch [1300/5000], Average Loss: 0.53098312\n",
      "Epoch [1400/5000], Average Loss: 0.52645239\n",
      "Epoch [1500/5000], Average Loss: 0.52173909\n",
      "Epoch [1600/5000], Average Loss: 0.51762627\n",
      "Epoch [1700/5000], Average Loss: 0.51355286\n",
      "Epoch [1800/5000], Average Loss: 0.50974467\n",
      "Epoch [1900/5000], Average Loss: 0.50638535\n",
      "Epoch [2000/5000], Average Loss: 0.50101841\n",
      "Epoch [2100/5000], Average Loss: 0.49739976\n",
      "Epoch [2200/5000], Average Loss: 0.49363195\n",
      "Epoch [2300/5000], Average Loss: 0.48995705\n",
      "Epoch [2400/5000], Average Loss: 0.48642816\n",
      "Epoch [2500/5000], Average Loss: 0.48285964\n",
      "Epoch [2600/5000], Average Loss: 0.47864344\n",
      "Epoch [2700/5000], Average Loss: 0.47531787\n",
      "Epoch [2800/5000], Average Loss: 0.47228206\n",
      "Epoch [2900/5000], Average Loss: 0.46906815\n",
      "Epoch [3000/5000], Average Loss: 0.46681214\n",
      "Epoch [3100/5000], Average Loss: 0.46370091\n",
      "Epoch [3200/5000], Average Loss: 0.45935728\n",
      "Epoch [3300/5000], Average Loss: 0.45681919\n",
      "Epoch [3400/5000], Average Loss: 0.45371605\n",
      "Epoch [3500/5000], Average Loss: 0.45144141\n",
      "Epoch [3600/5000], Average Loss: 0.44812919\n",
      "Epoch [3700/5000], Average Loss: 0.44560613\n",
      "Epoch [3800/5000], Average Loss: 0.44359682\n",
      "Epoch [3900/5000], Average Loss: 0.44065633\n",
      "Epoch [4000/5000], Average Loss: 0.43795511\n",
      "Epoch [4100/5000], Average Loss: 0.43579223\n",
      "Epoch [4200/5000], Average Loss: 0.43431572\n",
      "Epoch [4300/5000], Average Loss: 0.43389366\n",
      "Epoch [4400/5000], Average Loss: 0.42895522\n",
      "Epoch [4500/5000], Average Loss: 0.42854609\n",
      "Epoch [4600/5000], Average Loss: 0.42515402\n",
      "Epoch [4700/5000], Average Loss: 0.42310304\n",
      "Epoch [4800/5000], Average Loss: 0.42118851\n",
      "Epoch [4900/5000], Average Loss: 0.41932985\n",
      "Epoch [5000/5000], Average Loss: 0.41919280\n",
      "Test Accuracy: 0.6982\n",
      "Epoch [100/5000], Average Loss: 0.65806823\n",
      "Epoch [200/5000], Average Loss: 0.62356859\n",
      "Epoch [300/5000], Average Loss: 0.60138492\n",
      "Epoch [400/5000], Average Loss: 0.58599760\n",
      "Epoch [500/5000], Average Loss: 0.57374701\n",
      "Epoch [600/5000], Average Loss: 0.56438189\n",
      "Epoch [700/5000], Average Loss: 0.55668800\n",
      "Epoch [800/5000], Average Loss: 0.54925006\n",
      "Epoch [900/5000], Average Loss: 0.54198751\n",
      "Epoch [1000/5000], Average Loss: 0.53532118\n",
      "Epoch [1100/5000], Average Loss: 0.52912942\n",
      "Epoch [1200/5000], Average Loss: 0.52295710\n",
      "Epoch [1300/5000], Average Loss: 0.51753270\n",
      "Epoch [1400/5000], Average Loss: 0.51263658\n",
      "Epoch [1500/5000], Average Loss: 0.50798009\n",
      "Epoch [1600/5000], Average Loss: 0.50233743\n",
      "Epoch [1700/5000], Average Loss: 0.49793429\n",
      "Epoch [1800/5000], Average Loss: 0.49365798\n",
      "Epoch [1900/5000], Average Loss: 0.49002066\n",
      "Epoch [2000/5000], Average Loss: 0.48704371\n",
      "Epoch [2100/5000], Average Loss: 0.48284317\n",
      "Epoch [2200/5000], Average Loss: 0.47949440\n",
      "Epoch [2300/5000], Average Loss: 0.47713681\n",
      "Epoch [2400/5000], Average Loss: 0.47406146\n",
      "Epoch [2500/5000], Average Loss: 0.47045161\n",
      "Epoch [2600/5000], Average Loss: 0.46832394\n",
      "Epoch [2700/5000], Average Loss: 0.46558579\n",
      "Epoch [2800/5000], Average Loss: 0.46294368\n",
      "Epoch [2900/5000], Average Loss: 0.46037491\n",
      "Epoch [3000/5000], Average Loss: 0.45653340\n",
      "Epoch [3100/5000], Average Loss: 0.45507821\n",
      "Epoch [3200/5000], Average Loss: 0.45122127\n",
      "Epoch [3300/5000], Average Loss: 0.44843118\n",
      "Epoch [3400/5000], Average Loss: 0.44609459\n",
      "Epoch [3500/5000], Average Loss: 0.44364586\n",
      "Epoch [3600/5000], Average Loss: 0.44093981\n",
      "Epoch [3700/5000], Average Loss: 0.43843206\n",
      "Epoch [3800/5000], Average Loss: 0.43645980\n",
      "Epoch [3900/5000], Average Loss: 0.43416117\n",
      "Epoch [4000/5000], Average Loss: 0.43178886\n",
      "Epoch [4100/5000], Average Loss: 0.42973161\n",
      "Epoch [4200/5000], Average Loss: 0.42718608\n",
      "Epoch [4300/5000], Average Loss: 0.42591730\n",
      "Epoch [4400/5000], Average Loss: 0.42251096\n",
      "Epoch [4500/5000], Average Loss: 0.42155573\n",
      "Epoch [4600/5000], Average Loss: 0.41888472\n",
      "Epoch [4700/5000], Average Loss: 0.41631108\n",
      "Epoch [4800/5000], Average Loss: 0.41431846\n",
      "Epoch [4900/5000], Average Loss: 0.41115170\n",
      "Epoch [5000/5000], Average Loss: 0.40898025\n",
      "Test Accuracy: 0.7151\n",
      "Epoch [100/5000], Average Loss: 0.65571770\n",
      "Epoch [200/5000], Average Loss: 0.63227762\n",
      "Epoch [300/5000], Average Loss: 0.60481558\n",
      "Epoch [400/5000], Average Loss: 0.58536859\n",
      "Epoch [500/5000], Average Loss: 0.57337720\n",
      "Epoch [600/5000], Average Loss: 0.56444842\n",
      "Epoch [700/5000], Average Loss: 0.55734770\n",
      "Epoch [800/5000], Average Loss: 0.55058177\n",
      "Epoch [900/5000], Average Loss: 0.54473955\n",
      "Epoch [1000/5000], Average Loss: 0.54020059\n",
      "Epoch [1100/5000], Average Loss: 0.53623859\n",
      "Epoch [1200/5000], Average Loss: 0.53102023\n",
      "Epoch [1300/5000], Average Loss: 0.52556870\n",
      "Epoch [1400/5000], Average Loss: 0.52116505\n",
      "Epoch [1500/5000], Average Loss: 0.51682665\n",
      "Epoch [1600/5000], Average Loss: 0.51209456\n",
      "Epoch [1700/5000], Average Loss: 0.50824284\n",
      "Epoch [1800/5000], Average Loss: 0.50461357\n",
      "Epoch [1900/5000], Average Loss: 0.49972924\n",
      "Epoch [2000/5000], Average Loss: 0.49715884\n",
      "Epoch [2100/5000], Average Loss: 0.49309299\n",
      "Epoch [2200/5000], Average Loss: 0.49025239\n",
      "Epoch [2300/5000], Average Loss: 0.48617332\n",
      "Epoch [2400/5000], Average Loss: 0.48315316\n",
      "Epoch [2500/5000], Average Loss: 0.48077977\n",
      "Epoch [2600/5000], Average Loss: 0.47894708\n",
      "Epoch [2700/5000], Average Loss: 0.47434893\n",
      "Epoch [2800/5000], Average Loss: 0.47197327\n",
      "Epoch [2900/5000], Average Loss: 0.46923829\n",
      "Epoch [3000/5000], Average Loss: 0.46523970\n",
      "Epoch [3100/5000], Average Loss: 0.46328098\n",
      "Epoch [3200/5000], Average Loss: 0.46133068\n",
      "Epoch [3300/5000], Average Loss: 0.45965531\n",
      "Epoch [3400/5000], Average Loss: 0.45783677\n",
      "Epoch [3500/5000], Average Loss: 0.45427226\n",
      "Epoch [3600/5000], Average Loss: 0.45380549\n",
      "Epoch [3700/5000], Average Loss: 0.45110457\n",
      "Epoch [3800/5000], Average Loss: 0.44669523\n",
      "Epoch [3900/5000], Average Loss: 0.44488329\n",
      "Epoch [4000/5000], Average Loss: 0.44366570\n",
      "Epoch [4100/5000], Average Loss: 0.44169755\n",
      "Epoch [4200/5000], Average Loss: 0.44052446\n",
      "Epoch [4300/5000], Average Loss: 0.43518948\n",
      "Epoch [4400/5000], Average Loss: 0.43683953\n",
      "Epoch [4500/5000], Average Loss: 0.43689371\n",
      "Epoch [4600/5000], Average Loss: 0.43466515\n",
      "Epoch [4700/5000], Average Loss: 0.43251347\n",
      "Epoch [4800/5000], Average Loss: 0.42661224\n",
      "Epoch [4900/5000], Average Loss: 0.43109765\n",
      "Epoch [5000/5000], Average Loss: 0.43603401\n",
      "Test Accuracy: 0.7098\n",
      "Epoch [100/5000], Average Loss: 0.65950093\n",
      "Epoch [200/5000], Average Loss: 0.62904137\n",
      "Epoch [300/5000], Average Loss: 0.60396130\n",
      "Epoch [400/5000], Average Loss: 0.58994114\n",
      "Epoch [500/5000], Average Loss: 0.58007143\n",
      "Epoch [600/5000], Average Loss: 0.57186822\n",
      "Epoch [700/5000], Average Loss: 0.56453399\n",
      "Epoch [800/5000], Average Loss: 0.55834858\n",
      "Epoch [900/5000], Average Loss: 0.55313595\n",
      "Epoch [1000/5000], Average Loss: 0.54862611\n",
      "Epoch [1100/5000], Average Loss: 0.54483134\n",
      "Epoch [1200/5000], Average Loss: 0.54090146\n",
      "Epoch [1300/5000], Average Loss: 0.53691633\n",
      "Epoch [1400/5000], Average Loss: 0.53337150\n",
      "Epoch [1500/5000], Average Loss: 0.52865848\n",
      "Epoch [1600/5000], Average Loss: 0.52370402\n",
      "Epoch [1700/5000], Average Loss: 0.51862047\n",
      "Epoch [1800/5000], Average Loss: 0.51447937\n",
      "Epoch [1900/5000], Average Loss: 0.51022394\n",
      "Epoch [2000/5000], Average Loss: 0.50541329\n",
      "Epoch [2100/5000], Average Loss: 0.50143164\n",
      "Epoch [2200/5000], Average Loss: 0.49771396\n",
      "Epoch [2300/5000], Average Loss: 0.49393134\n",
      "Epoch [2400/5000], Average Loss: 0.49073239\n",
      "Epoch [2500/5000], Average Loss: 0.48884424\n",
      "Epoch [2600/5000], Average Loss: 0.48649576\n",
      "Epoch [2700/5000], Average Loss: 0.48414884\n",
      "Epoch [2800/5000], Average Loss: 0.48200610\n",
      "Epoch [2900/5000], Average Loss: 0.47911208\n",
      "Epoch [3000/5000], Average Loss: 0.47729929\n",
      "Epoch [3100/5000], Average Loss: 0.47530928\n",
      "Epoch [3200/5000], Average Loss: 0.47103544\n",
      "Epoch [3300/5000], Average Loss: 0.46925458\n",
      "Epoch [3400/5000], Average Loss: 0.46610003\n",
      "Epoch [3500/5000], Average Loss: 0.46431856\n",
      "Epoch [3600/5000], Average Loss: 0.46143192\n",
      "Epoch [3700/5000], Average Loss: 0.45921805\n",
      "Epoch [3800/5000], Average Loss: 0.45743520\n",
      "Epoch [3900/5000], Average Loss: 0.45526858\n",
      "Epoch [4000/5000], Average Loss: 0.45199248\n",
      "Epoch [4100/5000], Average Loss: 0.44999187\n",
      "Epoch [4200/5000], Average Loss: 0.44777895\n",
      "Epoch [4300/5000], Average Loss: 0.44550802\n",
      "Epoch [4400/5000], Average Loss: 0.44458952\n",
      "Epoch [4500/5000], Average Loss: 0.44222726\n",
      "Epoch [4600/5000], Average Loss: 0.43822461\n",
      "Epoch [4700/5000], Average Loss: 0.43821103\n",
      "Epoch [4800/5000], Average Loss: 0.43468820\n",
      "Epoch [4900/5000], Average Loss: 0.43417236\n",
      "Epoch [5000/5000], Average Loss: 0.43202498\n",
      "Test Accuracy: 0.7047\n",
      "Epoch [100/5000], Average Loss: 0.66411830\n",
      "Epoch [200/5000], Average Loss: 0.64568510\n",
      "Epoch [300/5000], Average Loss: 0.62550427\n",
      "Epoch [400/5000], Average Loss: 0.60543697\n",
      "Epoch [500/5000], Average Loss: 0.59119494\n",
      "Epoch [600/5000], Average Loss: 0.58078346\n",
      "Epoch [700/5000], Average Loss: 0.57261151\n",
      "Epoch [800/5000], Average Loss: 0.56772998\n",
      "Epoch [900/5000], Average Loss: 0.56361218\n",
      "Epoch [1000/5000], Average Loss: 0.55960438\n",
      "Epoch [1100/5000], Average Loss: 0.55581953\n",
      "Epoch [1200/5000], Average Loss: 0.55206693\n",
      "Epoch [1300/5000], Average Loss: 0.54840878\n",
      "Epoch [1400/5000], Average Loss: 0.54464568\n",
      "Epoch [1500/5000], Average Loss: 0.54081526\n",
      "Epoch [1600/5000], Average Loss: 0.53705905\n",
      "Epoch [1700/5000], Average Loss: 0.53394053\n",
      "Epoch [1800/5000], Average Loss: 0.53019949\n",
      "Epoch [1900/5000], Average Loss: 0.52620359\n",
      "Epoch [2000/5000], Average Loss: 0.52338817\n",
      "Epoch [2100/5000], Average Loss: 0.51859009\n",
      "Epoch [2200/5000], Average Loss: 0.51513801\n",
      "Epoch [2300/5000], Average Loss: 0.51227570\n",
      "Epoch [2400/5000], Average Loss: 0.51038528\n",
      "Epoch [2500/5000], Average Loss: 0.50640968\n",
      "Epoch [2600/5000], Average Loss: 0.50181752\n",
      "Epoch [2700/5000], Average Loss: 0.49937216\n",
      "Epoch [2800/5000], Average Loss: 0.49641145\n",
      "Epoch [2900/5000], Average Loss: 0.49314094\n",
      "Epoch [3000/5000], Average Loss: 0.49065054\n",
      "Epoch [3100/5000], Average Loss: 0.48860453\n",
      "Epoch [3200/5000], Average Loss: 0.48607921\n",
      "Epoch [3300/5000], Average Loss: 0.48456066\n",
      "Epoch [3400/5000], Average Loss: 0.48231416\n",
      "Epoch [3500/5000], Average Loss: 0.47909968\n",
      "Epoch [3600/5000], Average Loss: 0.47722245\n",
      "Epoch [3700/5000], Average Loss: 0.47565651\n",
      "Epoch [3800/5000], Average Loss: 0.47215794\n",
      "Epoch [3900/5000], Average Loss: 0.46948582\n",
      "Epoch [4000/5000], Average Loss: 0.46751745\n",
      "Epoch [4100/5000], Average Loss: 0.46474990\n",
      "Epoch [4200/5000], Average Loss: 0.46295284\n",
      "Epoch [4300/5000], Average Loss: 0.46042844\n",
      "Epoch [4400/5000], Average Loss: 0.45748888\n",
      "Epoch [4500/5000], Average Loss: 0.45649450\n",
      "Epoch [4600/5000], Average Loss: 0.45320824\n",
      "Epoch [4700/5000], Average Loss: 0.45028890\n",
      "Epoch [4800/5000], Average Loss: 0.44753837\n",
      "Epoch [4900/5000], Average Loss: 0.44616933\n",
      "Epoch [5000/5000], Average Loss: 0.44389550\n",
      "Test Accuracy: 0.7022\n",
      "Epoch [100/5000], Average Loss: 0.66408320\n",
      "Epoch [200/5000], Average Loss: 0.64944274\n",
      "Epoch [300/5000], Average Loss: 0.62836133\n",
      "Epoch [400/5000], Average Loss: 0.60505768\n",
      "Epoch [500/5000], Average Loss: 0.59071495\n",
      "Epoch [600/5000], Average Loss: 0.58147690\n",
      "Epoch [700/5000], Average Loss: 0.57446975\n",
      "Epoch [800/5000], Average Loss: 0.56742877\n",
      "Epoch [900/5000], Average Loss: 0.56176329\n",
      "Epoch [1000/5000], Average Loss: 0.55672306\n",
      "Epoch [1100/5000], Average Loss: 0.55193117\n",
      "Epoch [1200/5000], Average Loss: 0.54754397\n",
      "Epoch [1300/5000], Average Loss: 0.54293142\n",
      "Epoch [1400/5000], Average Loss: 0.53997458\n",
      "Epoch [1500/5000], Average Loss: 0.53418177\n",
      "Epoch [1600/5000], Average Loss: 0.53009472\n",
      "Epoch [1700/5000], Average Loss: 0.52591212\n",
      "Epoch [1800/5000], Average Loss: 0.52179888\n",
      "Epoch [1900/5000], Average Loss: 0.51785552\n",
      "Epoch [2000/5000], Average Loss: 0.51453914\n",
      "Epoch [2100/5000], Average Loss: 0.51042268\n",
      "Epoch [2200/5000], Average Loss: 0.50724381\n",
      "Epoch [2300/5000], Average Loss: 0.50366639\n",
      "Epoch [2400/5000], Average Loss: 0.49989966\n",
      "Epoch [2500/5000], Average Loss: 0.49684993\n",
      "Epoch [2600/5000], Average Loss: 0.49384614\n",
      "Epoch [2700/5000], Average Loss: 0.49069130\n",
      "Epoch [2800/5000], Average Loss: 0.48772984\n",
      "Epoch [2900/5000], Average Loss: 0.48536778\n",
      "Epoch [3000/5000], Average Loss: 0.48349787\n",
      "Epoch [3100/5000], Average Loss: 0.48126904\n",
      "Epoch [3200/5000], Average Loss: 0.47920023\n",
      "Epoch [3300/5000], Average Loss: 0.47757254\n",
      "Epoch [3400/5000], Average Loss: 0.47546588\n",
      "Epoch [3500/5000], Average Loss: 0.47372874\n",
      "Epoch [3600/5000], Average Loss: 0.47210786\n",
      "Epoch [3700/5000], Average Loss: 0.47006428\n",
      "Epoch [3800/5000], Average Loss: 0.46781205\n",
      "Epoch [3900/5000], Average Loss: 0.46622914\n",
      "Epoch [4000/5000], Average Loss: 0.46430445\n",
      "Epoch [4100/5000], Average Loss: 0.46219671\n",
      "Epoch [4200/5000], Average Loss: 0.46085919\n",
      "Epoch [4300/5000], Average Loss: 0.45951694\n",
      "Epoch [4400/5000], Average Loss: 0.45763882\n",
      "Epoch [4500/5000], Average Loss: 0.45536717\n",
      "Epoch [4600/5000], Average Loss: 0.45398552\n",
      "Epoch [4700/5000], Average Loss: 0.45229664\n",
      "Epoch [4800/5000], Average Loss: 0.45055001\n",
      "Epoch [4900/5000], Average Loss: 0.44934141\n",
      "Epoch [5000/5000], Average Loss: 0.44657957\n",
      "Test Accuracy: 0.7063\n",
      "Epoch [100/5000], Average Loss: 0.65505663\n",
      "Epoch [200/5000], Average Loss: 0.62812922\n",
      "Epoch [300/5000], Average Loss: 0.60222063\n",
      "Epoch [400/5000], Average Loss: 0.58442559\n",
      "Epoch [500/5000], Average Loss: 0.57271605\n",
      "Epoch [600/5000], Average Loss: 0.56482526\n",
      "Epoch [700/5000], Average Loss: 0.55794506\n",
      "Epoch [800/5000], Average Loss: 0.55187467\n",
      "Epoch [900/5000], Average Loss: 0.54688452\n",
      "Epoch [1000/5000], Average Loss: 0.54236325\n",
      "Epoch [1100/5000], Average Loss: 0.53766574\n",
      "Epoch [1200/5000], Average Loss: 0.53344873\n",
      "Epoch [1300/5000], Average Loss: 0.52880784\n",
      "Epoch [1400/5000], Average Loss: 0.52451032\n",
      "Epoch [1500/5000], Average Loss: 0.52069105\n",
      "Epoch [1600/5000], Average Loss: 0.51718009\n",
      "Epoch [1700/5000], Average Loss: 0.51329802\n",
      "Epoch [1800/5000], Average Loss: 0.50989253\n",
      "Epoch [1900/5000], Average Loss: 0.50600619\n",
      "Epoch [2000/5000], Average Loss: 0.50224369\n",
      "Epoch [2100/5000], Average Loss: 0.49909826\n",
      "Epoch [2200/5000], Average Loss: 0.49606083\n",
      "Epoch [2300/5000], Average Loss: 0.49298172\n",
      "Epoch [2400/5000], Average Loss: 0.49083799\n",
      "Epoch [2500/5000], Average Loss: 0.48712801\n",
      "Epoch [2600/5000], Average Loss: 0.48505723\n",
      "Epoch [2700/5000], Average Loss: 0.48168886\n",
      "Epoch [2800/5000], Average Loss: 0.47886637\n",
      "Epoch [2900/5000], Average Loss: 0.47636055\n",
      "Epoch [3000/5000], Average Loss: 0.47325791\n",
      "Epoch [3100/5000], Average Loss: 0.47163527\n",
      "Epoch [3200/5000], Average Loss: 0.46799592\n",
      "Epoch [3300/5000], Average Loss: 0.46082347\n",
      "Epoch [3400/5000], Average Loss: 0.45608526\n",
      "Epoch [3500/5000], Average Loss: 0.45309143\n",
      "Epoch [3600/5000], Average Loss: 0.44922737\n",
      "Epoch [3700/5000], Average Loss: 0.46235537\n",
      "Epoch [3800/5000], Average Loss: 0.45073216\n",
      "Epoch [3900/5000], Average Loss: 0.44611335\n",
      "Epoch [4000/5000], Average Loss: 0.44807553\n",
      "Epoch [4100/5000], Average Loss: 0.44237449\n",
      "Epoch [4200/5000], Average Loss: 0.43205077\n",
      "Epoch [4300/5000], Average Loss: 0.42665831\n",
      "Epoch [4400/5000], Average Loss: 0.41997076\n",
      "Epoch [4500/5000], Average Loss: 0.41352346\n",
      "Epoch [4600/5000], Average Loss: 0.40832371\n",
      "Epoch [4700/5000], Average Loss: 0.40530165\n",
      "Epoch [4800/5000], Average Loss: 0.39903890\n",
      "Epoch [4900/5000], Average Loss: 0.39433577\n",
      "Epoch [5000/5000], Average Loss: 0.39010937\n",
      "Test Accuracy: 0.7046\n",
      "Epoch [100/5000], Average Loss: 0.65744232\n",
      "Epoch [200/5000], Average Loss: 0.64274781\n",
      "Epoch [300/5000], Average Loss: 0.62900966\n",
      "Epoch [400/5000], Average Loss: 0.61307073\n",
      "Epoch [500/5000], Average Loss: 0.59839970\n",
      "Epoch [600/5000], Average Loss: 0.58573100\n",
      "Epoch [700/5000], Average Loss: 0.57535447\n",
      "Epoch [800/5000], Average Loss: 0.56750735\n",
      "Epoch [900/5000], Average Loss: 0.56111163\n",
      "Epoch [1000/5000], Average Loss: 0.55581989\n",
      "Epoch [1100/5000], Average Loss: 0.55155153\n",
      "Epoch [1200/5000], Average Loss: 0.54765138\n",
      "Epoch [1300/5000], Average Loss: 0.54377435\n",
      "Epoch [1400/5000], Average Loss: 0.54026054\n",
      "Epoch [1500/5000], Average Loss: 0.53686895\n",
      "Epoch [1600/5000], Average Loss: 0.53381199\n",
      "Epoch [1700/5000], Average Loss: 0.53078524\n",
      "Epoch [1800/5000], Average Loss: 0.52726554\n",
      "Epoch [1900/5000], Average Loss: 0.52490068\n",
      "Epoch [2000/5000], Average Loss: 0.52158759\n",
      "Epoch [2100/5000], Average Loss: 0.51863199\n",
      "Epoch [2200/5000], Average Loss: 0.51622298\n",
      "Epoch [2300/5000], Average Loss: 0.51353123\n",
      "Epoch [2400/5000], Average Loss: 0.51161178\n",
      "Epoch [2500/5000], Average Loss: 0.50862572\n",
      "Epoch [2600/5000], Average Loss: 0.50652385\n",
      "Epoch [2700/5000], Average Loss: 0.50370855\n",
      "Epoch [2800/5000], Average Loss: 0.50137094\n",
      "Epoch [2900/5000], Average Loss: 0.49819422\n",
      "Epoch [3000/5000], Average Loss: 0.49592008\n",
      "Epoch [3100/5000], Average Loss: 0.49308877\n",
      "Epoch [3200/5000], Average Loss: 0.49094190\n",
      "Epoch [3300/5000], Average Loss: 0.48853471\n",
      "Epoch [3400/5000], Average Loss: 0.48598518\n",
      "Epoch [3500/5000], Average Loss: 0.48257731\n",
      "Epoch [3600/5000], Average Loss: 0.48118157\n",
      "Epoch [3700/5000], Average Loss: 0.47828460\n",
      "Epoch [3800/5000], Average Loss: 0.47438265\n",
      "Epoch [3900/5000], Average Loss: 0.46972582\n",
      "Epoch [4000/5000], Average Loss: 0.46667481\n",
      "Epoch [4100/5000], Average Loss: 0.46363300\n",
      "Epoch [4200/5000], Average Loss: 0.46073621\n",
      "Epoch [4300/5000], Average Loss: 0.45767213\n",
      "Epoch [4400/5000], Average Loss: 0.45470945\n",
      "Epoch [4500/5000], Average Loss: 0.45163754\n",
      "Epoch [4600/5000], Average Loss: 0.44795791\n",
      "Epoch [4700/5000], Average Loss: 0.44447273\n",
      "Epoch [4800/5000], Average Loss: 0.44129747\n",
      "Epoch [4900/5000], Average Loss: 0.43776582\n",
      "Epoch [5000/5000], Average Loss: 0.43452638\n",
      "Test Accuracy: 0.7069\n",
      "Epoch [100/5000], Average Loss: 0.65761177\n",
      "Epoch [200/5000], Average Loss: 0.64192792\n",
      "Epoch [300/5000], Average Loss: 0.62393251\n",
      "Epoch [400/5000], Average Loss: 0.60666456\n",
      "Epoch [500/5000], Average Loss: 0.59312912\n",
      "Epoch [600/5000], Average Loss: 0.58322756\n",
      "Epoch [700/5000], Average Loss: 0.57554052\n",
      "Epoch [800/5000], Average Loss: 0.56966721\n",
      "Epoch [900/5000], Average Loss: 0.56455717\n",
      "Epoch [1000/5000], Average Loss: 0.56039337\n",
      "Epoch [1100/5000], Average Loss: 0.55684734\n",
      "Epoch [1200/5000], Average Loss: 0.55274981\n",
      "Epoch [1300/5000], Average Loss: 0.54910730\n",
      "Epoch [1400/5000], Average Loss: 0.54567471\n",
      "Epoch [1500/5000], Average Loss: 0.54230451\n",
      "Epoch [1600/5000], Average Loss: 0.53949413\n",
      "Epoch [1700/5000], Average Loss: 0.53672738\n",
      "Epoch [1800/5000], Average Loss: 0.53401758\n",
      "Epoch [1900/5000], Average Loss: 0.53158400\n",
      "Epoch [2000/5000], Average Loss: 0.52924379\n",
      "Epoch [2100/5000], Average Loss: 0.52685032\n",
      "Epoch [2200/5000], Average Loss: 0.52428507\n",
      "Epoch [2300/5000], Average Loss: 0.52149112\n",
      "Epoch [2400/5000], Average Loss: 0.51916802\n",
      "Epoch [2500/5000], Average Loss: 0.51671050\n",
      "Epoch [2600/5000], Average Loss: 0.51367304\n",
      "Epoch [2700/5000], Average Loss: 0.51122481\n",
      "Epoch [2800/5000], Average Loss: 0.50887010\n",
      "Epoch [2900/5000], Average Loss: 0.50598298\n",
      "Epoch [3000/5000], Average Loss: 0.50341821\n",
      "Epoch [3100/5000], Average Loss: 0.50112741\n",
      "Epoch [3200/5000], Average Loss: 0.49867433\n",
      "Epoch [3300/5000], Average Loss: 0.49594437\n",
      "Epoch [3400/5000], Average Loss: 0.49321462\n",
      "Epoch [3500/5000], Average Loss: 0.49044760\n",
      "Epoch [3600/5000], Average Loss: 0.48845338\n",
      "Epoch [3700/5000], Average Loss: 0.48559840\n",
      "Epoch [3800/5000], Average Loss: 0.48305763\n",
      "Epoch [3900/5000], Average Loss: 0.47936790\n",
      "Epoch [4000/5000], Average Loss: 0.47788973\n",
      "Epoch [4100/5000], Average Loss: 0.47646470\n",
      "Epoch [4200/5000], Average Loss: 0.47340813\n",
      "Epoch [4300/5000], Average Loss: 0.47094201\n",
      "Epoch [4400/5000], Average Loss: 0.46958479\n",
      "Epoch [4500/5000], Average Loss: 0.46637231\n",
      "Epoch [4600/5000], Average Loss: 0.46467174\n",
      "Epoch [4700/5000], Average Loss: 0.46275189\n",
      "Epoch [4800/5000], Average Loss: 0.46080016\n",
      "Epoch [4900/5000], Average Loss: 0.45763446\n",
      "Epoch [5000/5000], Average Loss: 0.45463644\n",
      "Test Accuracy: 0.7039\n",
      "Epoch [100/5000], Average Loss: 0.68581036\n",
      "Epoch [200/5000], Average Loss: 0.66496080\n",
      "Epoch [300/5000], Average Loss: 0.65294816\n",
      "Epoch [400/5000], Average Loss: 0.63700821\n",
      "Epoch [500/5000], Average Loss: 0.62115929\n",
      "Epoch [600/5000], Average Loss: 0.60897332\n",
      "Epoch [700/5000], Average Loss: 0.59862894\n",
      "Epoch [800/5000], Average Loss: 0.59001756\n",
      "Epoch [900/5000], Average Loss: 0.58377066\n",
      "Epoch [1000/5000], Average Loss: 0.57851583\n",
      "Epoch [1100/5000], Average Loss: 0.57396390\n",
      "Epoch [1200/5000], Average Loss: 0.56979139\n",
      "Epoch [1300/5000], Average Loss: 0.56477780\n",
      "Epoch [1400/5000], Average Loss: 0.56044320\n",
      "Epoch [1500/5000], Average Loss: 0.55630759\n",
      "Epoch [1600/5000], Average Loss: 0.55247979\n",
      "Epoch [1700/5000], Average Loss: 0.54843679\n",
      "Epoch [1800/5000], Average Loss: 0.54418412\n",
      "Epoch [1900/5000], Average Loss: 0.54031242\n",
      "Epoch [2000/5000], Average Loss: 0.53633550\n",
      "Epoch [2100/5000], Average Loss: 0.53250361\n",
      "Epoch [2200/5000], Average Loss: 0.52834315\n",
      "Epoch [2300/5000], Average Loss: 0.52423871\n",
      "Epoch [2400/5000], Average Loss: 0.52070377\n",
      "Epoch [2500/5000], Average Loss: 0.51715051\n",
      "Epoch [2600/5000], Average Loss: 0.51299104\n",
      "Epoch [2700/5000], Average Loss: 0.50893007\n",
      "Epoch [2800/5000], Average Loss: 0.50467539\n",
      "Epoch [2900/5000], Average Loss: 0.50044301\n",
      "Epoch [3000/5000], Average Loss: 0.49624318\n",
      "Epoch [3100/5000], Average Loss: 0.49201691\n",
      "Epoch [3200/5000], Average Loss: 0.48829033\n",
      "Epoch [3300/5000], Average Loss: 0.48427183\n",
      "Epoch [3400/5000], Average Loss: 0.48031765\n",
      "Epoch [3500/5000], Average Loss: 0.47634731\n",
      "Epoch [3600/5000], Average Loss: 0.47318526\n",
      "Epoch [3700/5000], Average Loss: 0.46937543\n",
      "Epoch [3800/5000], Average Loss: 0.46594695\n",
      "Epoch [3900/5000], Average Loss: 0.46289694\n",
      "Epoch [4000/5000], Average Loss: 0.45964026\n",
      "Epoch [4100/5000], Average Loss: 0.45677975\n",
      "Epoch [4200/5000], Average Loss: 0.45405125\n",
      "Epoch [4300/5000], Average Loss: 0.45094477\n",
      "Epoch [4400/5000], Average Loss: 0.44814233\n",
      "Epoch [4500/5000], Average Loss: 0.44534231\n",
      "Epoch [4600/5000], Average Loss: 0.44239558\n",
      "Epoch [4700/5000], Average Loss: 0.43952066\n",
      "Epoch [4800/5000], Average Loss: 0.43649255\n",
      "Epoch [4900/5000], Average Loss: 0.43416409\n",
      "Epoch [5000/5000], Average Loss: 0.43142315\n",
      "Test Accuracy: 0.6862\n",
      "Epoch [100/5000], Average Loss: 0.70048076\n",
      "Epoch [200/5000], Average Loss: 0.66731901\n",
      "Epoch [300/5000], Average Loss: 0.64819206\n",
      "Epoch [400/5000], Average Loss: 0.63295216\n",
      "Epoch [500/5000], Average Loss: 0.62070846\n",
      "Epoch [600/5000], Average Loss: 0.61031410\n",
      "Epoch [700/5000], Average Loss: 0.60152167\n",
      "Epoch [800/5000], Average Loss: 0.59425432\n",
      "Epoch [900/5000], Average Loss: 0.58793317\n",
      "Epoch [1000/5000], Average Loss: 0.58251981\n",
      "Epoch [1100/5000], Average Loss: 0.57808082\n",
      "Epoch [1200/5000], Average Loss: 0.57425317\n",
      "Epoch [1300/5000], Average Loss: 0.57071545\n",
      "Epoch [1400/5000], Average Loss: 0.56737040\n",
      "Epoch [1500/5000], Average Loss: 0.56402263\n",
      "Epoch [1600/5000], Average Loss: 0.56072524\n",
      "Epoch [1700/5000], Average Loss: 0.55767149\n",
      "Epoch [1800/5000], Average Loss: 0.55404470\n",
      "Epoch [1900/5000], Average Loss: 0.55086316\n",
      "Epoch [2000/5000], Average Loss: 0.54782226\n",
      "Epoch [2100/5000], Average Loss: 0.54461953\n",
      "Epoch [2200/5000], Average Loss: 0.54182414\n",
      "Epoch [2300/5000], Average Loss: 0.53864578\n",
      "Epoch [2400/5000], Average Loss: 0.53581525\n",
      "Epoch [2500/5000], Average Loss: 0.53221401\n",
      "Epoch [2600/5000], Average Loss: 0.52886124\n",
      "Epoch [2700/5000], Average Loss: 0.52548707\n",
      "Epoch [2800/5000], Average Loss: 0.52234835\n",
      "Epoch [2900/5000], Average Loss: 0.51942791\n",
      "Epoch [3000/5000], Average Loss: 0.51641705\n",
      "Epoch [3100/5000], Average Loss: 0.51390900\n",
      "Epoch [3200/5000], Average Loss: 0.51095846\n",
      "Epoch [3300/5000], Average Loss: 0.50812557\n",
      "Epoch [3400/5000], Average Loss: 0.50598580\n",
      "Epoch [3500/5000], Average Loss: 0.50331747\n",
      "Epoch [3600/5000], Average Loss: 0.50068815\n",
      "Epoch [3700/5000], Average Loss: 0.49815998\n",
      "Epoch [3800/5000], Average Loss: 0.49549480\n",
      "Epoch [3900/5000], Average Loss: 0.49275582\n",
      "Epoch [4000/5000], Average Loss: 0.49012953\n",
      "Epoch [4100/5000], Average Loss: 0.48747421\n",
      "Epoch [4200/5000], Average Loss: 0.48529208\n",
      "Epoch [4300/5000], Average Loss: 0.48266946\n",
      "Epoch [4400/5000], Average Loss: 0.48044666\n",
      "Epoch [4500/5000], Average Loss: 0.47758409\n",
      "Epoch [4600/5000], Average Loss: 0.47524605\n",
      "Epoch [4700/5000], Average Loss: 0.47254014\n",
      "Epoch [4800/5000], Average Loss: 0.47063116\n",
      "Epoch [4900/5000], Average Loss: 0.46854575\n",
      "Epoch [5000/5000], Average Loss: 0.46642872\n",
      "Test Accuracy: 0.6887\n",
      "Epoch [100/5000], Average Loss: 0.68919410\n",
      "Epoch [200/5000], Average Loss: 0.66534313\n",
      "Epoch [300/5000], Average Loss: 0.65100396\n",
      "Epoch [400/5000], Average Loss: 0.63466026\n",
      "Epoch [500/5000], Average Loss: 0.61924576\n",
      "Epoch [600/5000], Average Loss: 0.60567522\n",
      "Epoch [700/5000], Average Loss: 0.59402895\n",
      "Epoch [800/5000], Average Loss: 0.58488209\n",
      "Epoch [900/5000], Average Loss: 0.57827351\n",
      "Epoch [1000/5000], Average Loss: 0.57262505\n",
      "Epoch [1100/5000], Average Loss: 0.56772981\n",
      "Epoch [1200/5000], Average Loss: 0.56318991\n",
      "Epoch [1300/5000], Average Loss: 0.55872852\n",
      "Epoch [1400/5000], Average Loss: 0.55472969\n",
      "Epoch [1500/5000], Average Loss: 0.55033545\n",
      "Epoch [1600/5000], Average Loss: 0.54614864\n",
      "Epoch [1700/5000], Average Loss: 0.54216217\n",
      "Epoch [1800/5000], Average Loss: 0.53818730\n",
      "Epoch [1900/5000], Average Loss: 0.53429642\n",
      "Epoch [2000/5000], Average Loss: 0.53009057\n",
      "Epoch [2100/5000], Average Loss: 0.52607074\n",
      "Epoch [2200/5000], Average Loss: 0.52221170\n",
      "Epoch [2300/5000], Average Loss: 0.51834017\n",
      "Epoch [2400/5000], Average Loss: 0.51431920\n",
      "Epoch [2500/5000], Average Loss: 0.50994798\n",
      "Epoch [2600/5000], Average Loss: 0.50549371\n",
      "Epoch [2700/5000], Average Loss: 0.50119385\n",
      "Epoch [2800/5000], Average Loss: 0.49734830\n",
      "Epoch [2900/5000], Average Loss: 0.49311863\n",
      "Epoch [3000/5000], Average Loss: 0.48907412\n",
      "Epoch [3100/5000], Average Loss: 0.48443993\n",
      "Epoch [3200/5000], Average Loss: 0.48015873\n",
      "Epoch [3300/5000], Average Loss: 0.47573999\n",
      "Epoch [3400/5000], Average Loss: 0.47125051\n",
      "Epoch [3500/5000], Average Loss: 0.46696563\n",
      "Epoch [3600/5000], Average Loss: 0.46385740\n",
      "Epoch [3700/5000], Average Loss: 0.46020890\n",
      "Epoch [3800/5000], Average Loss: 0.45673831\n",
      "Epoch [3900/5000], Average Loss: 0.45230395\n",
      "Epoch [4000/5000], Average Loss: 0.44839364\n",
      "Epoch [4100/5000], Average Loss: 0.44407476\n",
      "Epoch [4200/5000], Average Loss: 0.44001738\n",
      "Epoch [4300/5000], Average Loss: 0.43648141\n",
      "Epoch [4400/5000], Average Loss: 0.43257848\n",
      "Epoch [4500/5000], Average Loss: 0.42921482\n",
      "Epoch [4600/5000], Average Loss: 0.42396706\n",
      "Epoch [4700/5000], Average Loss: 0.42127774\n",
      "Epoch [4800/5000], Average Loss: 0.42121597\n",
      "Epoch [4900/5000], Average Loss: 0.41665257\n",
      "Epoch [5000/5000], Average Loss: 0.41140456\n",
      "Test Accuracy: 0.6921\n",
      "Epoch [100/5000], Average Loss: 0.80158917\n",
      "Epoch [200/5000], Average Loss: 0.76489583\n",
      "Epoch [300/5000], Average Loss: 0.73717446\n",
      "Epoch [400/5000], Average Loss: 0.71944797\n",
      "Epoch [500/5000], Average Loss: 0.70476641\n",
      "Epoch [600/5000], Average Loss: 0.68996245\n",
      "Epoch [700/5000], Average Loss: 0.67563694\n",
      "Epoch [800/5000], Average Loss: 0.65892187\n",
      "Epoch [900/5000], Average Loss: 0.64356377\n",
      "Epoch [1000/5000], Average Loss: 0.63044245\n",
      "Epoch [1100/5000], Average Loss: 0.61921221\n",
      "Epoch [1200/5000], Average Loss: 0.60981394\n",
      "Epoch [1300/5000], Average Loss: 0.60143892\n",
      "Epoch [1400/5000], Average Loss: 0.59291970\n",
      "Epoch [1500/5000], Average Loss: 0.58469199\n",
      "Epoch [1600/5000], Average Loss: 0.57700760\n",
      "Epoch [1700/5000], Average Loss: 0.56980946\n",
      "Epoch [1800/5000], Average Loss: 0.56273686\n",
      "Epoch [1900/5000], Average Loss: 0.55616841\n",
      "Epoch [2000/5000], Average Loss: 0.54945457\n",
      "Epoch [2100/5000], Average Loss: 0.54275583\n",
      "Epoch [2200/5000], Average Loss: 0.53558999\n",
      "Epoch [2300/5000], Average Loss: 0.52933557\n",
      "Epoch [2400/5000], Average Loss: 0.52341551\n",
      "Epoch [2500/5000], Average Loss: 0.51781550\n",
      "Epoch [2600/5000], Average Loss: 0.51257623\n",
      "Epoch [2700/5000], Average Loss: 0.50771435\n",
      "Epoch [2800/5000], Average Loss: 0.50298062\n",
      "Epoch [2900/5000], Average Loss: 0.49810158\n",
      "Epoch [3000/5000], Average Loss: 0.49319434\n",
      "Epoch [3100/5000], Average Loss: 0.48880918\n",
      "Epoch [3200/5000], Average Loss: 0.48433287\n",
      "Epoch [3300/5000], Average Loss: 0.47998316\n",
      "Epoch [3400/5000], Average Loss: 0.47588570\n",
      "Epoch [3500/5000], Average Loss: 0.47186139\n",
      "Epoch [3600/5000], Average Loss: 0.46798599\n",
      "Epoch [3700/5000], Average Loss: 0.46426595\n",
      "Epoch [3800/5000], Average Loss: 0.46077015\n",
      "Epoch [3900/5000], Average Loss: 0.45746818\n",
      "Epoch [4000/5000], Average Loss: 0.45437713\n",
      "Epoch [4100/5000], Average Loss: 0.45122864\n",
      "Epoch [4200/5000], Average Loss: 0.44827856\n",
      "Epoch [4300/5000], Average Loss: 0.44472127\n",
      "Epoch [4400/5000], Average Loss: 0.44155960\n",
      "Epoch [4500/5000], Average Loss: 0.43819919\n",
      "Epoch [4600/5000], Average Loss: 0.43511339\n",
      "Epoch [4700/5000], Average Loss: 0.43185813\n",
      "Epoch [4800/5000], Average Loss: 0.42846971\n",
      "Epoch [4900/5000], Average Loss: 0.42537013\n",
      "Epoch [5000/5000], Average Loss: 0.42195762\n",
      "Test Accuracy: 0.6715\n",
      "Epoch [100/5000], Average Loss: 0.80119914\n",
      "Epoch [200/5000], Average Loss: 0.76095435\n",
      "Epoch [300/5000], Average Loss: 0.73456559\n",
      "Epoch [400/5000], Average Loss: 0.71343338\n",
      "Epoch [500/5000], Average Loss: 0.69595765\n",
      "Epoch [600/5000], Average Loss: 0.68129746\n",
      "Epoch [700/5000], Average Loss: 0.66831102\n",
      "Epoch [800/5000], Average Loss: 0.65529699\n",
      "Epoch [900/5000], Average Loss: 0.64271528\n",
      "Epoch [1000/5000], Average Loss: 0.63109730\n",
      "Epoch [1100/5000], Average Loss: 0.62124389\n",
      "Epoch [1200/5000], Average Loss: 0.61260176\n",
      "Epoch [1300/5000], Average Loss: 0.60461702\n",
      "Epoch [1400/5000], Average Loss: 0.59645813\n",
      "Epoch [1500/5000], Average Loss: 0.58914968\n",
      "Epoch [1600/5000], Average Loss: 0.58177570\n",
      "Epoch [1700/5000], Average Loss: 0.57392532\n",
      "Epoch [1800/5000], Average Loss: 0.56681936\n",
      "Epoch [1900/5000], Average Loss: 0.55999449\n",
      "Epoch [2000/5000], Average Loss: 0.55364226\n",
      "Epoch [2100/5000], Average Loss: 0.54789074\n",
      "Epoch [2200/5000], Average Loss: 0.54211007\n",
      "Epoch [2300/5000], Average Loss: 0.53654255\n",
      "Epoch [2400/5000], Average Loss: 0.53068188\n",
      "Epoch [2500/5000], Average Loss: 0.52495124\n",
      "Epoch [2600/5000], Average Loss: 0.51945426\n",
      "Epoch [2700/5000], Average Loss: 0.51423332\n",
      "Epoch [2800/5000], Average Loss: 0.50900355\n",
      "Epoch [2900/5000], Average Loss: 0.50401669\n",
      "Epoch [3000/5000], Average Loss: 0.49902136\n",
      "Epoch [3100/5000], Average Loss: 0.49420914\n",
      "Epoch [3200/5000], Average Loss: 0.48926232\n",
      "Epoch [3300/5000], Average Loss: 0.48447152\n",
      "Epoch [3400/5000], Average Loss: 0.47971394\n",
      "Epoch [3500/5000], Average Loss: 0.47495856\n",
      "Epoch [3600/5000], Average Loss: 0.47044578\n",
      "Epoch [3700/5000], Average Loss: 0.46596463\n",
      "Epoch [3800/5000], Average Loss: 0.46126971\n",
      "Epoch [3900/5000], Average Loss: 0.45582541\n",
      "Epoch [4000/5000], Average Loss: 0.45049484\n",
      "Epoch [4100/5000], Average Loss: 0.44554194\n",
      "Epoch [4200/5000], Average Loss: 0.44099393\n",
      "Epoch [4300/5000], Average Loss: 0.43646286\n",
      "Epoch [4400/5000], Average Loss: 0.43204757\n",
      "Epoch [4500/5000], Average Loss: 0.42769051\n",
      "Epoch [4600/5000], Average Loss: 0.42323391\n",
      "Epoch [4700/5000], Average Loss: 0.41860030\n",
      "Epoch [4800/5000], Average Loss: 0.41364151\n",
      "Epoch [4900/5000], Average Loss: 0.40912259\n",
      "Epoch [5000/5000], Average Loss: 0.40411640\n",
      "Test Accuracy: 0.6761\n",
      "Epoch [100/5000], Average Loss: 0.80466638\n",
      "Epoch [200/5000], Average Loss: 0.76326794\n",
      "Epoch [300/5000], Average Loss: 0.73433138\n",
      "Epoch [400/5000], Average Loss: 0.71078383\n",
      "Epoch [500/5000], Average Loss: 0.69516176\n",
      "Epoch [600/5000], Average Loss: 0.68107555\n",
      "Epoch [700/5000], Average Loss: 0.66818902\n",
      "Epoch [800/5000], Average Loss: 0.65742757\n",
      "Epoch [900/5000], Average Loss: 0.64793876\n",
      "Epoch [1000/5000], Average Loss: 0.63914568\n",
      "Epoch [1100/5000], Average Loss: 0.63135778\n",
      "Epoch [1200/5000], Average Loss: 0.62412922\n",
      "Epoch [1300/5000], Average Loss: 0.61798078\n",
      "Epoch [1400/5000], Average Loss: 0.61201539\n",
      "Epoch [1500/5000], Average Loss: 0.60638287\n",
      "Epoch [1600/5000], Average Loss: 0.60090679\n",
      "Epoch [1700/5000], Average Loss: 0.59534517\n",
      "Epoch [1800/5000], Average Loss: 0.58948282\n",
      "Epoch [1900/5000], Average Loss: 0.58401132\n",
      "Epoch [2000/5000], Average Loss: 0.57895630\n",
      "Epoch [2100/5000], Average Loss: 0.57366188\n",
      "Epoch [2200/5000], Average Loss: 0.56874036\n",
      "Epoch [2300/5000], Average Loss: 0.56322138\n",
      "Epoch [2400/5000], Average Loss: 0.55770826\n",
      "Epoch [2500/5000], Average Loss: 0.55178693\n",
      "Epoch [2600/5000], Average Loss: 0.54609950\n",
      "Epoch [2700/5000], Average Loss: 0.54066232\n",
      "Epoch [2800/5000], Average Loss: 0.53471832\n",
      "Epoch [2900/5000], Average Loss: 0.52819417\n",
      "Epoch [3000/5000], Average Loss: 0.52235059\n",
      "Epoch [3100/5000], Average Loss: 0.51639076\n",
      "Epoch [3200/5000], Average Loss: 0.51032384\n",
      "Epoch [3300/5000], Average Loss: 0.50452402\n",
      "Epoch [3400/5000], Average Loss: 0.49913470\n",
      "Epoch [3500/5000], Average Loss: 0.49387975\n",
      "Epoch [3600/5000], Average Loss: 0.48895794\n",
      "Epoch [3700/5000], Average Loss: 0.48381506\n",
      "Epoch [3800/5000], Average Loss: 0.47882644\n",
      "Epoch [3900/5000], Average Loss: 0.47394685\n",
      "Epoch [4000/5000], Average Loss: 0.46927976\n",
      "Epoch [4100/5000], Average Loss: 0.46437793\n",
      "Epoch [4200/5000], Average Loss: 0.45960541\n",
      "Epoch [4300/5000], Average Loss: 0.45516864\n",
      "Epoch [4400/5000], Average Loss: 0.45068651\n",
      "Epoch [4500/5000], Average Loss: 0.44663402\n",
      "Epoch [4600/5000], Average Loss: 0.44229240\n",
      "Epoch [4700/5000], Average Loss: 0.43819835\n",
      "Epoch [4800/5000], Average Loss: 0.43395595\n",
      "Epoch [4900/5000], Average Loss: 0.42967504\n",
      "Epoch [5000/5000], Average Loss: 0.42578762\n",
      "Test Accuracy: 0.6772\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "input_size = 100\n",
    "hidden_sizes = [70,64, 32]\n",
    "output_size = 1\n",
    "# test sizes \n",
    "train_sizes = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5,0.4,0.3,0.2,0.1]\n",
    "accuracy = {i:[] for i in train_sizes}\n",
    "\n",
    "dat = pd.read_csv('../../data/data-norm/max-pixel-all/nthroot_0.5862.csv')\n",
    "data = dat.iloc[:, 1:].values\n",
    "labels = dat.iloc[:, 0].values.reshape(-1, 1)\n",
    "for i, num in enumerate(train_sizes):\n",
    "    # run couple of times\n",
    "    for _ in range(3):\n",
    "        model = DynamicBinaryClassifier(input_size, hidden_sizes, output_size)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        trainer = BinaryClassifierTrainer(model, criterion, optimizer)\n",
    "        batch_size = 128\n",
    "\n",
    "        # Split the data into training and test sets\n",
    "        input_train, input_test, labels_train, labels_test = train_test_split(data, labels, train_size=0.2, random_state=42)\n",
    "        # get num percentage of training data\n",
    "        # train_size won't accept 1.0, resort to train size\n",
    "        temp_num=None\n",
    "        if num == 1.0:\n",
    "            temp_num = num\n",
    "            num = int(len(input_train)) - 1   # -1 to avoid empty tensor\n",
    "        input_train, _, labels_train, _ = train_test_split(input_train, labels_train, train_size=num, random_state=42)\n",
    "        if temp_num:\n",
    "            num = temp_num\n",
    "\n",
    "        # Training\n",
    "        trainer.train(input_train, labels_train, num_epochs=5000, batch_size=batch_size)\n",
    "\n",
    "        # Evaluation\n",
    "        test_accuracy = trainer.evaluate(input_test, labels_test)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "        accuracy[num].append(test_accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle save accuracy dict\n",
    "import pickle\n",
    "with open('../vary-test-size/DNN-accuracy-new.pickle', 'wb') as handle:\n",
    "    pickle.dump(accuracy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.172278</td>\n",
       "      <td>72.516283</td>\n",
       "      <td>72.745620</td>\n",
       "      <td>70.745803</td>\n",
       "      <td>70.869645</td>\n",
       "      <td>69.819283</td>\n",
       "      <td>70.470599</td>\n",
       "      <td>70.461426</td>\n",
       "      <td>68.622145</td>\n",
       "      <td>67.149803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.296211</td>\n",
       "      <td>71.970461</td>\n",
       "      <td>71.915421</td>\n",
       "      <td>70.901752</td>\n",
       "      <td>69.943124</td>\n",
       "      <td>71.511788</td>\n",
       "      <td>70.218329</td>\n",
       "      <td>70.686176</td>\n",
       "      <td>68.874415</td>\n",
       "      <td>67.608476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.773232</td>\n",
       "      <td>70.433905</td>\n",
       "      <td>71.016421</td>\n",
       "      <td>69.768829</td>\n",
       "      <td>70.672415</td>\n",
       "      <td>70.984313</td>\n",
       "      <td>70.626548</td>\n",
       "      <td>70.392625</td>\n",
       "      <td>69.209247</td>\n",
       "      <td>67.723145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1.0        0.9        0.8        0.7        0.6        0.5  \\\n",
       "0  72.172278  72.516283  72.745620  70.745803  70.869645  69.819283   \n",
       "1  71.296211  71.970461  71.915421  70.901752  69.943124  71.511788   \n",
       "2  71.773232  70.433905  71.016421  69.768829  70.672415  70.984313   \n",
       "\n",
       "         0.4        0.3        0.2        0.1  \n",
       "0  70.470599  70.461426  68.622145  67.149803  \n",
       "1  70.218329  70.686176  68.874415  67.608476  \n",
       "2  70.626548  70.392625  69.209247  67.723145  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read trained data \n",
    "with open('../vary-test-size/DNN-accuracy-new.pickle', 'rb') as handle:\n",
    "    accuracies = pickle.load(handle)\n",
    "accuracies = pd.DataFrame(accuracies)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(train_sizes, np.max(accuracies, axis=0).values)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
