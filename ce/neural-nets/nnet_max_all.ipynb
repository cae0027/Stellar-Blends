{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model for Comparison (Max-all)\n",
    "In comparison to state of the art models, we train a neural network on the normalized data including the raw data. \n",
    "Since our dataset comparises image data, a natural thing to do is compare with a CNN model. However, we do not compare with a CNN model because the resolution of the data is small. The data are 10x10 images. We trained CNN models, though but did not get any better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "\n",
    "class DynamicBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(DynamicBinaryClassifier, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "        self.hidden_layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(prev_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class BinaryClassifierTrainer:\n",
    "    def __init__(self, model, criterion, optimizer, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def _to_tensor(self, data):\n",
    "        if not torch.is_tensor(data):\n",
    "            data = torch.tensor(data, dtype=torch.float32)\n",
    "        return data.to(self.device)\n",
    "\n",
    "    def train(self, input_data, labels, num_epochs=100, batch_size=32):\n",
    "        input_data, labels = self._to_tensor(input_data), self._to_tensor(labels)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0.0\n",
    "\n",
    "            # Forward pass and calculate loss\n",
    "            for i in range(0, len(input_data), batch_size):\n",
    "                batch_input = input_data[i:i + batch_size]\n",
    "                batch_labels = labels[i:i + batch_size]\n",
    "\n",
    "                outputs = self.model(batch_input)\n",
    "                loss = self.criterion(outputs, batch_labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            average_loss = total_loss / (len(input_data) / batch_size)\n",
    "\n",
    "            # Print the average loss every 100 epochs\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {average_loss:.8f}')\n",
    "\n",
    "    def evaluate(self, input_data, labels):\n",
    "        input_data, labels = self._to_tensor(input_data), self._to_tensor(labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_data)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "\n",
    "        accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        return accuracy\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from glob import glob\n",
    "\n",
    "# Example usage:\n",
    "input_size = 100\n",
    "hidden_sizes = [70,64, 32]\n",
    "output_size = 1\n",
    "\n",
    "model = DynamicBinaryClassifier(input_size, hidden_sizes, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "trainer = BinaryClassifierTrainer(model, criterion, optimizer)\n",
    "\n",
    "start = perf_counter()\n",
    "# read data\n",
    "batch_size = 128\n",
    "files = glob('../../data/data-norm/max-pixel-all/*.csv')\n",
    "file_names = [f.split('/')[-1] for f in files]\n",
    "results = {name:[] for name in file_names}\n",
    "for name in results:\n",
    "    for _ in range(3):\n",
    "        print(name)\n",
    "        dat = pd.read_csv(f'../../data/data-norm/max-pixel-all/{name}')\n",
    "        data = dat.iloc[:, 1:].values\n",
    "        labels = dat.iloc[:, 0].values.reshape(-1, 1)\n",
    "        # Split the data into training and test sets\n",
    "        input_train, input_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "        # Training\n",
    "        trainer.train(input_train, labels_train, num_epochs=200, batch_size=batch_size)\n",
    "        # Evaluation\n",
    "        test_accuracy = trainer.evaluate(input_test, labels_test)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "        results[name].append(test_accuracy)\n",
    "data_accuracies = pd.DataFrame(results)\n",
    "data_accuracies.to_csv('../../data/data-norm/accuracies-nnet-max-all.csv', index=False)\n",
    "\n",
    "end = perf_counter()\n",
    "print(f'Total time taken: {(end-start)/60:.6f} minutes')\n",
    "# dat = pd.read_csv('../../data/data-norm/max-only/raw_image_data.csv')\n",
    "# data = dat.iloc[:, 1:].values\n",
    "# labels = dat.iloc[:, 0].values.reshape(-1, 1)\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# input_train, input_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Training\n",
    "# trainer.train(input_train, labels_train, num_epochs=1000, batch_size=32)\n",
    "\n",
    "# # Evaluation\n",
    "# test_accuracy = trainer.evaluate(input_test, labels_test)\n",
    "# print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_accuracies = pd.read_csv('../../data/data-norm/accuracies-nnet-max-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nthroot_0.4483_data.csv\n",
       "1         nthroot_0.5862.csv\n",
       "2    nthroot_0.4483_data.csv\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return column with max value\n",
    "data_accuracies.idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.774537\n",
       "1    0.777105\n",
       "2    0.774904\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(data_accuracies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idcs = np.argmax(data_accuracies.values, axis=1)\n",
    "idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nthroot_0.4483_data.csv</th>\n",
       "      <th>nthroot_0.5862.csv</th>\n",
       "      <th>nthroot_0.4483_data.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774537</td>\n",
       "      <td>0.774170</td>\n",
       "      <td>0.774537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775087</td>\n",
       "      <td>0.777105</td>\n",
       "      <td>0.775087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774904</td>\n",
       "      <td>0.770501</td>\n",
       "      <td>0.774904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nthroot_0.4483_data.csv  nthroot_0.5862.csv  nthroot_0.4483_data.csv\n",
       "0                 0.774537            0.774170                 0.774537\n",
       "1                 0.775087            0.777105                 0.775087\n",
       "2                 0.774904            0.770501                 0.774904"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_accuracies.iloc[:, idcs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all normalizations as well as the raw data, the $r^{th}$ with max-all over each image performs the best at an average of $77\\%$ accuracy on $20\\%$ test data for neural nets models. So judging from these runs, we conlcude that for neural net models, dividing each pixel with the absolute max over the entire dataset is more benefitial than dividing by max over each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nthroot_0.4483_data.csv    0.774843\n",
       "nthroot_0.5862.csv         0.773925\n",
       "nthroot_0.5862_data.csv    0.766587\n",
       "nthroot_0.7931.csv         0.763346\n",
       "nthroot_0.5172.csv         0.752278\n",
       "nthroot_1.0.csv            0.750199\n",
       "norm_1_data.csv            0.747875\n",
       "nthroot_0.4828.csv         0.737541\n",
       "norm_41_data.csv           0.631383\n",
       "norm_31_data.csv           0.618908\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_accuracies.mean(axis=0).nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary Test Size\n",
    "We check DNN performance when the test size changes. Use the top performing normalization `nthroot_0.5862.csv` file as well the optimized DNN hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/5000], Average Loss: 0.56027412\n",
      "Epoch [200/5000], Average Loss: 0.54288551\n",
      "Epoch [300/5000], Average Loss: 0.53296017\n",
      "Epoch [400/5000], Average Loss: 0.52590078\n",
      "Epoch [500/5000], Average Loss: 0.51945489\n",
      "Epoch [600/5000], Average Loss: 0.51416018\n",
      "Epoch [700/5000], Average Loss: 0.50857543\n",
      "Epoch [800/5000], Average Loss: 0.50308598\n",
      "Epoch [900/5000], Average Loss: 0.49851373\n",
      "Epoch [1000/5000], Average Loss: 0.49383590\n",
      "Epoch [1100/5000], Average Loss: 0.48985659\n",
      "Epoch [1200/5000], Average Loss: 0.48610622\n",
      "Epoch [1300/5000], Average Loss: 0.48283778\n",
      "Epoch [1400/5000], Average Loss: 0.47792443\n",
      "Epoch [1500/5000], Average Loss: 0.47397124\n",
      "Epoch [1600/5000], Average Loss: 0.47033251\n",
      "Epoch [1700/5000], Average Loss: 0.46695641\n",
      "Epoch [1800/5000], Average Loss: 0.46406452\n",
      "Epoch [1900/5000], Average Loss: 0.46001719\n",
      "Epoch [2000/5000], Average Loss: 0.45782523\n",
      "Epoch [2100/5000], Average Loss: 0.45445795\n",
      "Epoch [2200/5000], Average Loss: 0.45091650\n",
      "Epoch [2300/5000], Average Loss: 0.44766234\n",
      "Epoch [2400/5000], Average Loss: 0.44553882\n",
      "Epoch [2500/5000], Average Loss: 0.44260642\n",
      "Epoch [2600/5000], Average Loss: 0.44019016\n",
      "Epoch [2700/5000], Average Loss: 0.43752432\n",
      "Epoch [2800/5000], Average Loss: 0.43480853\n",
      "Epoch [2900/5000], Average Loss: 0.43348074\n",
      "Epoch [3000/5000], Average Loss: 0.43071498\n",
      "Epoch [3100/5000], Average Loss: 0.42812140\n",
      "Epoch [3200/5000], Average Loss: 0.42652463\n",
      "Epoch [3300/5000], Average Loss: 0.42427102\n",
      "Epoch [3400/5000], Average Loss: 0.42187310\n",
      "Epoch [3500/5000], Average Loss: 0.41907948\n",
      "Epoch [3600/5000], Average Loss: 0.41803021\n",
      "Epoch [3700/5000], Average Loss: 0.41690262\n",
      "Epoch [3800/5000], Average Loss: 0.41409840\n",
      "Epoch [3900/5000], Average Loss: 0.41322136\n",
      "Epoch [4000/5000], Average Loss: 0.40978791\n",
      "Epoch [4100/5000], Average Loss: 0.40747764\n",
      "Epoch [4200/5000], Average Loss: 0.40433654\n",
      "Epoch [4300/5000], Average Loss: 0.40250512\n",
      "Epoch [4400/5000], Average Loss: 0.40058206\n",
      "Epoch [4500/5000], Average Loss: 0.39943985\n",
      "Epoch [4600/5000], Average Loss: 0.39675494\n",
      "Epoch [4700/5000], Average Loss: 0.39830298\n",
      "Epoch [4800/5000], Average Loss: 0.39659322\n",
      "Epoch [4900/5000], Average Loss: 0.39018632\n",
      "Epoch [5000/5000], Average Loss: 0.38873195\n",
      "Test Accuracy: 0.7693\n",
      "Epoch [100/5000], Average Loss: 0.56352071\n",
      "Epoch [200/5000], Average Loss: 0.54533824\n",
      "Epoch [300/5000], Average Loss: 0.53464930\n",
      "Epoch [400/5000], Average Loss: 0.52561905\n",
      "Epoch [500/5000], Average Loss: 0.51817480\n",
      "Epoch [600/5000], Average Loss: 0.51106714\n",
      "Epoch [700/5000], Average Loss: 0.50608059\n",
      "Epoch [800/5000], Average Loss: 0.50064444\n",
      "Epoch [900/5000], Average Loss: 0.49515725\n",
      "Epoch [1000/5000], Average Loss: 0.49060682\n",
      "Epoch [1100/5000], Average Loss: 0.48603882\n",
      "Epoch [1200/5000], Average Loss: 0.48170206\n",
      "Epoch [1300/5000], Average Loss: 0.47724937\n",
      "Epoch [1400/5000], Average Loss: 0.47234718\n",
      "Epoch [1500/5000], Average Loss: 0.46786857\n",
      "Epoch [1600/5000], Average Loss: 0.46424921\n",
      "Epoch [1700/5000], Average Loss: 0.46062381\n",
      "Epoch [1800/5000], Average Loss: 0.45802537\n",
      "Epoch [1900/5000], Average Loss: 0.45426163\n",
      "Epoch [2000/5000], Average Loss: 0.45185681\n",
      "Epoch [2100/5000], Average Loss: 0.44833929\n",
      "Epoch [2200/5000], Average Loss: 0.44489613\n",
      "Epoch [2300/5000], Average Loss: 0.44218388\n",
      "Epoch [2400/5000], Average Loss: 0.43921051\n",
      "Epoch [2500/5000], Average Loss: 0.43690105\n",
      "Epoch [2600/5000], Average Loss: 0.43269175\n",
      "Epoch [2700/5000], Average Loss: 0.43126720\n",
      "Epoch [2800/5000], Average Loss: 0.42874210\n",
      "Epoch [2900/5000], Average Loss: 0.42549290\n",
      "Epoch [3000/5000], Average Loss: 0.42378154\n",
      "Epoch [3100/5000], Average Loss: 0.42093564\n",
      "Epoch [3200/5000], Average Loss: 0.41828184\n",
      "Epoch [3300/5000], Average Loss: 0.41555959\n",
      "Epoch [3400/5000], Average Loss: 0.41293186\n",
      "Epoch [3500/5000], Average Loss: 0.41055942\n",
      "Epoch [3600/5000], Average Loss: 0.40858506\n",
      "Epoch [3700/5000], Average Loss: 0.40642195\n",
      "Epoch [3800/5000], Average Loss: 0.40401210\n",
      "Epoch [3900/5000], Average Loss: 0.40000405\n",
      "Epoch [4000/5000], Average Loss: 0.39806054\n",
      "Epoch [4100/5000], Average Loss: 0.39649116\n",
      "Epoch [4200/5000], Average Loss: 0.39422325\n",
      "Epoch [4300/5000], Average Loss: 0.39264750\n",
      "Epoch [4400/5000], Average Loss: 0.39123722\n",
      "Epoch [4500/5000], Average Loss: 0.38943657\n",
      "Epoch [4600/5000], Average Loss: 0.38715423\n",
      "Epoch [4700/5000], Average Loss: 0.38539364\n",
      "Epoch [4800/5000], Average Loss: 0.40207941\n",
      "Epoch [4900/5000], Average Loss: 0.38205155\n",
      "Epoch [5000/5000], Average Loss: 0.38089269\n",
      "Test Accuracy: 0.7737\n",
      "Epoch [100/5000], Average Loss: 0.56018072\n",
      "Epoch [200/5000], Average Loss: 0.54368818\n",
      "Epoch [300/5000], Average Loss: 0.53265930\n",
      "Epoch [400/5000], Average Loss: 0.52449903\n",
      "Epoch [500/5000], Average Loss: 0.51890402\n",
      "Epoch [600/5000], Average Loss: 0.51349773\n",
      "Epoch [700/5000], Average Loss: 0.50863614\n",
      "Epoch [800/5000], Average Loss: 0.50416633\n",
      "Epoch [900/5000], Average Loss: 0.49979628\n",
      "Epoch [1000/5000], Average Loss: 0.49332280\n",
      "Epoch [1100/5000], Average Loss: 0.48830128\n",
      "Epoch [1200/5000], Average Loss: 0.48319351\n",
      "Epoch [1300/5000], Average Loss: 0.47893305\n",
      "Epoch [1400/5000], Average Loss: 0.47459335\n",
      "Epoch [1500/5000], Average Loss: 0.47120089\n",
      "Epoch [1600/5000], Average Loss: 0.46771518\n",
      "Epoch [1700/5000], Average Loss: 0.46472209\n",
      "Epoch [1800/5000], Average Loss: 0.46135241\n",
      "Epoch [1900/5000], Average Loss: 0.45803089\n",
      "Epoch [2000/5000], Average Loss: 0.45575176\n",
      "Epoch [2100/5000], Average Loss: 0.45266863\n",
      "Epoch [2200/5000], Average Loss: 0.45001037\n",
      "Epoch [2300/5000], Average Loss: 0.44604592\n",
      "Epoch [2400/5000], Average Loss: 0.44350234\n",
      "Epoch [2500/5000], Average Loss: 0.44037115\n",
      "Epoch [2600/5000], Average Loss: 0.43812010\n",
      "Epoch [2700/5000], Average Loss: 0.43478554\n",
      "Epoch [2800/5000], Average Loss: 0.43118457\n",
      "Epoch [2900/5000], Average Loss: 0.42970042\n",
      "Epoch [3000/5000], Average Loss: 0.42676796\n",
      "Epoch [3100/5000], Average Loss: 0.42392154\n",
      "Epoch [3200/5000], Average Loss: 0.42292758\n",
      "Epoch [3300/5000], Average Loss: 0.41948773\n",
      "Epoch [3400/5000], Average Loss: 0.41710780\n",
      "Epoch [3500/5000], Average Loss: 0.41459779\n",
      "Epoch [3600/5000], Average Loss: 0.41248358\n",
      "Epoch [3700/5000], Average Loss: 0.41033590\n",
      "Epoch [3800/5000], Average Loss: 0.40835026\n",
      "Epoch [3900/5000], Average Loss: 0.40672797\n",
      "Epoch [4000/5000], Average Loss: 0.40482668\n",
      "Epoch [4100/5000], Average Loss: 0.40286923\n",
      "Epoch [4200/5000], Average Loss: 0.39949411\n",
      "Epoch [4300/5000], Average Loss: 0.39813302\n",
      "Epoch [4400/5000], Average Loss: 0.39781921\n",
      "Epoch [4500/5000], Average Loss: 0.39527920\n",
      "Epoch [4600/5000], Average Loss: 0.39303214\n",
      "Epoch [4700/5000], Average Loss: 0.39116952\n",
      "Epoch [4800/5000], Average Loss: 0.38869788\n",
      "Epoch [4900/5000], Average Loss: 0.38746935\n",
      "Epoch [5000/5000], Average Loss: 0.38492181\n",
      "Test Accuracy: 0.7634\n",
      "Epoch [100/5000], Average Loss: 0.56787565\n",
      "Epoch [200/5000], Average Loss: 0.54716794\n",
      "Epoch [300/5000], Average Loss: 0.53897272\n",
      "Epoch [400/5000], Average Loss: 0.53194402\n",
      "Epoch [500/5000], Average Loss: 0.52601300\n",
      "Epoch [600/5000], Average Loss: 0.51913029\n",
      "Epoch [700/5000], Average Loss: 0.51300057\n",
      "Epoch [800/5000], Average Loss: 0.50712376\n",
      "Epoch [900/5000], Average Loss: 0.50101138\n",
      "Epoch [1000/5000], Average Loss: 0.49621109\n",
      "Epoch [1100/5000], Average Loss: 0.49149479\n",
      "Epoch [1200/5000], Average Loss: 0.48748906\n",
      "Epoch [1300/5000], Average Loss: 0.48307265\n",
      "Epoch [1400/5000], Average Loss: 0.47936909\n",
      "Epoch [1500/5000], Average Loss: 0.47608099\n",
      "Epoch [1600/5000], Average Loss: 0.47219855\n",
      "Epoch [1700/5000], Average Loss: 0.46889460\n",
      "Epoch [1800/5000], Average Loss: 0.46583291\n",
      "Epoch [1900/5000], Average Loss: 0.46269174\n",
      "Epoch [2000/5000], Average Loss: 0.45929611\n",
      "Epoch [2100/5000], Average Loss: 0.45619136\n",
      "Epoch [2200/5000], Average Loss: 0.45224529\n",
      "Epoch [2300/5000], Average Loss: 0.44901732\n",
      "Epoch [2400/5000], Average Loss: 0.44601075\n",
      "Epoch [2500/5000], Average Loss: 0.44291258\n",
      "Epoch [2600/5000], Average Loss: 0.44775691\n",
      "Epoch [2700/5000], Average Loss: 0.43666500\n",
      "Epoch [2800/5000], Average Loss: 0.43485148\n",
      "Epoch [2900/5000], Average Loss: 0.43186485\n",
      "Epoch [3000/5000], Average Loss: 0.42937683\n",
      "Epoch [3100/5000], Average Loss: 0.42691341\n",
      "Epoch [3200/5000], Average Loss: 0.42472359\n",
      "Epoch [3300/5000], Average Loss: 0.42207469\n",
      "Epoch [3400/5000], Average Loss: 0.41936288\n",
      "Epoch [3500/5000], Average Loss: 0.41783087\n",
      "Epoch [3600/5000], Average Loss: 0.41557560\n",
      "Epoch [3700/5000], Average Loss: 0.41391270\n",
      "Epoch [3800/5000], Average Loss: 0.41266283\n",
      "Epoch [3900/5000], Average Loss: 0.40917071\n",
      "Epoch [4000/5000], Average Loss: 0.40664835\n",
      "Epoch [4100/5000], Average Loss: 0.40505684\n",
      "Epoch [4200/5000], Average Loss: 0.40276765\n",
      "Epoch [4300/5000], Average Loss: 0.40028825\n",
      "Epoch [4400/5000], Average Loss: 0.39882455\n",
      "Epoch [4500/5000], Average Loss: 0.39617144\n",
      "Epoch [4600/5000], Average Loss: 0.39477223\n",
      "Epoch [4700/5000], Average Loss: 0.39240308\n",
      "Epoch [4800/5000], Average Loss: 0.39137145\n",
      "Epoch [4900/5000], Average Loss: 0.38753713\n",
      "Epoch [5000/5000], Average Loss: 0.38619376\n",
      "Test Accuracy: 0.7536\n",
      "Epoch [100/5000], Average Loss: 0.57331704\n",
      "Epoch [200/5000], Average Loss: 0.55297909\n",
      "Epoch [300/5000], Average Loss: 0.54344800\n",
      "Epoch [400/5000], Average Loss: 0.53570535\n",
      "Epoch [500/5000], Average Loss: 0.52887528\n",
      "Epoch [600/5000], Average Loss: 0.52298674\n",
      "Epoch [700/5000], Average Loss: 0.51761544\n",
      "Epoch [800/5000], Average Loss: 0.51217252\n",
      "Epoch [900/5000], Average Loss: 0.50777209\n",
      "Epoch [1000/5000], Average Loss: 0.50358444\n",
      "Epoch [1100/5000], Average Loss: 0.49964024\n",
      "Epoch [1200/5000], Average Loss: 0.49592538\n",
      "Epoch [1300/5000], Average Loss: 0.49025632\n",
      "Epoch [1400/5000], Average Loss: 0.48638226\n",
      "Epoch [1500/5000], Average Loss: 0.48260860\n",
      "Epoch [1600/5000], Average Loss: 0.47989553\n",
      "Epoch [1700/5000], Average Loss: 0.47625365\n",
      "Epoch [1800/5000], Average Loss: 0.47305451\n",
      "Epoch [1900/5000], Average Loss: 0.46974758\n",
      "Epoch [2000/5000], Average Loss: 0.46704845\n",
      "Epoch [2100/5000], Average Loss: 0.46380200\n",
      "Epoch [2200/5000], Average Loss: 0.46154478\n",
      "Epoch [2300/5000], Average Loss: 0.45894463\n",
      "Epoch [2400/5000], Average Loss: 0.45587636\n",
      "Epoch [2500/5000], Average Loss: 0.45346256\n",
      "Epoch [2600/5000], Average Loss: 0.45149749\n",
      "Epoch [2700/5000], Average Loss: 0.44875596\n",
      "Epoch [2800/5000], Average Loss: 0.44603435\n",
      "Epoch [2900/5000], Average Loss: 0.44409983\n",
      "Epoch [3000/5000], Average Loss: 0.44160933\n",
      "Epoch [3100/5000], Average Loss: 0.43935317\n",
      "Epoch [3200/5000], Average Loss: 0.43738426\n",
      "Epoch [3300/5000], Average Loss: 0.43566173\n",
      "Epoch [3400/5000], Average Loss: 0.43247236\n",
      "Epoch [3500/5000], Average Loss: 0.43064681\n",
      "Epoch [3600/5000], Average Loss: 0.42718944\n",
      "Epoch [3700/5000], Average Loss: 0.42604570\n",
      "Epoch [3800/5000], Average Loss: 0.42339391\n",
      "Epoch [3900/5000], Average Loss: 0.42134158\n",
      "Epoch [4000/5000], Average Loss: 0.41930772\n",
      "Epoch [4100/5000], Average Loss: 0.41780910\n",
      "Epoch [4200/5000], Average Loss: 0.41589932\n",
      "Epoch [4300/5000], Average Loss: 0.41389738\n",
      "Epoch [4400/5000], Average Loss: 0.41221502\n",
      "Epoch [4500/5000], Average Loss: 0.41036153\n",
      "Epoch [4600/5000], Average Loss: 0.40827874\n",
      "Epoch [4700/5000], Average Loss: 0.40673954\n",
      "Epoch [4800/5000], Average Loss: 0.40513430\n",
      "Epoch [4900/5000], Average Loss: 0.40331464\n",
      "Epoch [5000/5000], Average Loss: 0.40148173\n",
      "Test Accuracy: 0.7411\n",
      "Epoch [100/5000], Average Loss: 0.57641982\n",
      "Epoch [200/5000], Average Loss: 0.55118112\n",
      "Epoch [300/5000], Average Loss: 0.54063513\n",
      "Epoch [400/5000], Average Loss: 0.53207150\n",
      "Epoch [500/5000], Average Loss: 0.52429332\n",
      "Epoch [600/5000], Average Loss: 0.51871395\n",
      "Epoch [700/5000], Average Loss: 0.51406173\n",
      "Epoch [800/5000], Average Loss: 0.50881528\n",
      "Epoch [900/5000], Average Loss: 0.50463364\n",
      "Epoch [1000/5000], Average Loss: 0.49957780\n",
      "Epoch [1100/5000], Average Loss: 0.49481156\n",
      "Epoch [1200/5000], Average Loss: 0.49133886\n",
      "Epoch [1300/5000], Average Loss: 0.48590778\n",
      "Epoch [1400/5000], Average Loss: 0.48227975\n",
      "Epoch [1500/5000], Average Loss: 0.47877433\n",
      "Epoch [1600/5000], Average Loss: 0.47517547\n",
      "Epoch [1700/5000], Average Loss: 0.47039935\n",
      "Epoch [1800/5000], Average Loss: 0.46707930\n",
      "Epoch [1900/5000], Average Loss: 0.46429218\n",
      "Epoch [2000/5000], Average Loss: 0.46060038\n",
      "Epoch [2100/5000], Average Loss: 0.45756487\n",
      "Epoch [2200/5000], Average Loss: 0.45447972\n",
      "Epoch [2300/5000], Average Loss: 0.45208040\n",
      "Epoch [2400/5000], Average Loss: 0.44927295\n",
      "Epoch [2500/5000], Average Loss: 0.44464870\n",
      "Epoch [2600/5000], Average Loss: 0.44129244\n",
      "Epoch [2700/5000], Average Loss: 0.43772392\n",
      "Epoch [2800/5000], Average Loss: 0.43432608\n",
      "Epoch [2900/5000], Average Loss: 0.43184475\n",
      "Epoch [3000/5000], Average Loss: 0.42794015\n",
      "Epoch [3100/5000], Average Loss: 0.42653620\n",
      "Epoch [3200/5000], Average Loss: 0.42314051\n",
      "Epoch [3300/5000], Average Loss: 0.42002103\n",
      "Epoch [3400/5000], Average Loss: 0.41802224\n",
      "Epoch [3500/5000], Average Loss: 0.41684423\n",
      "Epoch [3600/5000], Average Loss: 0.41467352\n",
      "Epoch [3700/5000], Average Loss: 0.41729320\n",
      "Epoch [3800/5000], Average Loss: 0.40933243\n",
      "Epoch [3900/5000], Average Loss: 0.40753198\n",
      "Epoch [4000/5000], Average Loss: 0.40506363\n",
      "Epoch [4100/5000], Average Loss: 0.40362687\n",
      "Epoch [4200/5000], Average Loss: 0.40072487\n",
      "Epoch [4300/5000], Average Loss: 0.39850550\n",
      "Epoch [4400/5000], Average Loss: 0.39612913\n",
      "Epoch [4500/5000], Average Loss: 0.39422662\n",
      "Epoch [4600/5000], Average Loss: 0.39218854\n",
      "Epoch [4700/5000], Average Loss: 0.39163335\n",
      "Epoch [4800/5000], Average Loss: 0.38819617\n",
      "Epoch [4900/5000], Average Loss: 0.38631759\n",
      "Epoch [5000/5000], Average Loss: 0.38586568\n",
      "Test Accuracy: 0.7564\n",
      "Epoch [100/5000], Average Loss: 0.56406400\n",
      "Epoch [200/5000], Average Loss: 0.54651582\n",
      "Epoch [300/5000], Average Loss: 0.53667868\n",
      "Epoch [400/5000], Average Loss: 0.52969887\n",
      "Epoch [500/5000], Average Loss: 0.52266032\n",
      "Epoch [600/5000], Average Loss: 0.51644601\n",
      "Epoch [700/5000], Average Loss: 0.50948245\n",
      "Epoch [800/5000], Average Loss: 0.50398396\n",
      "Epoch [900/5000], Average Loss: 0.49894620\n",
      "Epoch [1000/5000], Average Loss: 0.49344756\n",
      "Epoch [1100/5000], Average Loss: 0.48871331\n",
      "Epoch [1200/5000], Average Loss: 0.48411066\n",
      "Epoch [1300/5000], Average Loss: 0.48012497\n",
      "Epoch [1400/5000], Average Loss: 0.47556792\n",
      "Epoch [1500/5000], Average Loss: 0.47124401\n",
      "Epoch [1600/5000], Average Loss: 0.46817896\n",
      "Epoch [1700/5000], Average Loss: 0.46586137\n",
      "Epoch [1800/5000], Average Loss: 0.46153332\n",
      "Epoch [1900/5000], Average Loss: 0.45881965\n",
      "Epoch [2000/5000], Average Loss: 0.45438314\n",
      "Epoch [2100/5000], Average Loss: 0.45110940\n",
      "Epoch [2200/5000], Average Loss: 0.44893756\n",
      "Epoch [2300/5000], Average Loss: 0.44622228\n",
      "Epoch [2400/5000], Average Loss: 0.44363147\n",
      "Epoch [2500/5000], Average Loss: 0.44085903\n",
      "Epoch [2600/5000], Average Loss: 0.43833020\n",
      "Epoch [2700/5000], Average Loss: 0.43677433\n",
      "Epoch [2800/5000], Average Loss: 0.43381685\n",
      "Epoch [2900/5000], Average Loss: 0.43015198\n",
      "Epoch [3000/5000], Average Loss: 0.42776682\n",
      "Epoch [3100/5000], Average Loss: 0.42621942\n",
      "Epoch [3200/5000], Average Loss: 0.42299352\n",
      "Epoch [3300/5000], Average Loss: 0.41927679\n",
      "Epoch [3400/5000], Average Loss: 0.41711993\n",
      "Epoch [3500/5000], Average Loss: 0.41505837\n",
      "Epoch [3600/5000], Average Loss: 0.41306592\n",
      "Epoch [3700/5000], Average Loss: 0.41049956\n",
      "Epoch [3800/5000], Average Loss: 0.40829131\n",
      "Epoch [3900/5000], Average Loss: 0.40548960\n",
      "Epoch [4000/5000], Average Loss: 0.40456207\n",
      "Epoch [4100/5000], Average Loss: 0.40246725\n",
      "Epoch [4200/5000], Average Loss: 0.40047451\n",
      "Epoch [4300/5000], Average Loss: 0.39849979\n",
      "Epoch [4400/5000], Average Loss: 0.39658151\n",
      "Epoch [4500/5000], Average Loss: 0.39476098\n",
      "Epoch [4600/5000], Average Loss: 0.39306650\n",
      "Epoch [4700/5000], Average Loss: 0.38955198\n",
      "Epoch [4800/5000], Average Loss: 0.38991377\n",
      "Epoch [4900/5000], Average Loss: 0.38826963\n",
      "Epoch [5000/5000], Average Loss: 0.38460126\n",
      "Test Accuracy: 0.7491\n",
      "Epoch [100/5000], Average Loss: 0.56735594\n",
      "Epoch [200/5000], Average Loss: 0.54519132\n",
      "Epoch [300/5000], Average Loss: 0.53318377\n",
      "Epoch [400/5000], Average Loss: 0.52260588\n",
      "Epoch [500/5000], Average Loss: 0.51398081\n",
      "Epoch [600/5000], Average Loss: 0.50648291\n",
      "Epoch [700/5000], Average Loss: 0.50124924\n",
      "Epoch [800/5000], Average Loss: 0.49647976\n",
      "Epoch [900/5000], Average Loss: 0.49216022\n",
      "Epoch [1000/5000], Average Loss: 0.48825077\n",
      "Epoch [1100/5000], Average Loss: 0.48370082\n",
      "Epoch [1200/5000], Average Loss: 0.48023444\n",
      "Epoch [1300/5000], Average Loss: 0.47715574\n",
      "Epoch [1400/5000], Average Loss: 0.47256136\n",
      "Epoch [1500/5000], Average Loss: 0.46871768\n",
      "Epoch [1600/5000], Average Loss: 0.46494811\n",
      "Epoch [1700/5000], Average Loss: 0.46269742\n",
      "Epoch [1800/5000], Average Loss: 0.45939174\n",
      "Epoch [1900/5000], Average Loss: 0.45538852\n",
      "Epoch [2000/5000], Average Loss: 0.45033587\n",
      "Epoch [2100/5000], Average Loss: 0.44704095\n",
      "Epoch [2200/5000], Average Loss: 0.44370003\n",
      "Epoch [2300/5000], Average Loss: 0.43990277\n",
      "Epoch [2400/5000], Average Loss: 0.43553148\n",
      "Epoch [2500/5000], Average Loss: 0.43153790\n",
      "Epoch [2600/5000], Average Loss: 0.43027892\n",
      "Epoch [2700/5000], Average Loss: 0.42555031\n",
      "Epoch [2800/5000], Average Loss: 0.42244826\n",
      "Epoch [2900/5000], Average Loss: 0.41975492\n",
      "Epoch [3000/5000], Average Loss: 0.41732124\n",
      "Epoch [3100/5000], Average Loss: 0.41536523\n",
      "Epoch [3200/5000], Average Loss: 0.41337503\n",
      "Epoch [3300/5000], Average Loss: 0.40981589\n",
      "Epoch [3400/5000], Average Loss: 0.40760218\n",
      "Epoch [3500/5000], Average Loss: 0.40492126\n",
      "Epoch [3600/5000], Average Loss: 0.40825984\n",
      "Epoch [3700/5000], Average Loss: 0.40059227\n",
      "Epoch [3800/5000], Average Loss: 0.39866287\n",
      "Epoch [3900/5000], Average Loss: 0.39725693\n",
      "Epoch [4000/5000], Average Loss: 0.40300412\n",
      "Epoch [4100/5000], Average Loss: 0.39227173\n",
      "Epoch [4200/5000], Average Loss: 0.38931495\n",
      "Epoch [4300/5000], Average Loss: 0.38699477\n",
      "Epoch [4400/5000], Average Loss: 0.38414821\n",
      "Epoch [4500/5000], Average Loss: 0.38349209\n",
      "Epoch [4600/5000], Average Loss: 0.38138260\n",
      "Epoch [4700/5000], Average Loss: 0.37989977\n",
      "Epoch [4800/5000], Average Loss: 0.37731737\n",
      "Epoch [4900/5000], Average Loss: 0.37513402\n",
      "Epoch [5000/5000], Average Loss: 0.37486790\n",
      "Test Accuracy: 0.7513\n",
      "Epoch [100/5000], Average Loss: 0.57190741\n",
      "Epoch [200/5000], Average Loss: 0.54723572\n",
      "Epoch [300/5000], Average Loss: 0.53565944\n",
      "Epoch [400/5000], Average Loss: 0.52698362\n",
      "Epoch [500/5000], Average Loss: 0.52011658\n",
      "Epoch [600/5000], Average Loss: 0.51526093\n",
      "Epoch [700/5000], Average Loss: 0.51009370\n",
      "Epoch [800/5000], Average Loss: 0.50602237\n",
      "Epoch [900/5000], Average Loss: 0.50250210\n",
      "Epoch [1000/5000], Average Loss: 0.49908615\n",
      "Epoch [1100/5000], Average Loss: 0.49511895\n",
      "Epoch [1200/5000], Average Loss: 0.49168235\n",
      "Epoch [1300/5000], Average Loss: 0.48873541\n",
      "Epoch [1400/5000], Average Loss: 0.48433421\n",
      "Epoch [1500/5000], Average Loss: 0.48169521\n",
      "Epoch [1600/5000], Average Loss: 0.47937379\n",
      "Epoch [1700/5000], Average Loss: 0.47654660\n",
      "Epoch [1800/5000], Average Loss: 0.47415437\n",
      "Epoch [1900/5000], Average Loss: 0.47093992\n",
      "Epoch [2000/5000], Average Loss: 0.46898637\n",
      "Epoch [2100/5000], Average Loss: 0.46529707\n",
      "Epoch [2200/5000], Average Loss: 0.46365305\n",
      "Epoch [2300/5000], Average Loss: 0.46162021\n",
      "Epoch [2400/5000], Average Loss: 0.45902423\n",
      "Epoch [2500/5000], Average Loss: 0.45666963\n",
      "Epoch [2600/5000], Average Loss: 0.45488309\n",
      "Epoch [2700/5000], Average Loss: 0.45302203\n",
      "Epoch [2800/5000], Average Loss: 0.44985454\n",
      "Epoch [2900/5000], Average Loss: 0.44833155\n",
      "Epoch [3000/5000], Average Loss: 0.44562436\n",
      "Epoch [3100/5000], Average Loss: 0.44366343\n",
      "Epoch [3200/5000], Average Loss: 0.44181545\n",
      "Epoch [3300/5000], Average Loss: 0.43848076\n",
      "Epoch [3400/5000], Average Loss: 0.43693226\n",
      "Epoch [3500/5000], Average Loss: 0.43516994\n",
      "Epoch [3600/5000], Average Loss: 0.43230352\n",
      "Epoch [3700/5000], Average Loss: 0.43036582\n",
      "Epoch [3800/5000], Average Loss: 0.42916269\n",
      "Epoch [3900/5000], Average Loss: 0.42690669\n",
      "Epoch [4000/5000], Average Loss: 0.42423806\n",
      "Epoch [4100/5000], Average Loss: 0.42312901\n",
      "Epoch [4200/5000], Average Loss: 0.42056070\n",
      "Epoch [4300/5000], Average Loss: 0.41918943\n",
      "Epoch [4400/5000], Average Loss: 0.41692141\n",
      "Epoch [4500/5000], Average Loss: 0.41512162\n",
      "Epoch [4600/5000], Average Loss: 0.41551620\n",
      "Epoch [4700/5000], Average Loss: 0.41215892\n",
      "Epoch [4800/5000], Average Loss: 0.41048123\n",
      "Epoch [4900/5000], Average Loss: 0.40863071\n",
      "Epoch [5000/5000], Average Loss: 0.40702699\n",
      "Test Accuracy: 0.7462\n",
      "Epoch [100/5000], Average Loss: 0.57570986\n",
      "Epoch [200/5000], Average Loss: 0.54900012\n",
      "Epoch [300/5000], Average Loss: 0.53894958\n",
      "Epoch [400/5000], Average Loss: 0.53170500\n",
      "Epoch [500/5000], Average Loss: 0.52558273\n",
      "Epoch [600/5000], Average Loss: 0.52003704\n",
      "Epoch [700/5000], Average Loss: 0.51500735\n",
      "Epoch [800/5000], Average Loss: 0.50990013\n",
      "Epoch [900/5000], Average Loss: 0.50525947\n",
      "Epoch [1000/5000], Average Loss: 0.50127947\n",
      "Epoch [1100/5000], Average Loss: 0.49778740\n",
      "Epoch [1200/5000], Average Loss: 0.49286543\n",
      "Epoch [1300/5000], Average Loss: 0.48788552\n",
      "Epoch [1400/5000], Average Loss: 0.48286539\n",
      "Epoch [1500/5000], Average Loss: 0.47814744\n",
      "Epoch [1600/5000], Average Loss: 0.47384919\n",
      "Epoch [1700/5000], Average Loss: 0.46866063\n",
      "Epoch [1800/5000], Average Loss: 0.46522248\n",
      "Epoch [1900/5000], Average Loss: 0.46219587\n",
      "Epoch [2000/5000], Average Loss: 0.45830941\n",
      "Epoch [2100/5000], Average Loss: 0.45449271\n",
      "Epoch [2200/5000], Average Loss: 0.45184059\n",
      "Epoch [2300/5000], Average Loss: 0.44902096\n",
      "Epoch [2400/5000], Average Loss: 0.44720251\n",
      "Epoch [2500/5000], Average Loss: 0.44403098\n",
      "Epoch [2600/5000], Average Loss: 0.44126097\n",
      "Epoch [2700/5000], Average Loss: 0.43855606\n",
      "Epoch [2800/5000], Average Loss: 0.43640714\n",
      "Epoch [2900/5000], Average Loss: 0.43334348\n",
      "Epoch [3000/5000], Average Loss: 0.43080574\n",
      "Epoch [3100/5000], Average Loss: 0.42990762\n",
      "Epoch [3200/5000], Average Loss: 0.42761064\n",
      "Epoch [3300/5000], Average Loss: 0.42430029\n",
      "Epoch [3400/5000], Average Loss: 0.42281818\n",
      "Epoch [3500/5000], Average Loss: 0.42073280\n",
      "Epoch [3600/5000], Average Loss: 0.41884941\n",
      "Epoch [3700/5000], Average Loss: 0.41589535\n",
      "Epoch [3800/5000], Average Loss: 0.41507080\n",
      "Epoch [3900/5000], Average Loss: 0.41258250\n",
      "Epoch [4000/5000], Average Loss: 0.41089159\n",
      "Epoch [4100/5000], Average Loss: 0.40800838\n",
      "Epoch [4200/5000], Average Loss: 0.40640877\n",
      "Epoch [4300/5000], Average Loss: 0.40500405\n",
      "Epoch [4400/5000], Average Loss: 0.40335805\n",
      "Epoch [4500/5000], Average Loss: 0.40051543\n",
      "Epoch [4600/5000], Average Loss: 0.39890910\n",
      "Epoch [4700/5000], Average Loss: 0.39673559\n",
      "Epoch [4800/5000], Average Loss: 0.39503847\n",
      "Epoch [4900/5000], Average Loss: 0.39369153\n",
      "Epoch [5000/5000], Average Loss: 0.39613014\n",
      "Test Accuracy: 0.7395\n",
      "Epoch [100/5000], Average Loss: 0.56874385\n",
      "Epoch [200/5000], Average Loss: 0.54635221\n",
      "Epoch [300/5000], Average Loss: 0.53562434\n",
      "Epoch [400/5000], Average Loss: 0.52709399\n",
      "Epoch [500/5000], Average Loss: 0.52012519\n",
      "Epoch [600/5000], Average Loss: 0.51402221\n",
      "Epoch [700/5000], Average Loss: 0.50864164\n",
      "Epoch [800/5000], Average Loss: 0.50344837\n",
      "Epoch [900/5000], Average Loss: 0.49834510\n",
      "Epoch [1000/5000], Average Loss: 0.49346300\n",
      "Epoch [1100/5000], Average Loss: 0.48903660\n",
      "Epoch [1200/5000], Average Loss: 0.48544077\n",
      "Epoch [1300/5000], Average Loss: 0.48132109\n",
      "Epoch [1400/5000], Average Loss: 0.47684896\n",
      "Epoch [1500/5000], Average Loss: 0.47170188\n",
      "Epoch [1600/5000], Average Loss: 0.46747103\n",
      "Epoch [1700/5000], Average Loss: 0.46507055\n",
      "Epoch [1800/5000], Average Loss: 0.46096175\n",
      "Epoch [1900/5000], Average Loss: 0.45828868\n",
      "Epoch [2000/5000], Average Loss: 0.45434561\n",
      "Epoch [2100/5000], Average Loss: 0.45085887\n",
      "Epoch [2200/5000], Average Loss: 0.44810841\n",
      "Epoch [2300/5000], Average Loss: 0.44469173\n",
      "Epoch [2400/5000], Average Loss: 0.44166935\n",
      "Epoch [2500/5000], Average Loss: 0.43868699\n",
      "Epoch [2600/5000], Average Loss: 0.43570751\n",
      "Epoch [2700/5000], Average Loss: 0.43308406\n",
      "Epoch [2800/5000], Average Loss: 0.43037103\n",
      "Epoch [2900/5000], Average Loss: 0.42764778\n",
      "Epoch [3000/5000], Average Loss: 0.42562971\n",
      "Epoch [3100/5000], Average Loss: 0.42273676\n",
      "Epoch [3200/5000], Average Loss: 0.42047399\n",
      "Epoch [3300/5000], Average Loss: 0.41909433\n",
      "Epoch [3400/5000], Average Loss: 0.41524755\n",
      "Epoch [3500/5000], Average Loss: 0.41200575\n",
      "Epoch [3600/5000], Average Loss: 0.40900854\n",
      "Epoch [3700/5000], Average Loss: 0.40673258\n",
      "Epoch [3800/5000], Average Loss: 0.40475819\n",
      "Epoch [3900/5000], Average Loss: 0.40128878\n",
      "Epoch [4000/5000], Average Loss: 0.39955588\n",
      "Epoch [4100/5000], Average Loss: 0.39728875\n",
      "Epoch [4200/5000], Average Loss: 0.39571030\n",
      "Epoch [4300/5000], Average Loss: 0.39241136\n",
      "Epoch [4400/5000], Average Loss: 0.39166690\n",
      "Epoch [4500/5000], Average Loss: 0.38909999\n",
      "Epoch [4600/5000], Average Loss: 0.38689177\n",
      "Epoch [4700/5000], Average Loss: 0.38395751\n",
      "Epoch [4800/5000], Average Loss: 0.38332995\n",
      "Epoch [4900/5000], Average Loss: 0.38069110\n",
      "Epoch [5000/5000], Average Loss: 0.38279065\n",
      "Test Accuracy: 0.7554\n",
      "Epoch [100/5000], Average Loss: 0.56561005\n",
      "Epoch [200/5000], Average Loss: 0.54567114\n",
      "Epoch [300/5000], Average Loss: 0.53643958\n",
      "Epoch [400/5000], Average Loss: 0.52994002\n",
      "Epoch [500/5000], Average Loss: 0.52379073\n",
      "Epoch [600/5000], Average Loss: 0.51783636\n",
      "Epoch [700/5000], Average Loss: 0.51224997\n",
      "Epoch [800/5000], Average Loss: 0.50652952\n",
      "Epoch [900/5000], Average Loss: 0.50046185\n",
      "Epoch [1000/5000], Average Loss: 0.49424569\n",
      "Epoch [1100/5000], Average Loss: 0.48920251\n",
      "Epoch [1200/5000], Average Loss: 0.48409897\n",
      "Epoch [1300/5000], Average Loss: 0.47798453\n",
      "Epoch [1400/5000], Average Loss: 0.47313526\n",
      "Epoch [1500/5000], Average Loss: 0.46860769\n",
      "Epoch [1600/5000], Average Loss: 0.46417036\n",
      "Epoch [1700/5000], Average Loss: 0.45999584\n",
      "Epoch [1800/5000], Average Loss: 0.45580550\n",
      "Epoch [1900/5000], Average Loss: 0.45289254\n",
      "Epoch [2000/5000], Average Loss: 0.45001095\n",
      "Epoch [2100/5000], Average Loss: 0.44668983\n",
      "Epoch [2200/5000], Average Loss: 0.44414004\n",
      "Epoch [2300/5000], Average Loss: 0.44029745\n",
      "Epoch [2400/5000], Average Loss: 0.43810450\n",
      "Epoch [2500/5000], Average Loss: 0.43484010\n",
      "Epoch [2600/5000], Average Loss: 0.43182548\n",
      "Epoch [2700/5000], Average Loss: 0.43078278\n",
      "Epoch [2800/5000], Average Loss: 0.42731344\n",
      "Epoch [2900/5000], Average Loss: 0.42583612\n",
      "Epoch [3000/5000], Average Loss: 0.42347901\n",
      "Epoch [3100/5000], Average Loss: 0.42157370\n",
      "Epoch [3200/5000], Average Loss: 0.41983877\n",
      "Epoch [3300/5000], Average Loss: 0.41692891\n",
      "Epoch [3400/5000], Average Loss: 0.41500844\n",
      "Epoch [3500/5000], Average Loss: 0.41167830\n",
      "Epoch [3600/5000], Average Loss: 0.41122360\n",
      "Epoch [3700/5000], Average Loss: 0.40907901\n",
      "Epoch [3800/5000], Average Loss: 0.40652575\n",
      "Epoch [3900/5000], Average Loss: 0.40526375\n",
      "Epoch [4000/5000], Average Loss: 0.40233527\n",
      "Epoch [4100/5000], Average Loss: 0.40090711\n",
      "Epoch [4200/5000], Average Loss: 0.39997076\n",
      "Epoch [4300/5000], Average Loss: 0.39835720\n",
      "Epoch [4400/5000], Average Loss: 0.39675816\n",
      "Epoch [4500/5000], Average Loss: 0.39543606\n",
      "Epoch [4600/5000], Average Loss: 0.39260266\n",
      "Epoch [4700/5000], Average Loss: 0.39229709\n",
      "Epoch [4800/5000], Average Loss: 0.39058319\n",
      "Epoch [4900/5000], Average Loss: 0.38818053\n",
      "Epoch [5000/5000], Average Loss: 0.38801596\n",
      "Test Accuracy: 0.7461\n",
      "Epoch [100/5000], Average Loss: 0.61065765\n",
      "Epoch [200/5000], Average Loss: 0.56413807\n",
      "Epoch [300/5000], Average Loss: 0.54994860\n",
      "Epoch [400/5000], Average Loss: 0.54220452\n",
      "Epoch [500/5000], Average Loss: 0.53647493\n",
      "Epoch [600/5000], Average Loss: 0.53167293\n",
      "Epoch [700/5000], Average Loss: 0.52719590\n",
      "Epoch [800/5000], Average Loss: 0.52258483\n",
      "Epoch [900/5000], Average Loss: 0.51797229\n",
      "Epoch [1000/5000], Average Loss: 0.51332703\n",
      "Epoch [1100/5000], Average Loss: 0.50803441\n",
      "Epoch [1200/5000], Average Loss: 0.50414029\n",
      "Epoch [1300/5000], Average Loss: 0.49933243\n",
      "Epoch [1400/5000], Average Loss: 0.49653649\n",
      "Epoch [1500/5000], Average Loss: 0.49306951\n",
      "Epoch [1600/5000], Average Loss: 0.49051281\n",
      "Epoch [1700/5000], Average Loss: 0.48680627\n",
      "Epoch [1800/5000], Average Loss: 0.48347063\n",
      "Epoch [1900/5000], Average Loss: 0.48070043\n",
      "Epoch [2000/5000], Average Loss: 0.47863997\n",
      "Epoch [2100/5000], Average Loss: 0.47554294\n",
      "Epoch [2200/5000], Average Loss: 0.47312829\n",
      "Epoch [2300/5000], Average Loss: 0.47048810\n",
      "Epoch [2400/5000], Average Loss: 0.46792703\n",
      "Epoch [2500/5000], Average Loss: 0.46552743\n",
      "Epoch [2600/5000], Average Loss: 0.46300119\n",
      "Epoch [2700/5000], Average Loss: 0.45996796\n",
      "Epoch [2800/5000], Average Loss: 0.45746158\n",
      "Epoch [2900/5000], Average Loss: 0.45535687\n",
      "Epoch [3000/5000], Average Loss: 0.45300493\n",
      "Epoch [3100/5000], Average Loss: 0.44927833\n",
      "Epoch [3200/5000], Average Loss: 0.44524643\n",
      "Epoch [3300/5000], Average Loss: 0.44315160\n",
      "Epoch [3400/5000], Average Loss: 0.44020856\n",
      "Epoch [3500/5000], Average Loss: 0.43771993\n",
      "Epoch [3600/5000], Average Loss: 0.43489939\n",
      "Epoch [3700/5000], Average Loss: 0.43302792\n",
      "Epoch [3800/5000], Average Loss: 0.43007589\n",
      "Epoch [3900/5000], Average Loss: 0.42857545\n",
      "Epoch [4000/5000], Average Loss: 0.42625491\n",
      "Epoch [4100/5000], Average Loss: 0.42482304\n",
      "Epoch [4200/5000], Average Loss: 0.42291010\n",
      "Epoch [4300/5000], Average Loss: 0.42005178\n",
      "Epoch [4400/5000], Average Loss: 0.41831955\n",
      "Epoch [4500/5000], Average Loss: 0.41737292\n",
      "Epoch [4600/5000], Average Loss: 0.41527904\n",
      "Epoch [4700/5000], Average Loss: 0.41293643\n",
      "Epoch [4800/5000], Average Loss: 0.41273323\n",
      "Epoch [4900/5000], Average Loss: 0.40888053\n",
      "Epoch [5000/5000], Average Loss: 0.40741617\n",
      "Test Accuracy: 0.7340\n",
      "Epoch [100/5000], Average Loss: 0.58472366\n",
      "Epoch [200/5000], Average Loss: 0.55456901\n",
      "Epoch [300/5000], Average Loss: 0.54149947\n",
      "Epoch [400/5000], Average Loss: 0.53074888\n",
      "Epoch [500/5000], Average Loss: 0.52227117\n",
      "Epoch [600/5000], Average Loss: 0.51503710\n",
      "Epoch [700/5000], Average Loss: 0.50814219\n",
      "Epoch [800/5000], Average Loss: 0.50351949\n",
      "Epoch [900/5000], Average Loss: 0.49911089\n",
      "Epoch [1000/5000], Average Loss: 0.49537886\n",
      "Epoch [1100/5000], Average Loss: 0.49178876\n",
      "Epoch [1200/5000], Average Loss: 0.48855956\n",
      "Epoch [1300/5000], Average Loss: 0.48594752\n",
      "Epoch [1400/5000], Average Loss: 0.48316547\n",
      "Epoch [1500/5000], Average Loss: 0.47986097\n",
      "Epoch [1600/5000], Average Loss: 0.47740377\n",
      "Epoch [1700/5000], Average Loss: 0.47425441\n",
      "Epoch [1800/5000], Average Loss: 0.47162126\n",
      "Epoch [1900/5000], Average Loss: 0.46929143\n",
      "Epoch [2000/5000], Average Loss: 0.46631897\n",
      "Epoch [2100/5000], Average Loss: 0.46370786\n",
      "Epoch [2200/5000], Average Loss: 0.46129716\n",
      "Epoch [2300/5000], Average Loss: 0.45826546\n",
      "Epoch [2400/5000], Average Loss: 0.45583536\n",
      "Epoch [2500/5000], Average Loss: 0.45265276\n",
      "Epoch [2600/5000], Average Loss: 0.44933616\n",
      "Epoch [2700/5000], Average Loss: 0.44738085\n",
      "Epoch [2800/5000], Average Loss: 0.44487236\n",
      "Epoch [2900/5000], Average Loss: 0.44224285\n",
      "Epoch [3000/5000], Average Loss: 0.44000056\n",
      "Epoch [3100/5000], Average Loss: 0.43753231\n",
      "Epoch [3200/5000], Average Loss: 0.43584443\n",
      "Epoch [3300/5000], Average Loss: 0.43256832\n",
      "Epoch [3400/5000], Average Loss: 0.43031225\n",
      "Epoch [3500/5000], Average Loss: 0.42928588\n",
      "Epoch [3600/5000], Average Loss: 0.42687576\n",
      "Epoch [3700/5000], Average Loss: 0.42494709\n",
      "Epoch [3800/5000], Average Loss: 0.42264382\n",
      "Epoch [3900/5000], Average Loss: 0.42054627\n",
      "Epoch [4000/5000], Average Loss: 0.41755754\n",
      "Epoch [4100/5000], Average Loss: 0.41543739\n",
      "Epoch [4200/5000], Average Loss: 0.41349404\n",
      "Epoch [4300/5000], Average Loss: 0.41251299\n",
      "Epoch [4400/5000], Average Loss: 0.40874432\n",
      "Epoch [4500/5000], Average Loss: 0.40718682\n",
      "Epoch [4600/5000], Average Loss: 0.40471498\n",
      "Epoch [4700/5000], Average Loss: 0.40316717\n",
      "Epoch [4800/5000], Average Loss: 0.40130425\n",
      "Epoch [4900/5000], Average Loss: 0.39912096\n",
      "Epoch [5000/5000], Average Loss: 0.39744964\n",
      "Test Accuracy: 0.7479\n",
      "Epoch [100/5000], Average Loss: 0.58029536\n",
      "Epoch [200/5000], Average Loss: 0.55052938\n",
      "Epoch [300/5000], Average Loss: 0.53678647\n",
      "Epoch [400/5000], Average Loss: 0.52713238\n",
      "Epoch [500/5000], Average Loss: 0.51824744\n",
      "Epoch [600/5000], Average Loss: 0.51121981\n",
      "Epoch [700/5000], Average Loss: 0.50439442\n",
      "Epoch [800/5000], Average Loss: 0.49857289\n",
      "Epoch [900/5000], Average Loss: 0.49427663\n",
      "Epoch [1000/5000], Average Loss: 0.48979234\n",
      "Epoch [1100/5000], Average Loss: 0.48578379\n",
      "Epoch [1200/5000], Average Loss: 0.48155733\n",
      "Epoch [1300/5000], Average Loss: 0.47821693\n",
      "Epoch [1400/5000], Average Loss: 0.47212190\n",
      "Epoch [1500/5000], Average Loss: 0.46921512\n",
      "Epoch [1600/5000], Average Loss: 0.46543785\n",
      "Epoch [1700/5000], Average Loss: 0.46110213\n",
      "Epoch [1800/5000], Average Loss: 0.45807216\n",
      "Epoch [1900/5000], Average Loss: 0.45463263\n",
      "Epoch [2000/5000], Average Loss: 0.45114649\n",
      "Epoch [2100/5000], Average Loss: 0.44932073\n",
      "Epoch [2200/5000], Average Loss: 0.44545114\n",
      "Epoch [2300/5000], Average Loss: 0.44391606\n",
      "Epoch [2400/5000], Average Loss: 0.43974084\n",
      "Epoch [2500/5000], Average Loss: 0.43631811\n",
      "Epoch [2600/5000], Average Loss: 0.43281860\n",
      "Epoch [2700/5000], Average Loss: 0.43042769\n",
      "Epoch [2800/5000], Average Loss: 0.42685381\n",
      "Epoch [2900/5000], Average Loss: 0.42428194\n",
      "Epoch [3000/5000], Average Loss: 0.42222070\n",
      "Epoch [3100/5000], Average Loss: 0.41870751\n",
      "Epoch [3200/5000], Average Loss: 0.41624682\n",
      "Epoch [3300/5000], Average Loss: 0.41326712\n",
      "Epoch [3400/5000], Average Loss: 0.41098226\n",
      "Epoch [3500/5000], Average Loss: 0.40745718\n",
      "Epoch [3600/5000], Average Loss: 0.40535727\n",
      "Epoch [3700/5000], Average Loss: 0.40306119\n",
      "Epoch [3800/5000], Average Loss: 0.40008720\n",
      "Epoch [3900/5000], Average Loss: 0.39861768\n",
      "Epoch [4000/5000], Average Loss: 0.39795062\n",
      "Epoch [4100/5000], Average Loss: 0.39424551\n",
      "Epoch [4200/5000], Average Loss: 0.39264027\n",
      "Epoch [4300/5000], Average Loss: 0.39017052\n",
      "Epoch [4400/5000], Average Loss: 0.38860817\n",
      "Epoch [4500/5000], Average Loss: 0.38644710\n",
      "Epoch [4600/5000], Average Loss: 0.38420262\n",
      "Epoch [4700/5000], Average Loss: 0.38240985\n",
      "Epoch [4800/5000], Average Loss: 0.38063598\n",
      "Epoch [4900/5000], Average Loss: 0.37822188\n",
      "Epoch [5000/5000], Average Loss: 0.37665741\n",
      "Test Accuracy: 0.7407\n",
      "Epoch [100/5000], Average Loss: 0.61347902\n",
      "Epoch [200/5000], Average Loss: 0.57091610\n",
      "Epoch [300/5000], Average Loss: 0.55644454\n",
      "Epoch [400/5000], Average Loss: 0.54709185\n",
      "Epoch [500/5000], Average Loss: 0.53900571\n",
      "Epoch [600/5000], Average Loss: 0.53257805\n",
      "Epoch [700/5000], Average Loss: 0.52713521\n",
      "Epoch [800/5000], Average Loss: 0.52168262\n",
      "Epoch [900/5000], Average Loss: 0.51693704\n",
      "Epoch [1000/5000], Average Loss: 0.51219870\n",
      "Epoch [1100/5000], Average Loss: 0.50809465\n",
      "Epoch [1200/5000], Average Loss: 0.50278734\n",
      "Epoch [1300/5000], Average Loss: 0.49817665\n",
      "Epoch [1400/5000], Average Loss: 0.49404685\n",
      "Epoch [1500/5000], Average Loss: 0.48995733\n",
      "Epoch [1600/5000], Average Loss: 0.48467704\n",
      "Epoch [1700/5000], Average Loss: 0.47978005\n",
      "Epoch [1800/5000], Average Loss: 0.47539921\n",
      "Epoch [1900/5000], Average Loss: 0.47170311\n",
      "Epoch [2000/5000], Average Loss: 0.46863426\n",
      "Epoch [2100/5000], Average Loss: 0.46474798\n",
      "Epoch [2200/5000], Average Loss: 0.46214197\n",
      "Epoch [2300/5000], Average Loss: 0.45919693\n",
      "Epoch [2400/5000], Average Loss: 0.45660054\n",
      "Epoch [2500/5000], Average Loss: 0.45423494\n",
      "Epoch [2600/5000], Average Loss: 0.45157405\n",
      "Epoch [2700/5000], Average Loss: 0.44947957\n",
      "Epoch [2800/5000], Average Loss: 0.44776523\n",
      "Epoch [2900/5000], Average Loss: 0.44569276\n",
      "Epoch [3000/5000], Average Loss: 0.44380057\n",
      "Epoch [3100/5000], Average Loss: 0.44094204\n",
      "Epoch [3200/5000], Average Loss: 0.43873530\n",
      "Epoch [3300/5000], Average Loss: 0.43764744\n",
      "Epoch [3400/5000], Average Loss: 0.43524531\n",
      "Epoch [3500/5000], Average Loss: 0.43284637\n",
      "Epoch [3600/5000], Average Loss: 0.43216194\n",
      "Epoch [3700/5000], Average Loss: 0.42998810\n",
      "Epoch [3800/5000], Average Loss: 0.42842021\n",
      "Epoch [3900/5000], Average Loss: 0.42649277\n",
      "Epoch [4000/5000], Average Loss: 0.42489931\n",
      "Epoch [4100/5000], Average Loss: 0.42372250\n",
      "Epoch [4200/5000], Average Loss: 0.42202594\n",
      "Epoch [4300/5000], Average Loss: 0.42068842\n",
      "Epoch [4400/5000], Average Loss: 0.41917007\n",
      "Epoch [4500/5000], Average Loss: 0.41782762\n",
      "Epoch [4600/5000], Average Loss: 0.41588744\n",
      "Epoch [4700/5000], Average Loss: 0.41407504\n",
      "Epoch [4800/5000], Average Loss: 0.41339840\n",
      "Epoch [4900/5000], Average Loss: 0.41143852\n",
      "Epoch [5000/5000], Average Loss: 0.41036077\n",
      "Test Accuracy: 0.7430\n",
      "Epoch [100/5000], Average Loss: 0.60572827\n",
      "Epoch [200/5000], Average Loss: 0.56824922\n",
      "Epoch [300/5000], Average Loss: 0.55583058\n",
      "Epoch [400/5000], Average Loss: 0.54676225\n",
      "Epoch [500/5000], Average Loss: 0.53888210\n",
      "Epoch [600/5000], Average Loss: 0.53322515\n",
      "Epoch [700/5000], Average Loss: 0.52839355\n",
      "Epoch [800/5000], Average Loss: 0.52304772\n",
      "Epoch [900/5000], Average Loss: 0.51903161\n",
      "Epoch [1000/5000], Average Loss: 0.51448890\n",
      "Epoch [1100/5000], Average Loss: 0.51069963\n",
      "Epoch [1200/5000], Average Loss: 0.50737256\n",
      "Epoch [1300/5000], Average Loss: 0.50340487\n",
      "Epoch [1400/5000], Average Loss: 0.50087908\n",
      "Epoch [1500/5000], Average Loss: 0.49664726\n",
      "Epoch [1600/5000], Average Loss: 0.49339003\n",
      "Epoch [1700/5000], Average Loss: 0.48959758\n",
      "Epoch [1800/5000], Average Loss: 0.48761508\n",
      "Epoch [1900/5000], Average Loss: 0.48585045\n",
      "Epoch [2000/5000], Average Loss: 0.48285940\n",
      "Epoch [2100/5000], Average Loss: 0.47717174\n",
      "Epoch [2200/5000], Average Loss: 0.47548344\n",
      "Epoch [2300/5000], Average Loss: 0.47201409\n",
      "Epoch [2400/5000], Average Loss: 0.46921116\n",
      "Epoch [2500/5000], Average Loss: 0.46548149\n",
      "Epoch [2600/5000], Average Loss: 0.46175042\n",
      "Epoch [2700/5000], Average Loss: 0.46019809\n",
      "Epoch [2800/5000], Average Loss: 0.45690110\n",
      "Epoch [2900/5000], Average Loss: 0.45418954\n",
      "Epoch [3000/5000], Average Loss: 0.45025588\n",
      "Epoch [3100/5000], Average Loss: 0.44769032\n",
      "Epoch [3200/5000], Average Loss: 0.44372927\n",
      "Epoch [3300/5000], Average Loss: 0.44020597\n",
      "Epoch [3400/5000], Average Loss: 0.43766205\n",
      "Epoch [3500/5000], Average Loss: 0.43556842\n",
      "Epoch [3600/5000], Average Loss: 0.43225341\n",
      "Epoch [3700/5000], Average Loss: 0.43005066\n",
      "Epoch [3800/5000], Average Loss: 0.42678699\n",
      "Epoch [3900/5000], Average Loss: 0.42425467\n",
      "Epoch [4000/5000], Average Loss: 0.42215525\n",
      "Epoch [4100/5000], Average Loss: 0.42025774\n",
      "Epoch [4200/5000], Average Loss: 0.41749156\n",
      "Epoch [4300/5000], Average Loss: 0.41514270\n",
      "Epoch [4400/5000], Average Loss: 0.41274411\n",
      "Epoch [4500/5000], Average Loss: 0.41206436\n",
      "Epoch [4600/5000], Average Loss: 0.40860582\n",
      "Epoch [4700/5000], Average Loss: 0.40803150\n",
      "Epoch [4800/5000], Average Loss: 0.40626700\n",
      "Epoch [4900/5000], Average Loss: 0.40285659\n",
      "Epoch [5000/5000], Average Loss: 0.40088589\n",
      "Test Accuracy: 0.7343\n",
      "Epoch [100/5000], Average Loss: 0.59778652\n",
      "Epoch [200/5000], Average Loss: 0.56697141\n",
      "Epoch [300/5000], Average Loss: 0.55309367\n",
      "Epoch [400/5000], Average Loss: 0.54383718\n",
      "Epoch [500/5000], Average Loss: 0.53629106\n",
      "Epoch [600/5000], Average Loss: 0.52948065\n",
      "Epoch [700/5000], Average Loss: 0.52389113\n",
      "Epoch [800/5000], Average Loss: 0.51859507\n",
      "Epoch [900/5000], Average Loss: 0.51477177\n",
      "Epoch [1000/5000], Average Loss: 0.50979747\n",
      "Epoch [1100/5000], Average Loss: 0.50527416\n",
      "Epoch [1200/5000], Average Loss: 0.50213179\n",
      "Epoch [1300/5000], Average Loss: 0.49892898\n",
      "Epoch [1400/5000], Average Loss: 0.49489843\n",
      "Epoch [1500/5000], Average Loss: 0.49289839\n",
      "Epoch [1600/5000], Average Loss: 0.48876117\n",
      "Epoch [1700/5000], Average Loss: 0.48483375\n",
      "Epoch [1800/5000], Average Loss: 0.48181768\n",
      "Epoch [1900/5000], Average Loss: 0.47991340\n",
      "Epoch [2000/5000], Average Loss: 0.47591996\n",
      "Epoch [2100/5000], Average Loss: 0.47234638\n",
      "Epoch [2200/5000], Average Loss: 0.46975142\n",
      "Epoch [2300/5000], Average Loss: 0.46664274\n",
      "Epoch [2400/5000], Average Loss: 0.46483727\n",
      "Epoch [2500/5000], Average Loss: 0.46244068\n",
      "Epoch [2600/5000], Average Loss: 0.45913381\n",
      "Epoch [2700/5000], Average Loss: 0.45757698\n",
      "Epoch [2800/5000], Average Loss: 0.45457021\n",
      "Epoch [2900/5000], Average Loss: 0.45239550\n",
      "Epoch [3000/5000], Average Loss: 0.45094275\n",
      "Epoch [3100/5000], Average Loss: 0.44813393\n",
      "Epoch [3200/5000], Average Loss: 0.44630748\n",
      "Epoch [3300/5000], Average Loss: 0.44452789\n",
      "Epoch [3400/5000], Average Loss: 0.44208412\n",
      "Epoch [3500/5000], Average Loss: 0.44060926\n",
      "Epoch [3600/5000], Average Loss: 0.43807833\n",
      "Epoch [3700/5000], Average Loss: 0.43757954\n",
      "Epoch [3800/5000], Average Loss: 0.43481514\n",
      "Epoch [3900/5000], Average Loss: 0.43342029\n",
      "Epoch [4000/5000], Average Loss: 0.43189479\n",
      "Epoch [4100/5000], Average Loss: 0.43002751\n",
      "Epoch [4200/5000], Average Loss: 0.42861732\n",
      "Epoch [4300/5000], Average Loss: 0.42506628\n",
      "Epoch [4400/5000], Average Loss: 0.42473946\n",
      "Epoch [4500/5000], Average Loss: 0.42102523\n",
      "Epoch [4600/5000], Average Loss: 0.41964203\n",
      "Epoch [4700/5000], Average Loss: 0.41657467\n",
      "Epoch [4800/5000], Average Loss: 0.41413921\n",
      "Epoch [4900/5000], Average Loss: 0.41257070\n",
      "Epoch [5000/5000], Average Loss: 0.40971388\n",
      "Test Accuracy: 0.7264\n",
      "Epoch [100/5000], Average Loss: 0.60987778\n",
      "Epoch [200/5000], Average Loss: 0.56102417\n",
      "Epoch [300/5000], Average Loss: 0.54558137\n",
      "Epoch [400/5000], Average Loss: 0.53616864\n",
      "Epoch [500/5000], Average Loss: 0.52854852\n",
      "Epoch [600/5000], Average Loss: 0.52215288\n",
      "Epoch [700/5000], Average Loss: 0.51755888\n",
      "Epoch [800/5000], Average Loss: 0.51335673\n",
      "Epoch [900/5000], Average Loss: 0.50889061\n",
      "Epoch [1000/5000], Average Loss: 0.50457964\n",
      "Epoch [1100/5000], Average Loss: 0.50051134\n",
      "Epoch [1200/5000], Average Loss: 0.49709010\n",
      "Epoch [1300/5000], Average Loss: 0.49456392\n",
      "Epoch [1400/5000], Average Loss: 0.49099529\n",
      "Epoch [1500/5000], Average Loss: 0.48845220\n",
      "Epoch [1600/5000], Average Loss: 0.48452287\n",
      "Epoch [1700/5000], Average Loss: 0.48201627\n",
      "Epoch [1800/5000], Average Loss: 0.48046271\n",
      "Epoch [1900/5000], Average Loss: 0.47746667\n",
      "Epoch [2000/5000], Average Loss: 0.47446846\n",
      "Epoch [2100/5000], Average Loss: 0.47119366\n",
      "Epoch [2200/5000], Average Loss: 0.46736338\n",
      "Epoch [2300/5000], Average Loss: 0.46503767\n",
      "Epoch [2400/5000], Average Loss: 0.46017490\n",
      "Epoch [2500/5000], Average Loss: 0.45737395\n",
      "Epoch [2600/5000], Average Loss: 0.45569005\n",
      "Epoch [2700/5000], Average Loss: 0.45194598\n",
      "Epoch [2800/5000], Average Loss: 0.45055426\n",
      "Epoch [2900/5000], Average Loss: 0.44806958\n",
      "Epoch [3000/5000], Average Loss: 0.44549932\n",
      "Epoch [3100/5000], Average Loss: 0.44207045\n",
      "Epoch [3200/5000], Average Loss: 0.44033743\n",
      "Epoch [3300/5000], Average Loss: 0.43944831\n",
      "Epoch [3400/5000], Average Loss: 0.43735036\n",
      "Epoch [3500/5000], Average Loss: 0.43373755\n",
      "Epoch [3600/5000], Average Loss: 0.43119760\n",
      "Epoch [3700/5000], Average Loss: 0.43109652\n",
      "Epoch [3800/5000], Average Loss: 0.42732868\n",
      "Epoch [3900/5000], Average Loss: 0.42505465\n",
      "Epoch [4000/5000], Average Loss: 0.42362989\n",
      "Epoch [4100/5000], Average Loss: 0.42065895\n",
      "Epoch [4200/5000], Average Loss: 0.41766888\n",
      "Epoch [4300/5000], Average Loss: 0.41584024\n",
      "Epoch [4400/5000], Average Loss: 0.41268703\n",
      "Epoch [4500/5000], Average Loss: 0.41179069\n",
      "Epoch [4600/5000], Average Loss: 0.41041555\n",
      "Epoch [4700/5000], Average Loss: 0.40539879\n",
      "Epoch [4800/5000], Average Loss: 0.40687100\n",
      "Epoch [4900/5000], Average Loss: 0.40761689\n",
      "Epoch [5000/5000], Average Loss: 0.40876443\n",
      "Test Accuracy: 0.7366\n",
      "Epoch [100/5000], Average Loss: 0.61675831\n",
      "Epoch [200/5000], Average Loss: 0.57342896\n",
      "Epoch [300/5000], Average Loss: 0.55705498\n",
      "Epoch [400/5000], Average Loss: 0.54801918\n",
      "Epoch [500/5000], Average Loss: 0.54078937\n",
      "Epoch [600/5000], Average Loss: 0.53555620\n",
      "Epoch [700/5000], Average Loss: 0.53045659\n",
      "Epoch [800/5000], Average Loss: 0.52650199\n",
      "Epoch [900/5000], Average Loss: 0.52227179\n",
      "Epoch [1000/5000], Average Loss: 0.51861067\n",
      "Epoch [1100/5000], Average Loss: 0.51438578\n",
      "Epoch [1200/5000], Average Loss: 0.51052265\n",
      "Epoch [1300/5000], Average Loss: 0.50677037\n",
      "Epoch [1400/5000], Average Loss: 0.50378475\n",
      "Epoch [1500/5000], Average Loss: 0.50017127\n",
      "Epoch [1600/5000], Average Loss: 0.49586863\n",
      "Epoch [1700/5000], Average Loss: 0.49249591\n",
      "Epoch [1800/5000], Average Loss: 0.48981942\n",
      "Epoch [1900/5000], Average Loss: 0.48671254\n",
      "Epoch [2000/5000], Average Loss: 0.48364942\n",
      "Epoch [2100/5000], Average Loss: 0.48176488\n",
      "Epoch [2200/5000], Average Loss: 0.47974834\n",
      "Epoch [2300/5000], Average Loss: 0.47641612\n",
      "Epoch [2400/5000], Average Loss: 0.47329859\n",
      "Epoch [2500/5000], Average Loss: 0.47129122\n",
      "Epoch [2600/5000], Average Loss: 0.46960715\n",
      "Epoch [2700/5000], Average Loss: 0.46724222\n",
      "Epoch [2800/5000], Average Loss: 0.46525095\n",
      "Epoch [2900/5000], Average Loss: 0.46311210\n",
      "Epoch [3000/5000], Average Loss: 0.46129366\n",
      "Epoch [3100/5000], Average Loss: 0.45856863\n",
      "Epoch [3200/5000], Average Loss: 0.45601410\n",
      "Epoch [3300/5000], Average Loss: 0.45399943\n",
      "Epoch [3400/5000], Average Loss: 0.45302380\n",
      "Epoch [3500/5000], Average Loss: 0.45169629\n",
      "Epoch [3600/5000], Average Loss: 0.44881009\n",
      "Epoch [3700/5000], Average Loss: 0.44698375\n",
      "Epoch [3800/5000], Average Loss: 0.44536866\n",
      "Epoch [3900/5000], Average Loss: 0.44368966\n",
      "Epoch [4000/5000], Average Loss: 0.44139993\n",
      "Epoch [4100/5000], Average Loss: 0.43927715\n",
      "Epoch [4200/5000], Average Loss: 0.43762919\n",
      "Epoch [4300/5000], Average Loss: 0.43539216\n",
      "Epoch [4400/5000], Average Loss: 0.43430407\n",
      "Epoch [4500/5000], Average Loss: 0.43162030\n",
      "Epoch [4600/5000], Average Loss: 0.43043830\n",
      "Epoch [4700/5000], Average Loss: 0.42871835\n",
      "Epoch [4800/5000], Average Loss: 0.42742134\n",
      "Epoch [4900/5000], Average Loss: 0.42512234\n",
      "Epoch [5000/5000], Average Loss: 0.42427530\n",
      "Test Accuracy: 0.7234\n",
      "Epoch [100/5000], Average Loss: 0.62298248\n",
      "Epoch [200/5000], Average Loss: 0.57799179\n",
      "Epoch [300/5000], Average Loss: 0.55431902\n",
      "Epoch [400/5000], Average Loss: 0.54245623\n",
      "Epoch [500/5000], Average Loss: 0.53526754\n",
      "Epoch [600/5000], Average Loss: 0.52964140\n",
      "Epoch [700/5000], Average Loss: 0.52508623\n",
      "Epoch [800/5000], Average Loss: 0.52119694\n",
      "Epoch [900/5000], Average Loss: 0.51726754\n",
      "Epoch [1000/5000], Average Loss: 0.51406493\n",
      "Epoch [1100/5000], Average Loss: 0.50999039\n",
      "Epoch [1200/5000], Average Loss: 0.50627345\n",
      "Epoch [1300/5000], Average Loss: 0.50382934\n",
      "Epoch [1400/5000], Average Loss: 0.49986755\n",
      "Epoch [1500/5000], Average Loss: 0.49679546\n",
      "Epoch [1600/5000], Average Loss: 0.49368105\n",
      "Epoch [1700/5000], Average Loss: 0.49042376\n",
      "Epoch [1800/5000], Average Loss: 0.48715826\n",
      "Epoch [1900/5000], Average Loss: 0.48372578\n",
      "Epoch [2000/5000], Average Loss: 0.48175485\n",
      "Epoch [2100/5000], Average Loss: 0.48128087\n",
      "Epoch [2200/5000], Average Loss: 0.47898413\n",
      "Epoch [2300/5000], Average Loss: 0.47368674\n",
      "Epoch [2400/5000], Average Loss: 0.47091076\n",
      "Epoch [2500/5000], Average Loss: 0.47000687\n",
      "Epoch [2600/5000], Average Loss: 0.46581896\n",
      "Epoch [2700/5000], Average Loss: 0.46521038\n",
      "Epoch [2800/5000], Average Loss: 0.46261401\n",
      "Epoch [2900/5000], Average Loss: 0.46024539\n",
      "Epoch [3000/5000], Average Loss: 0.45714097\n",
      "Epoch [3100/5000], Average Loss: 0.45516154\n",
      "Epoch [3200/5000], Average Loss: 0.45188525\n",
      "Epoch [3300/5000], Average Loss: 0.45040390\n",
      "Epoch [3400/5000], Average Loss: 0.44676699\n",
      "Epoch [3500/5000], Average Loss: 0.44605647\n",
      "Epoch [3600/5000], Average Loss: 0.44473035\n",
      "Epoch [3700/5000], Average Loss: 0.44063071\n",
      "Epoch [3800/5000], Average Loss: 0.43747818\n",
      "Epoch [3900/5000], Average Loss: 0.43546605\n",
      "Epoch [4000/5000], Average Loss: 0.43423380\n",
      "Epoch [4100/5000], Average Loss: 0.43184936\n",
      "Epoch [4200/5000], Average Loss: 0.42890059\n",
      "Epoch [4300/5000], Average Loss: 0.42682109\n",
      "Epoch [4400/5000], Average Loss: 0.42336102\n",
      "Epoch [4500/5000], Average Loss: 0.42238833\n",
      "Epoch [4600/5000], Average Loss: 0.41943761\n",
      "Epoch [4700/5000], Average Loss: 0.41698471\n",
      "Epoch [4800/5000], Average Loss: 0.41516854\n",
      "Epoch [4900/5000], Average Loss: 0.41316283\n",
      "Epoch [5000/5000], Average Loss: 0.41087266\n",
      "Test Accuracy: 0.7322\n",
      "Epoch [100/5000], Average Loss: 0.64361029\n",
      "Epoch [200/5000], Average Loss: 0.62470153\n",
      "Epoch [300/5000], Average Loss: 0.58709597\n",
      "Epoch [400/5000], Average Loss: 0.56224772\n",
      "Epoch [500/5000], Average Loss: 0.55018390\n",
      "Epoch [600/5000], Average Loss: 0.54201471\n",
      "Epoch [700/5000], Average Loss: 0.53647383\n",
      "Epoch [800/5000], Average Loss: 0.53207329\n",
      "Epoch [900/5000], Average Loss: 0.52758800\n",
      "Epoch [1000/5000], Average Loss: 0.52373542\n",
      "Epoch [1100/5000], Average Loss: 0.52046436\n",
      "Epoch [1200/5000], Average Loss: 0.51711092\n",
      "Epoch [1300/5000], Average Loss: 0.51332129\n",
      "Epoch [1400/5000], Average Loss: 0.50988482\n",
      "Epoch [1500/5000], Average Loss: 0.50663199\n",
      "Epoch [1600/5000], Average Loss: 0.50365056\n",
      "Epoch [1700/5000], Average Loss: 0.50094405\n",
      "Epoch [1800/5000], Average Loss: 0.49716109\n",
      "Epoch [1900/5000], Average Loss: 0.49350044\n",
      "Epoch [2000/5000], Average Loss: 0.49001052\n",
      "Epoch [2100/5000], Average Loss: 0.48800502\n",
      "Epoch [2200/5000], Average Loss: 0.48470692\n",
      "Epoch [2300/5000], Average Loss: 0.48043584\n",
      "Epoch [2400/5000], Average Loss: 0.47765058\n",
      "Epoch [2500/5000], Average Loss: 0.47506635\n",
      "Epoch [2600/5000], Average Loss: 0.47227483\n",
      "Epoch [2700/5000], Average Loss: 0.46892933\n",
      "Epoch [2800/5000], Average Loss: 0.46628354\n",
      "Epoch [2900/5000], Average Loss: 0.46413639\n",
      "Epoch [3000/5000], Average Loss: 0.46166709\n",
      "Epoch [3100/5000], Average Loss: 0.45946054\n",
      "Epoch [3200/5000], Average Loss: 0.45761554\n",
      "Epoch [3300/5000], Average Loss: 0.45419544\n",
      "Epoch [3400/5000], Average Loss: 0.45346313\n",
      "Epoch [3500/5000], Average Loss: 0.45246101\n",
      "Epoch [3600/5000], Average Loss: 0.44982390\n",
      "Epoch [3700/5000], Average Loss: 0.44827092\n",
      "Epoch [3800/5000], Average Loss: 0.44607667\n",
      "Epoch [3900/5000], Average Loss: 0.44503587\n",
      "Epoch [4000/5000], Average Loss: 0.44350357\n",
      "Epoch [4100/5000], Average Loss: 0.44189146\n",
      "Epoch [4200/5000], Average Loss: 0.44058515\n",
      "Epoch [4300/5000], Average Loss: 0.43932690\n",
      "Epoch [4400/5000], Average Loss: 0.43817254\n",
      "Epoch [4500/5000], Average Loss: 0.43616785\n",
      "Epoch [4600/5000], Average Loss: 0.43494076\n",
      "Epoch [4700/5000], Average Loss: 0.43420646\n",
      "Epoch [4800/5000], Average Loss: 0.43244456\n",
      "Epoch [4900/5000], Average Loss: 0.43116203\n",
      "Epoch [5000/5000], Average Loss: 0.42986109\n",
      "Test Accuracy: 0.7169\n",
      "Epoch [100/5000], Average Loss: 0.63905242\n",
      "Epoch [200/5000], Average Loss: 0.59339129\n",
      "Epoch [300/5000], Average Loss: 0.56870396\n",
      "Epoch [400/5000], Average Loss: 0.55734714\n",
      "Epoch [500/5000], Average Loss: 0.54892908\n",
      "Epoch [600/5000], Average Loss: 0.54164215\n",
      "Epoch [700/5000], Average Loss: 0.53561559\n",
      "Epoch [800/5000], Average Loss: 0.53044319\n",
      "Epoch [900/5000], Average Loss: 0.52586563\n",
      "Epoch [1000/5000], Average Loss: 0.52147957\n",
      "Epoch [1100/5000], Average Loss: 0.51621951\n",
      "Epoch [1200/5000], Average Loss: 0.51194258\n",
      "Epoch [1300/5000], Average Loss: 0.50750618\n",
      "Epoch [1400/5000], Average Loss: 0.50352359\n",
      "Epoch [1500/5000], Average Loss: 0.49923220\n",
      "Epoch [1600/5000], Average Loss: 0.49493381\n",
      "Epoch [1700/5000], Average Loss: 0.49090299\n",
      "Epoch [1800/5000], Average Loss: 0.48839225\n",
      "Epoch [1900/5000], Average Loss: 0.48607296\n",
      "Epoch [2000/5000], Average Loss: 0.48238986\n",
      "Epoch [2100/5000], Average Loss: 0.47934099\n",
      "Epoch [2200/5000], Average Loss: 0.47734815\n",
      "Epoch [2300/5000], Average Loss: 0.47317635\n",
      "Epoch [2400/5000], Average Loss: 0.47116726\n",
      "Epoch [2500/5000], Average Loss: 0.46901062\n",
      "Epoch [2600/5000], Average Loss: 0.46673612\n",
      "Epoch [2700/5000], Average Loss: 0.46479024\n",
      "Epoch [2800/5000], Average Loss: 0.46190956\n",
      "Epoch [2900/5000], Average Loss: 0.46192089\n",
      "Epoch [3000/5000], Average Loss: 0.45821570\n",
      "Epoch [3100/5000], Average Loss: 0.45772749\n",
      "Epoch [3200/5000], Average Loss: 0.45514241\n",
      "Epoch [3300/5000], Average Loss: 0.45260639\n",
      "Epoch [3400/5000], Average Loss: 0.45089705\n",
      "Epoch [3500/5000], Average Loss: 0.44905728\n",
      "Epoch [3600/5000], Average Loss: 0.44576794\n",
      "Epoch [3700/5000], Average Loss: 0.44521067\n",
      "Epoch [3800/5000], Average Loss: 0.44277167\n",
      "Epoch [3900/5000], Average Loss: 0.43907205\n",
      "Epoch [4000/5000], Average Loss: 0.43829168\n",
      "Epoch [4100/5000], Average Loss: 0.43610341\n",
      "Epoch [4200/5000], Average Loss: 0.43225324\n",
      "Epoch [4300/5000], Average Loss: 0.43072722\n",
      "Epoch [4400/5000], Average Loss: 0.42841659\n",
      "Epoch [4500/5000], Average Loss: 0.42720657\n",
      "Epoch [4600/5000], Average Loss: 0.42443873\n",
      "Epoch [4700/5000], Average Loss: 0.42185953\n",
      "Epoch [4800/5000], Average Loss: 0.41978208\n",
      "Epoch [4900/5000], Average Loss: 0.41767295\n",
      "Epoch [5000/5000], Average Loss: 0.41633851\n",
      "Test Accuracy: 0.7236\n",
      "Epoch [100/5000], Average Loss: 0.64476780\n",
      "Epoch [200/5000], Average Loss: 0.61188619\n",
      "Epoch [300/5000], Average Loss: 0.57775895\n",
      "Epoch [400/5000], Average Loss: 0.56300838\n",
      "Epoch [500/5000], Average Loss: 0.55356190\n",
      "Epoch [600/5000], Average Loss: 0.54633062\n",
      "Epoch [700/5000], Average Loss: 0.54145459\n",
      "Epoch [800/5000], Average Loss: 0.53677920\n",
      "Epoch [900/5000], Average Loss: 0.53208327\n",
      "Epoch [1000/5000], Average Loss: 0.52747309\n",
      "Epoch [1100/5000], Average Loss: 0.52276565\n",
      "Epoch [1200/5000], Average Loss: 0.51861643\n",
      "Epoch [1300/5000], Average Loss: 0.51520103\n",
      "Epoch [1400/5000], Average Loss: 0.51100428\n",
      "Epoch [1500/5000], Average Loss: 0.50757256\n",
      "Epoch [1600/5000], Average Loss: 0.50484574\n",
      "Epoch [1700/5000], Average Loss: 0.50070364\n",
      "Epoch [1800/5000], Average Loss: 0.49758421\n",
      "Epoch [1900/5000], Average Loss: 0.49381152\n",
      "Epoch [2000/5000], Average Loss: 0.49145203\n",
      "Epoch [2100/5000], Average Loss: 0.48745467\n",
      "Epoch [2200/5000], Average Loss: 0.48453903\n",
      "Epoch [2300/5000], Average Loss: 0.48142545\n",
      "Epoch [2400/5000], Average Loss: 0.47796005\n",
      "Epoch [2500/5000], Average Loss: 0.47573811\n",
      "Epoch [2600/5000], Average Loss: 0.47422399\n",
      "Epoch [2700/5000], Average Loss: 0.47140770\n",
      "Epoch [2800/5000], Average Loss: 0.46851408\n",
      "Epoch [2900/5000], Average Loss: 0.46681642\n",
      "Epoch [3000/5000], Average Loss: 0.46543221\n",
      "Epoch [3100/5000], Average Loss: 0.46350636\n",
      "Epoch [3200/5000], Average Loss: 0.46051213\n",
      "Epoch [3300/5000], Average Loss: 0.45793677\n",
      "Epoch [3400/5000], Average Loss: 0.45621607\n",
      "Epoch [3500/5000], Average Loss: 0.45518722\n",
      "Epoch [3600/5000], Average Loss: 0.45226729\n",
      "Epoch [3700/5000], Average Loss: 0.45040004\n",
      "Epoch [3800/5000], Average Loss: 0.44799321\n",
      "Epoch [3900/5000], Average Loss: 0.44604698\n",
      "Epoch [4000/5000], Average Loss: 0.44609717\n",
      "Epoch [4100/5000], Average Loss: 0.44340273\n",
      "Epoch [4200/5000], Average Loss: 0.44170893\n",
      "Epoch [4300/5000], Average Loss: 0.44014491\n",
      "Epoch [4400/5000], Average Loss: 0.43779248\n",
      "Epoch [4500/5000], Average Loss: 0.43649279\n",
      "Epoch [4600/5000], Average Loss: 0.43451898\n",
      "Epoch [4700/5000], Average Loss: 0.43293147\n",
      "Epoch [4800/5000], Average Loss: 0.43088958\n",
      "Epoch [4900/5000], Average Loss: 0.43010328\n",
      "Epoch [5000/5000], Average Loss: 0.42840485\n",
      "Test Accuracy: 0.7257\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "input_size = 100\n",
    "hidden_sizes = [70,64, 32]\n",
    "output_size = 1\n",
    "# test sizes \n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,0.7,0.8]\n",
    "accuracy = {i:[] for i in test_sizes}\n",
    "\n",
    "dat = pd.read_csv('../../data/data-norm/max-pixel-all/nthroot_0.5862.csv')\n",
    "data = dat.iloc[:, 1:].values\n",
    "labels = dat.iloc[:, 0].values.reshape(-1, 1)\n",
    "for i, num in enumerate(test_sizes):\n",
    "    # run couple of times\n",
    "    for _ in range(3):\n",
    "        model = DynamicBinaryClassifier(input_size, hidden_sizes, output_size)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        trainer = BinaryClassifierTrainer(model, criterion, optimizer)\n",
    "        batch_size = 128\n",
    "\n",
    "        # Split the data into training and test sets\n",
    "        input_train, input_test, labels_train, labels_test = train_test_split(data, labels, test_size=num, random_state=42)\n",
    "\n",
    "        # Training\n",
    "        trainer.train(input_train, labels_train, num_epochs=5000, batch_size=batch_size)\n",
    "\n",
    "        # Evaluation\n",
    "        test_accuracy = trainer.evaluate(input_test, labels_test)\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "        accuracy[num].append(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle save accuracy dict\n",
    "import pickle\n",
    "with open('../vary-test-size/DNN-accuracy-new.pickle', 'wb') as handle:\n",
    "    pickle.dump(accuracy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769259</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.749144</td>\n",
       "      <td>0.739473</td>\n",
       "      <td>0.734038</td>\n",
       "      <td>0.742967</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.716861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.773661</td>\n",
       "      <td>0.741148</td>\n",
       "      <td>0.751345</td>\n",
       "      <td>0.755435</td>\n",
       "      <td>0.747908</td>\n",
       "      <td>0.734283</td>\n",
       "      <td>0.723437</td>\n",
       "      <td>0.723557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763390</td>\n",
       "      <td>0.756375</td>\n",
       "      <td>0.746208</td>\n",
       "      <td>0.746078</td>\n",
       "      <td>0.740716</td>\n",
       "      <td>0.726394</td>\n",
       "      <td>0.732243</td>\n",
       "      <td>0.725667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0.1       0.2       0.3       0.4       0.5       0.6       0.7  \\\n",
       "0  0.769259  0.753623  0.749144  0.739473  0.734038  0.742967  0.736594   \n",
       "1  0.773661  0.741148  0.751345  0.755435  0.747908  0.734283  0.723437   \n",
       "2  0.763390  0.756375  0.746208  0.746078  0.740716  0.726394  0.732243   \n",
       "\n",
       "        0.8  \n",
       "0  0.716861  \n",
       "1  0.723557  \n",
       "2  0.725667  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read trained data \n",
    "with open('../vary-test-size/DNN-accuracy-new.pickle', 'rb') as handle:\n",
    "    accuracies = pickle.load(handle)\n",
    "accuracies = pd.DataFrame(accuracies)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASBElEQVR4nO3df2xd533f8fentIzRWWvVM9vOkju7nafM/RErY421HeIuaSZ5m2q5DTBrGwpkAzwPc9EWKFdrfxQdiqEY9E8HLKthZF4HtLOx1bLsZW3oYkHTwm0zU5VSyUlYqF5SS8JmZpoWxCBqSfnuD17G19Ql7yFF8vI+fr8AQjzPea7uhwfUh0fPubwnVYUkqV3fMOoAkqStZdFLUuMseklqnEUvSY2z6CWpcTeNOsAgt99+e911112jjiFJY+PkyZNfrqqpQft2ZNHfddddzM3NjTqGJI2NJF9abZ9LN5LUOItekhpn0UtS4yx6SWqcRS9JjduRr7rZiBOnLnBsdp6Llxe5Y/ckMwf2cXj/nlHHkqSRa6LoT5y6wNHjZ1i8cg2AC5cXOXr8DIBlL+ldr4mlm2Oz818v+WWLV65xbHZ+RIkkaedoougvXl5c17gkvZs0UfR37J5c17gkvZs0UfQzB/YxuWviHWOTuyaYObBvRIkkaedo4mLs8gVXX3UjSddrouhhqewtdkm6XhNLN5Kk1Vn0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXGdij7JwSTzSc4leWLA/pkkp3sfZ5NcS3Jbkn1946eTfCXJT236VyFJWtXQX5hKMgF8DPgwcB54JcmLVfW55TlVdQw41pt/CPjpqroEXALu6/t7LgDPb/LXIElaQ5cz+vuBc1X1WlW9BTwLPLTG/CPAMwPGPwT8SVV9af0xJUkb1aXo9wCv922f741dJ8ktwEHguQG7H2HwD4Dlxz6aZC7J3MLCQodYkqQuuhR9BozVKnMPAS/3lm3e/guSm4EfAf7Lak9SVU9V1XRVTU9NTXWIJUnqokvRnwfu7NveC1xcZe5qZ+0PAn9YVf97ffEkSTeqS9G/AtyT5O7emfkjwIsrJyW5FXgAeGHA37Haur0kaYsNfdVNVV1N8jgwC0wAT1fVq0ke6+1/sjf1YeClqnqz//G9dfsPA/9kU5NLkjpJ1WrL7aMzPT1dc3Nzo44hSWMjycmqmh60z9+MlaTGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDWuU9EnOZhkPsm5JE8M2D+T5HTv42ySa0lu6+3bneTXk3whyeeTfP9mfxGSpNUNLfokE8DHgAeBe4EjSe7tn1NVx6rqvqq6DzgKfLqqLvV2/xvgk1X1XuB9wOc3Mb8kaYguZ/T3A+eq6rWqegt4FnhojflHgGcAknwT8AHg3wNU1VtVdfmGEkuS1qVL0e8BXu/bPt8bu06SW4CDwHO9oe8AFoD/kORUko8nec8N5JUkrVOXos+AsVpl7iHg5b5lm5uA9wO/XFX7gTeB69b4AZI8mmQuydzCwkKHWJKkLroU/Xngzr7tvcDFVeY+Qm/Zpu+x56vqM73tX2ep+K9TVU9V1XRVTU9NTXWIJUnqokvRvwLck+TuJDezVOYvrpyU5FbgAeCF5bGq+l/A60n29YY+BHzuhlNLkjq7adiEqrqa5HFgFpgAnq6qV5M81tv/ZG/qw8BLVfXmir/iJ4Bf6/2QeA346KallyQNlarVlttHZ3p6uubm5kYdQ5LGRpKTVTU9aJ+/GStJjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaN/R19Np8J05d4NjsPBcvL3LH7klmDuzj8P6Bbx8kSTfMot9mJ05d4OjxMyxeuQbAhcuLHD1+BsCyl7QlXLrZZsdm579e8ssWr1zj2Oz8iBJJap1Fv80uXl5c17gk3SiXbrbZHbsnuTCg1O/YPTmCNO3x+od0Pc/ot9nMgX1M7pp4x9jkrglmDuxb5RHqavn6x4XLixRvX/84cerCqKNJI2XRb7PD+/fwiz/6PezZPUmAPbsn+cUf/R7POjeB1z+kwVy6GYHD+/dY7FvA6x/SYJ7RqxmrXefw+ofe7Sx6NcPrH9JgLt2oGcvLYb7qRnoni15N8fqHdD2XbiSpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXH+ZqyG8mYe0niz6LUmb2YujT+XbrQmb+YhjT+LXmvyZh7S+LPotSZv5iGNP4tea/JmHtL461T0SQ4mmU9yLskTA/bPJDnd+zib5FqS23r7vpjkTG/f3GZ/Adpa3sxcGn+pqrUnJBPAHwMfBs4DrwBHqupzq8w/BPx0VX2wt/1FYLqqvtw11PT0dM3N+TNBkrpKcrKqpgft63JGfz9wrqpeq6q3gGeBh9aYfwR4Zv0xJUlboUvR7wFe79s+3xu7TpJbgIPAc33DBbyU5GSSR1d7kiSPJplLMrewsNAhliSpiy5FnwFjq633HAJerqpLfWM/WFXvBx4E/lmSDwx6YFU9VVXTVTU9NTXVIZYkqYsuRX8euLNvey9wcZW5j7Bi2aaqLvb+fAN4nqWlIEnSNulS9K8A9yS5O8nNLJX5iysnJbkVeAB4oW/sPUm+cflz4G8BZzcjuCSpm6HvdVNVV5M8DswCE8DTVfVqksd6+5/sTX0YeKmq3ux7+LcCzydZfq7/VFWf3MwvQJK0tqEvrxwFX16pdwvfGVSbZa2XV/ruldKI+M6g2i6+BYI0Ir4zqLaLRS+NiO8Mqu1i0Usj4juDartY9NKI+M6g2i5ejJVGZPmCq6+60Vaz6KUROrx/j8WuLefSjSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuN890pJnXgj8/Fl0UsayhuZjzeXbiQN5Y3Mx5tFL2kob2Q+3ix6SUN5I/PxZtFLGsobmY83L8ZKGsobmY83i15SJ97IfHy5dCNJjbPoJalxFr0kNc6il6TGdSr6JAeTzCc5l+SJAftnkpzufZxNci3JbX37J5KcSvKJzQwvSRpuaNEnmQA+BjwI3AscSXJv/5yqOlZV91XVfcBR4NNVdalvyk8Cn9+01JKkzrqc0d8PnKuq16rqLeBZ4KE15h8BnlneSLIX+DvAx28kqCRpY7oU/R7g9b7t872x6yS5BTgIPNc3/EvAPwe+ttaTJHk0yVySuYWFhQ6xJElddCn6DBirVeYeAl5eXrZJ8neBN6rq5LAnqaqnqmq6qqanpqY6xJIkddGl6M8Dd/Zt7wUurjL3EfqWbYAfBH4kyRdZWvL5YJJf3UBOSdIGdSn6V4B7ktyd5GaWyvzFlZOS3Ao8ALywPFZVR6tqb1Xd1Xvcp6rqH25KcklSJ0Pf66aqriZ5HJgFJoCnq+rVJI/19j/Zm/ow8FJVvbllaSVJ65aq1ZbbR2d6errm5uZGHUOSxkaSk1U1PWifvxkrSY2z6CWpcRa9JDXOopekxln0ktQ4byUoqUknTl3wHrc9Fr2k5pw4dYGjx8+weOUaABcuL3L0+BmAd2XZu3QjqTnHZue/XvLLFq9c49js/IgSjZZFL6k5Fy8vrmu8dRa9pObcsXtyXeOts+glNWfmwD4md028Y2xy1wQzB/aNKNFoeTFWUnOWL7j6qpslFr2kJh3ev+ddW+wruXQjSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNa5T0Sc5mGQ+ybkkTwzYP5PkdO/jbJJrSW5L8ueS/I8kn03yapJ/uflfgiRpLUOLPskE8DHgQeBe4EiSe/vnVNWxqrqvqu4DjgKfrqpLwJ8BH6yq9wH3AQeT/PXN/RIkSWvpckZ/P3Cuql6rqreAZ4GH1ph/BHgGoJZ8tTe+q/dRN5BXkrROXYp+D/B63/b53th1ktwCHASe6xubSHIaeAP4rar6zCqPfTTJXJK5hYWFjvElScN0KfoMGFvtrPwQ8HJv2WZpYtW13pLOXuD+JN896IFV9VRVTVfV9NTUVIdYkqQuuhT9eeDOvu29wMVV5j5Cb9lmpaq6DPw2S2f8kqRt0qXoXwHuSXJ3kptZKvMXV05KcivwAPBC39hUkt29zyeBHwa+sAm5JUkd3TRsQlVdTfI4MAtMAE9X1atJHuvtf7I39WHgpap6s+/hfxH4j71X7nwD8J+r6hOb+hVIktaUqp33Ipjp6emam5sbdQxJGhtJTlbV9KB9/masJDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1buhbIEiSttaJUxc4NjvPxcuL3LF7kpkD+zi8f+C7wW+IRS9JI3Ti1AWOHj/D4pVrAFy4vMjR42cANq3sXbqRpBE6Njv/9ZJftnjlGsdm5zftOSx6SRqhi5cX1zW+ERa9JI3QHbsn1zW+ERa9JI3QzIF9TO6aeMfY5K4JZg7s27Tn8GKsJI3Q8gVXX3UjSQ07vH/Pphb7Si7dSFLjLHpJapxFL0mNs+glqXEWvSQ1LlU16gzXSbIAfGmDD78d+PImxtlK45QVxivvOGWF8co7TllhvPLeSNa/VFVTg3bsyKK/EUnmqmp61Dm6GKesMF55xykrjFfeccoK45V3q7K6dCNJjbPoJalxLRb9U6MOsA7jlBXGK+84ZYXxyjtOWWG88m5J1ubW6CVJ79TiGb0kqY9FL0mNG8uiT3IwyXySc0meGLD/vUl+P8mfJfmZUWRckWdY3n+Q5I96H7+X5H2jyNnLMizrQ72cp5PMJfkbo8jZl2fNvH3zvi/JtSQf2c58KzIMO7Y/lOT/9Y7t6SQ/N4qcfXmGHtte5tNJXk3y6e3O2Jdj2LGd6TuuZ3vfC7eNImsvz7C8tyb5r0k+2zu2H72hJ6yqsfoAJoA/Ab4DuBn4LHDvijnfAnwf8K+AnxmDvD8AfHPv8weBz+zgrH+et6/tfC/whZ18bPvmfQr4DeAjOzUr8EPAJ0Z1PDeQdzfwOeDbe9vfslOzrph/CPjUDj+2/wL4173Pp4BLwM0bfc5xPKO/HzhXVa9V1VvAs8BD/ROq6o2qegW4MoqAK3TJ+3tV9X97m38A7N3mjMu6ZP1q9b77gPcAo7yaPzRvz08AzwFvbGe4Fbpm3Sm65P37wPGq+lNY+ne3zRmXrffYHgGe2ZZkg3XJW8A3JglLJ1eXgKsbfcJxLPo9wOt92+d7YzvVevP+Y+A3tzTR6jplTfJwki8A/w34R9uUbZCheZPsAR4GntzGXIN0/T74/t5/138zyXdtT7SBuuT9K8A3J/ntJCeT/Pi2pXunzv/GktwCHGTpB/+odMn7b4G/ClwEzgA/WVVf2+gTjuMdpjJgbCe/RrRz3iR/k6WiH9W6d6esVfU88HySDwC/APzwVgdbRZe8vwT8bFVdWzo5GpkuWf+Qpfcr+WqSvw2cAO7Z6mCr6JL3JuCvAR8CJoHfT/IHVfXHWx1uhfV0wiHg5aq6tIV5humS9wBwGvgg8J3AbyX53ar6ykaecBzP6M8Dd/Zt72Xpp95O1Slvku8FPg48VFX/Z5uyrbSuY1tVvwN8Z5LbtzrYKrrknQaeTfJF4CPAv0tyeFvSvdPQrFX1lar6au/z3wB27fBjex74ZFW9WVVfBn4HGMULCdbzffsIo122gW55P8rSslhV1TngfwLv3fAzjuqCxA1cyLgJeA24m7cvZHzXKnN/ntFfjB2aF/h24BzwA2OQ9S/z9sXY9wMXlrd3Yt4V83+F0V2M7XJsv63v2N4P/OlOPrYsLS38997cW4CzwHfvxKy9ebeytNb9nlEc03Ue218Gfr73+bf2/p3dvtHnHLulm6q6muRxYJalq9dPV9WrSR7r7X8yybcBc8A3AV9L8lMsXdXe0H97tjov8HPAX2DpbBPgao3g3fY6Zv0x4MeTXAEWgb9Xve/GHZp3R+iY9SPAP01ylaVj+8hOPrZV9fkknwT+CPga8PGqOrsTs/amPgy8VFVvbnfGfh3z/gLwK0nOsLTU87O19L+mDfEtECSpceO4Ri9JWgeLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXu/wPUTkcjllDHKwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(test_sizes, np.max(accuracies, axis=0).values)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
